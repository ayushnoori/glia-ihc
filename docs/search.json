{
  "articles": [
    {
      "path": "404.html",
      "title": "404 Error",
      "author": [],
      "contents": "\r\nYou may have reached this page in error. Please return to the home page, or open an issue on our GitHub repository.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:18:20-07:00"
    },
    {
      "path": "abeta-extraction.html",
      "title": "Plaque Channel Extraction",
      "description": "This ImageJ script extracts the ABETA channel from multi-channel TIFF images and assigns each image a random alphanumeric code for blinded plaque annotation.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\nThis script is written in the ImageJ Macro Language (IJM).\r\nmacro \"ABETA Channel Extraction\" {\r\n\r\n    setBatchMode(true);\r\n\r\n    input = getDirectory(\"Choose input data folder.\");\r\n    files = getFileList(input);\r\n    // Array.show(files);\r\n\r\n    dir = \"<insert your directory here>\";\r\n    datadir = dir + \"Data/2 - Channel Extraction/Plaque/\";\r\n\r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  FUNCTION FOR RANDOM ID\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    function randomString(length, chars) {\r\n        result = \"\";\r\n        for (i = 0; i < length; i++) {\r\n            maxlen = lengthOf(chars)-1;\r\n            rand = round(random * maxlen);\r\n            result +=  substring(chars, rand, rand+1);\r\n        }\r\n        return result;\r\n    }\r\n    \r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  ITERATE OVER IMAGES\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    for (f = 0; f < files.length; f++) {\r\n\r\n        open(input + files[f]);\r\n        Roi.remove; // remove active selection, if any\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  LOAD IMAGE + DEFINE MARKERS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n        filename = substring(image, 0, indexOf(image, \"_Reordered.tif\"));\r\n        \r\n        splitname = split(filename, \"_\");   \r\n        sample = splitname[0];\r\n        layer = splitname[1];\r\n        crop = splitname[2];\r\n        crop = substring(crop, 4);\r\n        \r\n        if (sample == \"1190\" || sample == \"1301\" || sample == \"1619\" || sample == \"2169\" || sample == \"2191\" || sample == \"2250\" || sample == \"2274\") {\r\n            condition = \"CTRL\";\r\n        } else {\r\n            condition = \"AD\";\r\n        }\r\n        \r\n        print(filename);\r\n\r\n        ////////////////////////////////////////////////////////////\r\n        /////  RANDOMIZE CROP\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        id = randomString(6, \"0123456789abcdefghijklmnopqrstuvwxyz\");\r\n        // print(id);\r\n\r\n        Table.set(\"ID\", f, id);\r\n        Table.set(\"Sample\", f, sample);\r\n        Table.set(\"Layer\", f, layer);\r\n        Table.set(\"Crop\", f, crop);\r\n        Table.set(\"Condition\", f, condition);\r\n        Table.set(\"File\", f, filename);\r\n        Table.update();\r\n        \r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE ABETA CHANNEL\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        // duplicate ABETA channel\r\n        selectImage(image); // shift focus to original\r\n        run(\"Duplicate...\", \"title=ABETA duplicate channels=16\");\r\n        \r\n        selectWindow(\"ABETA\"); // shift focus to original\r\n        saveAs(\"Png\", datadir + condition + \"/\" + id + \".png\");\r\n        close();\r\n\r\n        selectImage(image);\r\n        close();\r\n    \r\n    }\r\n\r\n    // save table with mappings\r\n    Table.save(datadir + \"ID Mappings.csv\")\r\n\r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:18:41-07:00"
    },
    {
      "path": "aldh1l1-extraction.html",
      "title": "Astrocyte Channel Extraction",
      "description": "This ImageJ script extracts the ALDH1L1 channel from multi-channel TIFF images and assigns each image a random alphanumeric code for blinded astrocyte annotation.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\nThis script is written in the ImageJ Macro Language (IJM).\r\nmacro \"ALDH1L1 Channel Extraction\" {\r\n\r\n    setBatchMode(true);\r\n\r\n    input = getDirectory(\"Choose input data folder.\");\r\n    files = getFileList(input);\r\n    // Array.show(files);\r\n\r\n    dir = \"<insert your directory here>\";\r\n    datadir = dir + \"Data/2 - Channel Extraction/Astrocyte/\";\r\n\r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  FUNCTION FOR RANDOM ID\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    function randomString(length, chars) {\r\n        result = \"\";\r\n        for (i = 0; i < length; i++) {\r\n            maxlen = lengthOf(chars)-1;\r\n            rand = round(random * maxlen);\r\n            result +=  substring(chars, rand, rand+1);\r\n        }\r\n        return result;\r\n    }\r\n\r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  ITERATE OVER IMAGES\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    for (f = 0; f < files.length; f++) {\r\n\r\n        open(input + files[f]);\r\n        Roi.remove; // remove active selection, if any\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  LOAD IMAGE + DEFINE MARKERS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n        filename = substring(image, 0, indexOf(image, \"_Reordered.tif\"));\r\n        \r\n        splitname = split(filename, \"_\");   \r\n        sample = splitname[0];\r\n        layer = splitname[1];\r\n        crop = splitname[2];\r\n        crop = substring(crop, 4);\r\n        \r\n        if (sample == \"1190\" || sample == \"1301\" || sample == \"1619\" || sample == \"2169\" || sample == \"2191\" || sample == \"2250\" || sample == \"2274\") {\r\n            condition = \"CTRL\";\r\n        } else {\r\n            condition = \"AD\";\r\n        }\r\n        \r\n        print(filename);\r\n\r\n        ////////////////////////////////////////////////////////////\r\n        /////  RANDOMIZE CROP\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        id = randomString(6, \"0123456789abcdefghijklmnopqrstuvwxyz\");\r\n        // print(id);\r\n\r\n        Table.set(\"ID\", f, id);\r\n        Table.set(\"Sample\", f, sample);\r\n        Table.set(\"Layer\", f, layer);\r\n        Table.set(\"Crop\", f, crop);\r\n        Table.set(\"Condition\", f, condition);\r\n        Table.set(\"File\", f, filename);\r\n        Table.update();\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE ALDH1L1 CHANNEL\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        // duplicate ALDH1L1 channel\r\n        selectImage(image); // shift focus to original\r\n        run(\"Duplicate...\", \"title=ALDH1L1 duplicate channels=2\");\r\n\r\n        run(\"Enhance Contrast...\", \"saturated=0.1\"); // only for visualization purposes\r\n        \r\n        selectWindow(\"ALDH1L1\"); // shift focus to original\r\n        saveAs(\"Png\", datadir + condition + \"/\" + id + \".png\");\r\n        close();\r\n\r\n        selectImage(image);\r\n        close();\r\n    \r\n    }\r\n\r\n    // save table with mappings\r\n    Table.save(datadir + \"ID Mappings.csv\")\r\n\r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:18:47-07:00"
    },
    {
      "path": "astrocyte-cnn.html",
      "title": "Convolutional Neural Network for Astrocyte Classification",
      "description": "This Python script trains a convolutional neural network to predict diagnosis (i.e., CTRL vs. AD) at the single-astrocyte level using raw image features.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        },
        {
          "name": {},
          "url": {}
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nDefine Data Transformations\r\nLoad Data\r\nDefine Model Architecture\r\nDefine Training Loop\r\nTrain Model\r\nVisualize Training\r\nEvaluate on Test Set\r\nPlot ROC Curve\r\n\r\nModel Interpretability\r\nPlot CNN Weights\r\n\r\nSave Notebook\r\n\r\nDependencies\r\n\r\n# data manipulation and visualization\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.pyplot import *\r\nfrom skimage import io\r\n\r\n# PyTorch\r\nimport torch\r\nfrom torch import nn, optim\r\nimport torchvision\r\nfrom torchvision import transforms, datasets, models\r\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\r\nfrom torch.utils.data.sampler import SubsetRandomSampler\r\n\r\n# file management and time\r\nimport time\r\nfrom datetime import datetime\r\nimport os\r\n\r\n# create time object used for file names\r\nmy_time = datetime.now()\r\n\r\nbase_dir = \"<insert your directory here>\"\r\ndata_dir = base_dir + \"Data/4 - CNN/Astrocyte/\"\r\nresults_dir = base_dir + \"Results/CNN/2 - Astrocyte CNN/\"\r\n\r\n# set seeds to make computations deterministic\r\ntorch.manual_seed(1234)\r\nnp.random.seed(1234)\r\n\r\n# set CUDA device\r\ndevice = torch.device('cuda:0')\r\nprint(torch.cuda.is_available())\r\nprint(torch.cuda.get_device_name(0))\r\n\r\ndef togpu(x):\r\n    # return x.cuda()\r\n    return x.to(device)\r\n\r\ndef tocpu(x):\r\n    return x.cpu()\r\n\r\nDefine Data Transformations\r\nThe order of astrocyte markers (out of 17 markers in the original crops) prior to data transformation is specified below, used in the select_channels() function (zero-indexed).\r\nDAPI\r\nALDH1L1\r\nGFAP\r\nYKL40\r\nVIM\r\nTSPO\r\nEAAT1\r\nEAAT2\r\nGS\r\n1\r\n2\r\n4\r\n13\r\n11\r\n6\r\n10\r\n7\r\n14\r\n\r\ndef to_tensor(x):\r\n    x = np.ndarray.astype(x, float)\r\n    x /= 255 # normalize to a 0-1 distribution\r\n    return torch.from_numpy(x)\r\n\r\ndef select_channels(x):\r\n    return x[[0, 1, 3, 12, 10, 5, 9, 6, 13]]\r\n\r\ndef norm(x): # calculate mean and std for each channel\r\n    my_mean = []; my_std = []\r\n\r\n    for c in x:\r\n        channel_std = c.std().item() # return std of channel n as float\r\n        if channel_std == 0: # prevent division by zero error\r\n            channel_std += 1e-05\r\n\r\n        my_mean.append(c.mean().item()) # return mean of channel n as float, append\r\n        my_std.append(channel_std) # append std of channel n\r\n\r\n    return torchvision.transforms.functional.normalize(x, tuple(my_mean), tuple(my_std))\r\n\r\n# define data transforms\r\ndata_transform = transforms.Compose([\r\n    to_tensor,\r\n    select_channels,\r\n    norm # mean is 0 and std is 1 for all images\r\n    ])\r\n\r\nLoad Data\r\nLoad data into workspace, use sci-kit loader as PIL truncates at three channels.\r\n\r\n# load data\r\ntrain_data = datasets.ImageFolder(data_dir + \"Train\", transform = data_transform, loader = io.imread)\r\nval_data = datasets.ImageFolder(data_dir + \"Validation\", transform = data_transform, loader = io.imread)\r\ntest_data = datasets.ImageFolder(data_dir + \"Test\", transform = data_transform, loader = io.imread)\r\n\r\nnum_workers = 0 # number of subprocesses to use for data loading\r\n\r\nFunction to visualize specific astrocytes.\r\n\r\nfrom matplotlib.colors import Colormap, ListedColormap\r\n\r\nmarker = [\"DAPI\", \"ALDH1L1\", \"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\",  \"GS\"]\r\ncolormaps = [\"Blues\", \"Reds\", \"RdPu\", \"Oranges\", \"OrRd\", \"BuPu\", \"Greens\", \"BuGn\", \"Purples\"] # add _r to reverse colormaps\r\n\r\ndef plotAstrocyte(img, lab, idx, outdir = None): # dat = test_data or train_data\r\n\r\n    # given that train_data.class_to_idx is {'AD': 0, 'CTRL': 1}\r\n    if lab == 0:\r\n        img_title = \"Alzheimer\"\r\n    else:\r\n        img_title = \"Control\"\r\n\r\n    fig, axs = plt.subplots(2, 5, figsize = (10, 4))\r\n    plt.suptitle(\"Astrocyte #\" + str(idx + 1) + \": \" + img_title, fontsize = 14, fontweight = \"bold\")\r\n    fig.tight_layout(h_pad = 1)\r\n    i = 0\r\n\r\n    for r in range(2):\r\n        for c in range(5):\r\n            if(i < len(marker)):\r\n                cm = get_cmap(colormaps[i])(range(255))\r\n                cm = ListedColormap(cm)\r\n\r\n                axs[r, c].imshow(img[i], cmap = cm)\r\n                axs[r, c].set_title(marker[i])\r\n                i += 1\r\n                axs[r, c].get_xaxis().set_visible(False)\r\n                axs[r, c].get_yaxis().set_visible(False)\r\n    \r\n    axs[1, 4].set_axis_off()\r\n\r\nGet dataset lengths.\r\n\r\n# obtain training, validation, and test length\r\nnum_train = len(train_data)\r\nnum_val = len(val_data)\r\nnum_test = len(test_data)\r\n\r\n# define testing data loader\r\ntest_loader = DataLoader(test_data, batch_size = 20, shuffle = False)\r\n\r\n# print output\r\nprint(\"Train: \" + str(num_train) + \"\\t\\t\" + \"Validation: \" + str(num_val) + \"\\t\\t\" + \"Test: \" + str(num_test))\r\n\r\nDefine Model Architecture\r\nModel architecture is defined with four convolutional layers and three dense layers. All convolutional layers use the ReLU (rectified linear unit) activation function, and the first three convolutional layers are followed by max-pooling and dropout layers. The number of output channels and dropout probabilities are set as tunable hyperparameters.\r\n\r\nfrom torch.autograd import Variable\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\n\r\nclass AstrocyteCNN(torch.nn.Module):\r\n    \r\n    def __init__(self, trial):\r\n        super(AstrocyteCNN, self).__init__()\r\n\r\n        # define number of outgoing filters\r\n        out_channels_1 = trial.suggest_int(\"out_channels_1\", 64, 256)\r\n        out_channels_2 = trial.suggest_int(\"out_channels_2\", 64, out_channels_1)\r\n        out_channels_3 = trial.suggest_int(\"out_channels_3\", 32, out_channels_2)\r\n        out_channels_4 = trial.suggest_int(\"out_channels_4\", 8, 32)\r\n        self.feature_length = out_channels_4\r\n\r\n        # the shape of the input images are 9 x 64 x 64\r\n        self.conv1 = torch.nn.Conv2d(in_channels=9, out_channels=out_channels_1, kernel_size=3, padding=1)\r\n        self.conv2 = torch.nn.Conv2d(in_channels=out_channels_1, out_channels=out_channels_2, kernel_size=3, padding=1)\r\n        self.conv3 = torch.nn.Conv2d(in_channels=out_channels_2, out_channels=out_channels_3, kernel_size=3, padding=1)\r\n        self.conv4 = torch.nn.Conv2d(in_channels=out_channels_3, out_channels=out_channels_4, kernel_size=3, padding=1)\r\n        \r\n        # after pooling, the input feature vector should be 64 x 8 x 8\r\n        self.fc1 = torch.nn.Linear(in_features=(out_channels_4 * 8 * 8), out_features=1024)\r\n        self.fc2 = torch.nn.Linear(in_features=1024, out_features=64)\r\n        self.fc3 = torch.nn.Linear(in_features=64, out_features=2)\r\n\r\n        # define ReLU and max-pooling layers\r\n        self.relu = torch.nn.ReLU(inplace=False)\r\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\r\n\r\n        # define dropout layers\r\n        dropout_prob_1 = trial.suggest_float(\"dropout_prob_1\", 0.2, 0.8)\r\n        self.dropout1 = torch.nn.Dropout(p = dropout_prob_1, inplace=False)\r\n        \r\n        dropout_prob_2 = trial.suggest_float(\"dropout_prob_2\", 0.2, 0.8)\r\n        self.dropout2 = torch.nn.Dropout(p = dropout_prob_2, inplace=False) \r\n\r\n        dropout_prob_3 = trial.suggest_float(\"dropout_prob_3\", 0.2, 0.8)\r\n        self.dropout3 = torch.nn.Dropout(p = dropout_prob_3, inplace=False)\r\n\r\n        self.loss_list = []\r\n        self.acc_list = []\r\n        self.val_acc = []\r\n        self.val_loss = []\r\n        self.epoch_val_loss = []\r\n        self.epoch_val_auc = []\r\n\r\n        # print all of the hyperparameters of the training iteration:\r\n        print(\"\\n====== ASTROCYTE CNN ======\")\r\n        print(\"Dropout Probabilities: [1] {} --> [2] {} --> [3] {}\".format(dropout_prob_1, dropout_prob_2, dropout_prob_3))\r\n        print(\"Number of Kernels: [1] {} --> [2] {} --> [3] {} --> [4] {}\".format(out_channels_1, out_channels_2, out_channels_3, out_channels_4))\r\n        print(\"=\" * 27)\r\n\r\n        \r\n    def forward(self, x):\r\n\r\n        ## FEATURE EXTRACTOR\r\n\r\n        # size changes from (9, 64, 64) to (64, 64, 64)\r\n        x = self.relu(self.conv1(x)) # first convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 64, 64) to (64, 32, 32)\r\n\r\n        x = self.dropout1(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 32, 32) to (64, 32, 32)\r\n        x = self.relu(self.conv2(x)) # second convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 32, 32) to (64, 16, 16)\r\n\r\n        x = self.dropout2(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 16, 16) to (64, 16, 16)\r\n        x = self.relu(self.conv3(x)) # third convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 16, 16) to (64, 8, 8)\r\n\r\n        x = self.dropout3(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 8, 8) to (64, 8, 8)\r\n        x = self.relu(self.conv4(x)) # four convolution, then ReLU non-linearity\r\n\r\n        ## COLLAPSE TO FEATURE VECTOR\r\n\r\n        x = x.reshape(-1, self.feature_length * 8 * 8) # reshape data, then pass to dense classifier\r\n\r\n        ## DENSE NETWORK TO CLASSIFY\r\n\r\n        x = self.relu(self.fc1(x)) # 4096 to 1024\r\n        x = self.relu(self.fc2(x)) # 1024 to 64\r\n        x = self.fc3(x) # 64 to 2\r\n        \r\n        return x\r\n\r\nHere, the loss function is defined as cross-entropy loss. The loss function is defined as cross-entropy loss. Cross-entropy is a measure from the field of information theory to calculate the difference between two probability distributions.\r\nThe optimizer, learning rate, and weight decay are set as tunable hyperparameters. Of note, one of the possible optimizers is the Adam optimization algorithm, a variant of stochastic gradient descent (SGD). Adam was introduced in Kingma and Ba (2017) as follows:\r\n\r\n“We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.”\r\n\r\nStochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training. When using Adam, a learning rate is maintained for each network parameter and separately adapted as learning unfolds. The other possible optimizers are SGD and root mean square propagation (RMSprop).\r\nIn defining the optimizer, establishing a small value for weight_decay enables L2, or ridge, regularization which penalizes large weights and counteracts model overfitting.\r\n\r\ndef createLossAndOptimizer(net, trial):\r\n\r\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\r\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\r\n    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\r\n\r\n    loss = torch.nn.CrossEntropyLoss()\r\n    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\r\n    \r\n    return(loss, optimizer, optimizer_name, learning_rate, weight_decay)\r\n\r\nDefine Training Loop\r\nWhen defining the training loop, early stopping (regularization used to avoid overfitting on the training data) is implemented based on the EarlyStopping class in pytorchtool.py from Bjarten/early-stopping-pytorch (which in turn is inspired by the class of the same name from pytorch/ignite. Early stopping patience is the the number of epochs to wait after the last time the validation loss improved before “terminating” the training loop. Note that the training loop is allowed to continue, but a checkpoint is created, and model parameters at the last checkpoint are loaded at the end of trainNet().\r\nThe following function is called by trainNet().\r\n\r\ndef train_function(net, train_loader, optimizer, loss, epoch, verbose):\r\n\r\n    running_loss = 0.0\r\n    n_batches = len(train_loader)\r\n    print_every = n_batches // 5 # print 5 times total each epoch\r\n    start_time = time.time()\r\n    total_train_loss = 0\r\n    \r\n    # batch iteration\r\n    for i, data in enumerate(train_loader, 0):\r\n        \r\n        inputs, labels = data\r\n        # print(inputs, labels)\r\n        \r\n        # perform backpropagation and Adam optimization\r\n        inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\r\n\r\n        # clear gradients\r\n        optimizer.zero_grad()\r\n\r\n        # perform forward propagation\r\n        outputs = net(inputs)\r\n\r\n        # calculate cross-entropy loss\r\n        loss_size = loss(outputs, labels)\r\n        net.loss_list.append(loss_size.item())\r\n\r\n        # calculate gradients and update weights via Adam optimizer\r\n        loss_size.backward()\r\n        optimizer.step()\r\n        \r\n        # print(loss_size.data.item())\r\n        running_loss += loss_size.data.item()\r\n        total_train_loss += loss_size.data.item()\r\n        \r\n        # track the accuracy\r\n        total = labels.size(0)\r\n        _, predicted = torch.max(outputs.data, 1)\r\n        correct = (predicted == labels).sum().item()\r\n        net.acc_list.append(correct / total)\r\n        \r\n        if (i % print_every == print_every - 1) and verbose:\r\n            time_delta = time.time() - start_time\r\n            print(\"Epoch {}, {:d}% \\t Training Loss: {:.4f} \\t Accuracy: {:.2f}% \\t Took: {:.2f}s\".format(epoch + 1, int(100 * (i + 1) / n_batches), running_loss / print_every, (correct / total) * 100, time_delta))\r\n            running_loss = 0.0\r\n            start_time = time.time()\r\n\r\nThis is the central function which implements the model training loop. The Optuna optimizer maximizes the out-of-sample area under the receiver operating characteristic (ROC) curve (AUC), which is determined by 3-fold cross-validation using the scikit-learn cross-validator within the 80% training set for each Optuna trial (i.e., Bayesian meta-optimization) (Pedregosa et al. 2011).\r\n\r\nimport sklearn.metrics as metrics\r\nfrom statistics import mean\r\nfrom itertools import chain\r\nfrom pytorchtools import EarlyStopping\r\nfrom sklearn.model_selection import KFold\r\n\r\n# checkpoint_dir = results_dir + \"Early Stopping\\\\\"\r\ncheckpoint_dir = results_dir + \"Early Stopping/\"\r\n\r\ndef trainNet(trial, batch_size, n_epochs, patience, k_folds):\r\n\r\n    # print all of the hyperparameters of the training iteration:\r\n    print(\"\\n===== HYPERPARAMETERS =====\")\r\n    print(\"Trial Number: {}\".format(trial.number))\r\n    print(\"Batch Size: \", batch_size)\r\n    print(\"Epochs: \", n_epochs)\r\n    print(\"Folds: \", k_folds)\r\n    print(\"=\" * 27)\r\n\r\n    # concatenate original training and validation split\r\n    full_data = ConcatDataset([train_data, val_data])\r\n\r\n    # define the K-fold cross validator\r\n    kfold = KFold(n_splits = k_folds, shuffle = True)\r\n\r\n    # average max. validation AUC across k-folds\r\n    average_max_val_auc = []\r\n\r\n    # k-fold cross validation model evaluation\r\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(full_data)):\r\n\r\n        # generate the model\r\n        net = togpu(AstrocyteCNN(trial)).double()\r\n\r\n        # define loss and optimizer\r\n        loss, optimizer, optimizer_name, learning_rate, weight_decay = createLossAndOptimizer(net, trial)\r\n\r\n        # print fold statement\r\n        print(\"\\n>>> BEGIN FOLD #{}\".format(fold + 1))\r\n        print(\"Optimizer: \", optimizer_name)\r\n        print(\"Learning Rate: \", learning_rate)\r\n        print(\"Weight Decay: \", weight_decay)\r\n\r\n        # sample elements randomly from a given list of ids, no replacement\r\n        train_sampler = SubsetRandomSampler(train_idx)\r\n        val_sampler = SubsetRandomSampler(val_idx)\r\n\r\n        # define train and validation data loaders\r\n        train_loader = DataLoader(full_data, batch_size = batch_size, sampler = train_sampler)\r\n        val_loader = DataLoader(full_data, batch_size = 32, sampler = val_sampler)\r\n\r\n        # initialize the early stopping object\r\n        early_stopping = EarlyStopping(patience = patience, verbose = True, path = checkpoint_dir + \"checkpoint.pt\")\r\n\r\n        # set start data\r\n        training_start_time = time.time()        \r\n        min_val_loss = float('inf')\r\n        max_val_auc = 0\r\n\r\n        # epoch iteration\r\n        for epoch in range(n_epochs):\r\n            \r\n            print(\"\\n----- TRIAL #{} FOLD #{} EPOCH #{} -----\".format(trial.number + 1, fold + 1, epoch + 1))\r\n\r\n            # set model to training mode\r\n            net.train()\r\n\r\n            # batch iteration\r\n            train_function(net, train_loader, optimizer, loss, epoch, verbose = False)\r\n                    \r\n            # set model to evaluation mode\r\n            net.eval()\r\n            val_true = []; val_score = [];\r\n            total_val_loss = 0\r\n\r\n            # validation set iteration\r\n            for inputs, labels in val_loader:\r\n                inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\r\n                \r\n                val_outputs = net(inputs)\r\n                val_loss_size = loss(val_outputs, labels)\r\n                total_val_loss += val_loss_size.data.item()\r\n                net.val_loss.append(val_loss_size.item())\r\n\r\n                val_total = labels.size(0)\r\n                _, val_predicted = torch.max(val_outputs.data, 1)\r\n                val_correct = (val_predicted == labels).sum().item()\r\n                net.val_acc.append(val_correct / val_total)\r\n\r\n                # for ROC calculation\r\n                val_ctrl_probs = [x[1] for x in F.softmax(val_outputs.data).tolist()]\r\n                val_score.append(val_ctrl_probs); val_true.append(labels.tolist())\r\n\r\n            # get validation accuracy\r\n            print(\"\\nValidation Accuracy = {:.2f}%\".format((val_correct / val_total) * 100))\r\n\r\n            # calculate AUC for this epoch\r\n            val_true = list(chain.from_iterable(val_true))\r\n            val_score = list(chain.from_iterable(val_score))\r\n            fpr, tpr, thresholds = metrics.roc_curve(y_true = val_true, y_score = val_score, pos_label = 1)\r\n            val_auc = metrics.auc(fpr, tpr)\r\n            net.epoch_val_auc.append(val_auc)\r\n            print(\"\\nValidation AUC = {:.4f}\".format(val_auc))\r\n\r\n            # calculate maximum validation AUC\r\n            if val_auc > max_val_auc:\r\n                print(\"New Best AUC: ({} --> {})\".format(max_val_auc, val_auc))\r\n                max_val_auc = val_auc\r\n\r\n            # get validation loss for this epoch\r\n            val_loss = total_val_loss / len(val_loader)\r\n            net.epoch_val_loss.append(val_loss)     \r\n            print(\"\\nValidation Loss = {:.4f}\".format(val_loss))\r\n\r\n            # calculate minimum validation loss\r\n            if val_loss < min_val_loss:\r\n                print(\"New Best Loss: ({} --> {})\".format(min_val_loss, val_loss))\r\n                min_val_loss = val_loss\r\n\r\n            # early stopping based on validation loss\r\n            early_stopping(total_val_loss / len(val_loader), net)\r\n            if early_stopping.early_stop:\r\n                print(\"Early Stopping at Epoch {}\".format(epoch + 1))\r\n                break\r\n\r\n        # print output\r\n        print(\"\\n>>> COMPLETE FOLD #{}\".format(fold + 1))\r\n        print(\"Training Finished, Took {:.2f}s\".format(time.time() - training_start_time))\r\n        print(\"Minimum Validation Loss: {:.4f}\".format(min_val_loss))\r\n        print(\"Maximum Validation AUC: {:.4f}\\n\".format(max_val_auc))\r\n\r\n        # append max. val AUC\r\n        average_max_val_auc.append(max_val_auc)\r\n\r\n    # retrain model on full dataset\r\n    final_net = togpu(AstrocyteCNN(trial)).double()\r\n\r\n    # define loss and optimizer\r\n    loss, optimizer, optimizer_name, learning_rate, weight_decay = createLossAndOptimizer(final_net, trial)\r\n\r\n    # print statements\r\n    print(\"\\n\\n>>> FINAL MODEL FOR TRIAL #{}\".format(trial.number + 1))\r\n    print(\"Optimizer: \", optimizer_name)\r\n    print(\"Learning Rate: \", learning_rate)\r\n    print(\"Weight Decay: \", weight_decay)\r\n\r\n    # sample elements randomly from full dataset\r\n    num_full = len(full_data); full_idx = list(range(num_full)); np.random.shuffle(full_idx)\r\n    full_sampler = SubsetRandomSampler(full_idx)\r\n\r\n    # define train and validation data loaders\r\n    full_loader = DataLoader(full_data, batch_size = batch_size, sampler = full_sampler)\r\n    \r\n    # iterate over full dataset to train model\r\n    final_net.train()\r\n    for epoch in range(n_epochs):\r\n        print(\"\\n----- TRIAL #{} FINAL MODEL EPOCH #{} -----\".format(trial.number + 1, epoch + 1))\r\n        train_function(final_net, full_loader, optimizer, loss, epoch, verbose = True)\r\n\r\n    # calculate average validation AUC across folds\r\n    print(\"Maximum Validation AUCs:\" + str(average_max_val_auc))\r\n    average_max_val_auc = mean(average_max_val_auc)\r\n    print(\"Average Max. Validation AUC: {:.4f}\\n\\n\".format(average_max_val_auc))\r\n\r\n    # use validation AUC as score to maximize across Optuna trials\r\n    return(final_net, average_max_val_auc)\r\n\r\nTrain Model\r\nHere, we use Optuna to optimize the hyperparameters for training (Akiba et al. 2019). First, we define the objective() function, which returns the average validation AUC for any given trial with a combination of selected hyperparameters (as discussed above). This value is then used as feedback on the performance of the trial, and the objective() function is maximized using the multivariate tree-structured Parzen estimator algorithm (Bergstra et al. 2011). The trial object is passed to various functions (define above) to tune hyperparameters.\r\n\r\nimport optuna\r\nimport pickle\r\nfrom optuna.samplers import TPESampler\r\n\r\nparam_dir = results_dir + \"Hyperparameter Optimization/\"\r\nstudy_dir = results_dir + \"Study Database/\"\r\n\r\ndef objective(trial):\r\n\r\n    # start the training loop\r\n    model, max_val_auc = trainNet(trial, batch_size = 64, n_epochs = 30, patience = 10, k_folds = 3)\r\n\r\n    # save model for this loop\r\n    torch.save(model.state_dict(), param_dir + \"astrocyte_cnn_{}.pt\".format(trial.number))\r\n    f = open(param_dir + \"accuracy_loss_{}.pkl\".format(trial.number), \"wb\")\r\n    pickle.dump([model.acc_list, model.loss_list, model.val_acc, model.val_loss, model.epoch_val_loss, model.epoch_val_auc], f)\r\n    f.close()\r\n\r\n    return max_val_auc\r\n\r\nOptuna results are stored in a SQL database to preserve results between runs.\r\n\r\nimport logging\r\nimport sys\r\n\r\n# add stream handler of stdout to show the messages\r\noptuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\r\n\r\n# create study\r\nstudy_name = \"astrocyte-study\"  # unique identifier of the study\r\nstorage_name = \"sqlite:///{}.db\".format(study_dir + study_name)\r\nstudy = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed = 1234, multivariate = True), study_name = study_name, storage = storage_name, load_if_exists = True)\r\n\r\n# optimize hyperparameters\r\nstudy.optimize(objective, n_trials = 20, gc_after_trial = True)\r\n\r\nAfter the Optuna hyperparameter optimization is complete, the hyperparamters of the best performing trial are retrieved.\r\n\r\n# get pruned and complete trials\r\npruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\r\ncomplete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\r\n\r\n# print print study statistics\r\nprint(\"\\nStudy Statistics:\")\r\nprint(\"- Finished Trials: \", len(study.trials))\r\nprint(\"- Pruned Trials: \", len(pruned_trials))\r\nprint(\"- Complete Trials: \", len(complete_trials))\r\n\r\nprint(\"\\nBest Trial:\")\r\nbest_trial = study.best_trial\r\nprint(\"- Number: \", best_trial.number)\r\nprint(\"- Value: \", best_trial.value)\r\nprint(\"- Hyperparameters: \")\r\nfor key, value in best_trial.params.items():\r\n    print(\"   - {}: {}\".format(key, value))\r\n\r\n# save and view output\r\nstudy_results = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\r\nstudy_results.to_csv(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_OptunaHistory.csv\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year))\r\n\r\nA new CNN is then initialized with these hyperparameter values.\r\n\r\n# define CNN and load weights and parameters\r\nCNN = togpu(AstrocyteCNN(best_trial)).double()\r\nCNN.load_state_dict(torch.load(param_dir + \"astrocyte_cnn_{}.pt\".format(best_trial.number)))\r\n\r\n# load accuracy and loss logs for training/validation\r\nf = open(param_dir + \"accuracy_loss_{}.pkl\".format(best_trial.number), \"rb\")\r\n[CNN.acc_list, CNN.loss_list, CNN.val_acc, CNN.val_loss, CNN.epoch_val_loss, CNN.epoch_val_auc] = pickle.load(f)\r\nf.close()\r\n\r\nHyperparameter optimization progress is visualized below.\r\n\r\nimport optuna.visualization.matplotlib as oviz\r\n\r\nv1 = oviz.plot_param_importances(study)\r\nv2 = oviz.plot_optimization_history(study)\r\nv3 = oviz.plot_slice(study)\r\n\r\ndef fig_name(name):\r\n    return(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_{}.pdf\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year, name))\r\n\r\nv1.figure.savefig(fig_name(\"HyperparameterImportance\"))\r\nv2.figure.savefig(fig_name(\"OptimizationHistory\"))\r\n\r\nVisualize Training\r\nPlot the training accuracy, training loss, and validation loss from the best Optuna trial.\r\n\r\nimport itertools\r\nimport math\r\nfrom bokeh.plotting import figure, show\r\nfrom bokeh.io import output_notebook, reset_output, export_png\r\nfrom bokeh.models import LinearAxis, Range1d\r\n\r\nlen_loss = len(CNN.loss_list)\r\nmax_loss = max(CNN.loss_list)\r\nif max_loss < 1:\r\n    max_loss = 1\r\n\r\n# define figure\r\npname = \"{}:{}, {}/{}/{} - Astrocyte CNN Results\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\np = figure(y_axis_label=\"Loss\", x_axis_label=\"Training Iterations\", width=1400, height=750, title=pname)\r\n\r\n# range limits\r\np.x_range = Range1d(0, len_loss, bounds = (0, len_loss))\r\np.y_range = Range1d(0, 1, bounds = (0, max_loss)) # range from 0 to max_loss\r\n\r\n# define extra axes\r\np.extra_x_ranges = {\"Epochs\": Range1d(start=0, end=30, bounds = (0, 30))}\r\np.extra_y_ranges = {\"Accuracy\": Range1d(start=0, end=100, bounds = (0, max_loss * 100))}\r\n\r\n# add extra axes\r\np.add_layout(LinearAxis(y_range_name=\"Accuracy\", axis_label=\"Accuracy (%)\"), \"right\")\r\np.add_layout(LinearAxis(x_range_name=\"Epochs\", axis_label=\"Epochs\"), \"above\") # below\r\n\r\n# add graphs\r\np.line(np.arange(len_loss), CNN.loss_list, line_alpha = 0.5, legend_label = \"Training Loss\")\r\np.line(np.arange(len_loss), np.array(CNN.acc_list) * 100, y_range_name=\"Accuracy\", color=\"red\", line_alpha = 0.5, legend_label = \"Training Accuracy\")\r\n\r\n# specify options\r\np.legend.click_policy = \"hide\"\r\np.toolbar.active_drag = None\r\n\r\noutput_notebook()\r\nshow(p)\r\n\r\nEvaluate on Test Set\r\nDefine, then apply, a function to evaluate the model on test set images. Misclassified astrocytes in the hold-out test set can then be identified and plotted.\r\n\r\nfrom itertools import chain\r\n\r\ndef testNet(net, verbose = True):\r\n\r\n    cpuCNN = tocpu(CNN)\r\n\r\n    # initialize empty values\r\n    test_output = []; correct = 0; total = 0\r\n\r\n    # test the model\r\n    cpuCNN.eval()\r\n    with torch.no_grad():\r\n        for i, (images, labels) in enumerate(test_loader):\r\n\r\n            # evaluate images\r\n            outputs = cpuCNN(images)\r\n\r\n            # get prediction label, probability\r\n            _, predicted = torch.max(outputs.data, 1)\r\n            probs = F.softmax(outputs.data).tolist()\r\n            ad_probs = [x[0] for x in probs]; ctrl_probs = [x[1] for x in probs]\r\n\r\n            # get and parse file name\r\n            fname = test_loader.dataset.samples[(i*20):((i*20)+len(images))]\r\n            fname = [x[0].split(\"\\\\\").pop() for x in fname]\r\n\r\n            # update counter\r\n            total += labels.size(0)\r\n            correct += (predicted == labels).sum().item()\r\n\r\n            test_output.append([fname, predicted.tolist(), labels.tolist(), ctrl_probs, ad_probs, torch.chunk(images, 20, 0)])\r\n\r\n    # calculate accuracy\r\n    test_acc = (correct / total) * 100\r\n\r\n    # parse output\r\n    test_output = [list(x) for x in zip(*test_output)]\r\n    test_output = [list(chain.from_iterable(x)) for x in test_output]\r\n    test_output = pd.DataFrame(test_output).transpose()\r\n    test_output.columns = [\"File\", \"PredictedLabel\", \"TrueLabel\", \"ProbabilityCTRL\", \"ProbabilityAD\", \"Image\"]\r\n    \r\n    if verbose:\r\n        print(\"Accuracy on the {} Test Images: {}%\".format(len(test_data), test_acc))\r\n\r\n    return(test_acc, test_output)\r\n\r\nApply the function on the independnet test set.\r\n\r\n# test data\r\nacc, dat = testNet(CNN)\r\n\r\n# save and view output\r\ndat.to_csv(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_TestSetResults.csv\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year))\r\ndat.head(10)\r\n\r\nPlot ROC Curve\r\n\r\nimport sklearn.metrics as metrics\r\n\r\nfpr, tpr, thresholds = metrics.roc_curve(y_true = dat.TrueLabel.to_list(), y_score = dat.ProbabilityCTRL.to_list(), pos_label = 1)\r\nroc_auc = metrics.auc(fpr, tpr)\r\n\r\nplt.title('Receiver Operating Characteristic')\r\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\r\nplt.legend(loc = 'lower right')\r\nplt.plot([0, 1], [0, 1],'r--'); plt.xlim([0, 1]); plt.ylim([0, 1])\r\nplt.ylabel('True Positive Rate'); plt.xlabel('False Positive Rate')\r\n\r\nrfname = results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_ROCCurve.pdf\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\nplt.savefig(rfname, bbox_inches=\"tight\")\r\n\r\nprint(\"AUC: \" + str(roc_auc))\r\n\r\nModel Interpretability\r\nUsing the captum library for model interpretability in PyTorch (see CIFAR tutorial here) (Kokhlikyan et al. 2019).\r\nFirst, define attributeFeatures(), which is a generic function that will be used for calling an attribute on the attribution algorithm defined in input. Then, choose a test set image at index idx and define interpretAstrocyte(), which will apply the selected attribution algorithms on that image. The model (i.e., cpuCNN) should be set to eval mode from the prior chunk.\r\nWithin interpretAstrocyte(), compute gradients with respect to the class of the test set image, then, apply the integrated gradients attribution algorithm on the test set image. Integrated Gradients computes the integral of the gradients of the output prediction with respect to the input image pixels. More details about integrated gradients can be found in the original paper (Sundararajan, Taly, and Yan 2017).\r\nTranspose the image and gradients for visualization purposes. Also, note that the classification label assumes that test_data.class_to_idx is {'AD': 0, 'CTRL': 1}.\r\n\r\nfrom captum.attr import Saliency\r\nfrom captum.attr import IntegratedGradients\r\nfrom captum.attr import GuidedGradCam\r\nfrom captum.attr import visualization as viz\r\n\r\n# get model\r\ncpuCNN = tocpu(CNN).eval()\r\n\r\n# define generic attribution function\r\ndef attributeFeatures(idx, algorithm, input, **kwargs):\r\n    cpuCNN.zero_grad()\r\n    tensor_attributions = algorithm.attribute(input, target = dat.TrueLabel[idx], **kwargs)\r\n    return tensor_attributions\r\n\r\n# utility function\r\ndef scale(x):\r\n    return (x - np.min(x))/(np.max(x) - np.min(x))\r\n\r\n# function for model interpretability\r\ndef interpretAstrocyte(idx):\r\n\r\n    # select test image\r\n    input = dat.Image[idx]\r\n    input.requires_grad = True\r\n\r\n    # saliency\r\n    saliency = Saliency(cpuCNN)\r\n    grads = saliency.attribute(input, target = dat.TrueLabel[idx])\r\n    grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n\r\n    # integrated gradients\r\n    ig = IntegratedGradients(cpuCNN)\r\n    attr_ig, delta_ig = attributeFeatures(idx, ig, input, baselines = input * 0, return_convergence_delta=True)\r\n    attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n\r\n    # guided gradcam\r\n    gc = GuidedGradCam(cpuCNN, cpuCNN.conv4)\r\n    attr_gc = attributeFeatures(idx, gc, input)\r\n    attr_gc = np.transpose(attr_gc.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n    \r\n    # scale image to 0-1 distribution and transpose for visualization\r\n    original = input.cpu().detach().numpy()[0]\r\n    original = np.array([scale(x) for x in original])\r\n    original = np.transpose(original, (1, 2, 0))\r\n\r\n    return(idx, original, grads, attr_ig, attr_gc)\r\n\r\nNext, define a function to visualize results of attribution algorithms across all channels.\r\n\r\nimport regex as re\r\n\r\nmarker = [\"DAPI\", \"ALDH1L1\", \"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\",  \"GS\"]\r\ncolormaps = [\"Blues\", \"Reds\", \"RdPu\", \"Oranges\", \"OrRd\", \"BuPu\", \"Greens\", \"BuGn\", \"Purples\"]\r\n\r\n# function to visualize attribution across channels\r\ndef visualizeAttribution(idx, original, grads, attr_ig, attr_gc):\r\n\r\n    # print predicted class, classification probability, and true class\r\n    classes = (\"Alzheimer\", \"Control\")\r\n    my_fname, my_pred, my_lab, my_ctrl, my_ad = dat.iloc[idx, 0:5]\r\n    my_pred = classes[my_pred]; my_lab = classes[my_lab]\r\n    # print('Predicted:', my_pred, '\\nProbability:', my_prob[0], '\\nLabel:', my_lab)\r\n\r\n    # define plot\r\n    fig, axs = plt.subplots(nrows = 5, ncols = 8, figsize = (24, 15))\r\n    fig.tight_layout(h_pad = 2)\r\n\r\n    # parse filename\r\n    my_fname = my_fname.split(\"/\")[11]\r\n    prse = my_fname.split(\"_\")\r\n    sample = prse[1]; layer = re.sub(\"Layer\", \"\", prse[2])\r\n    crop = re.sub(\"crop\", \"\", prse[3])\r\n    lab = re.sub(\"(\\\\.tif|Astrocyte)\", \"\", prse[4])\r\n\r\n    # annotation text\r\n    plt.figtext(x = 0.52, y = 0.18, s = r\"$\\bf{Sample:~}$\" + sample + r\"$\\bf{~~~Layer:~}$\" + layer + r\"$\\bf{~~~Crop:~}$\" + crop + r\"$\\bf{~~~Number:~}$\" + lab + \"\\n\" + r\"$\\bf{Predicted:~}$\" + my_pred + \"\\n\" +  r\"$\\bf{Truth:~}$\" + my_lab + \"\\n\" + r\"$\\bf{Control\\ Probability:~}$\" + str(round(my_ctrl*100, 4)) + \"%\\n\" + r\"$\\bf{AD\\ Probability:~}$\" + str(round(my_ad*100, 4)) + \"%\\n\" + r\"$\\bf{Index:~}$\" + str(idx), fontsize = 18, linespacing = 2, ha = \"left\", va = \"top\")\r\n\r\n    for c in range(len(marker)):\r\n\r\n        # plot indexing\r\n        cl = [c]\r\n        x_idx = 0 if c < 5 else 4\r\n        y_idx = c % 5\r\n\r\n        # original image (with transforms)\r\n        _ = viz.visualize_image_attr(original[:, :, cl], original[:, :, cl], method = \"heat_map\", cmap = colormaps[c], title = r\"$\\bf{\" + marker[c] + r\"}$\", plt_fig_axis = (fig, axs[y_idx, 0 + x_idx]), use_pyplot = False)\r\n\r\n        # saliency gradient\r\n        _ = viz.visualize_image_attr(grads[:, :, cl], original[:, :, cl], method = \"masked_image\", sign = \"absolute_value\", show_colorbar = True, title = marker[c] + \" Gradient Magnitudes\", plt_fig_axis = (fig, axs[y_idx, 1 + x_idx]), use_pyplot = False)\r\n\r\n        # integrated gradient\r\n        if attr_ig[:, :, cl].sum() != 0: # if no signal\r\n            _ = viz.visualize_image_attr(attr_ig[:, :, cl], original[:, :, cl], method = \"blended_heat_map\", alpha_overlay = 0.85, sign = \"all\", show_colorbar = True, title = marker[c] + \" Integrated Gradients\", plt_fig_axis = (fig, axs[y_idx, 2 + x_idx]), use_pyplot = False)\r\n        else:\r\n            axs[y_idx, 2 + x_idx].set_visible(False)\r\n\r\n        # guided gradcam\r\n        _ = viz.visualize_image_attr(attr_gc[:, :, cl], original[:, :, cl], method = \"blended_heat_map\", alpha_overlay = 0.85, sign = \"absolute_value\", show_colorbar = True, title = marker[c] + \" Guided GradCAM\", plt_fig_axis = (fig, axs[y_idx, 3 + x_idx]), use_pyplot = False)\r\n\r\n    # remove axes\r\n    for remove in range(4,8):\r\n        axs[4, remove].set_visible(False)\r\n\r\n    # save figure\r\n    plt.savefig(results_dir + \"Model Interpretation/\" + re.sub(\".tif\", \"\", my_fname) + \"_Index\" + str(idx) + \".pdf\", bbox_inches=\"tight\")\r\n\r\nIdentify astrocytes with extreme classification probabilities.\r\n\r\ntop_n = 20\r\n\r\ntop_ad = dat.sort_values(\"ProbabilityAD\", ascending = False).head(top_n).index\r\ntop_ctrl = dat.sort_values(\"ProbabilityCTRL\", ascending = False).head(top_n).index\r\ntop_idx = top_ctrl.append(top_ad)\r\n\r\nprint(\"Top {} Alzheimer/Control Classifications:\".format(top_n))\r\ndat.iloc[top_idx]\r\n\r\nVisualize attribution functions for these astrocytes with extreme classification probabilities.\r\n\r\n%%capture\r\n\r\nfor i in top_idx:\r\n    try:\r\n        visualizeAttribution(*interpretAstrocyte(i))\r\n    except IndexError as e:\r\n        print(\"Failed to compute attribution for #\" + str(i) + \".\")\r\n\r\nPlot CNN Weights\r\nFor internal use only, plot CNN weights.\r\n\r\nfrom torchvision import utils\r\n\r\ndef visTensor(tensor, ch = 0, allkernels = False, nrow = 8, padding = 1): \r\n    n,c,w,h = tensor.shape\r\n\r\n    if allkernels: tensor = tensor.view(n*c, -1, w, h)\r\n    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\r\n\r\n    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \r\n    grid = utils.make_grid(tensor, nrow = nrow, normalize = True, padding = padding)\r\n    plt.figure(figsize = (nrow,rows))\r\n    plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\r\n\r\nApply the visTensor function to visualize the weights.\r\n\r\n%%capture\r\n\r\nweight_dir = results_dir + \"Weights/\"\r\n\r\nCNNlist = [CNN.conv1, CNN.conv2, CNN.conv3, CNN.conv4]\r\nmarker = [\"DAPI\", \"ALDH1L1\", \"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\",  \"GS\"]\r\nmlist = list(range(len(marker)))\r\n\r\nfor i, c in enumerate(CNNlist):\r\n\r\n    for m in mlist:\r\n\r\n        filter = c.weight.data.clone()\r\n        visTensor(filter, ch=m, allkernels = False)\r\n\r\n        plt.axis(\"off\")\r\n        plt.ioff()\r\n        plt.savefig(weight_dir + str(i+1) + \"_\" + marker[m] + \".png\", bbox_inches=\"tight\")\r\n        plt.show()\r\n\r\nSave Notebook\r\n\r\n# use time object imported above for loss/accuracy plot\r\ncname = base_dir + \"Code/CNN/2 - Astrocyte CNN.ipynb\"\r\nfname = results_dir + \"CNN Training/\" + \"{}.{}_{}.{}.{}_AstrocyteCNN.html\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\ncmd = 'jupyter nbconvert --to html ' + '\"' + cname + '\"' + ' --output ' + '\"' + fname + '\"'\r\n\r\n\r\n\r\n\r\nAkiba, Takuya, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019. “Optuna: A Next-Generation Hyperparameter Optimization Framework.” arXiv:1907.10902 [Cs, Stat], July. http://arxiv.org/abs/1907.10902.\r\n\r\n\r\nBergstra, James, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. “Algorithms for Hyper-Parameter Optimization.” Advances in Neural Information Processing Systems 24. https://proceedings.neurips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html.\r\n\r\n\r\nKingma, Diederik P., and Jimmy Ba. 2017. “Adam: A Method for Stochastic Optimization.” arXiv:1412.6980 [Cs], January. http://arxiv.org/abs/1412.6980.\r\n\r\n\r\nKokhlikyan, Narine, Vivek Miglani, Miguel Martin, Edward Wang, Jonathan Reynolds, Alexander Melnikov, Natalia Lunova, and Orion Reblitz-Richardson. 2019. “PyTorch Captum.” GitHub. https://github.com/pytorch/captum.\r\n\r\n\r\nPedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12 (85): 2825–30. http://jmlr.org/papers/v12/pedregosa11a.html.\r\n\r\n\r\nSundararajan, Mukund, Ankur Taly, and Qiqi Yan. 2017. “Axiomatic Attribution for Deep Networks.” arXiv:1703.01365 [Cs], June. http://arxiv.org/abs/1703.01365.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:18:55-07:00"
    },
    {
      "path": "data-visualization.html",
      "title": "Data Visualization",
      "description": "This R script creates several plots to visualize the data. Mixed effects regression models are also applied.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nDefine Plotting Functions\r\nMixed Effects Models\r\nDefine Iteration Functions\r\nCreate Plots\r\nDistance to Plaques\r\n\r\nDependencies\r\nLoad requisite packages and define directories.\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\nlibrary(ggpubr)\r\n\r\n# mixed effects model\r\nlibrary(lmerTest)\r\nlibrary(openxlsx)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\ndir6 = file.path(\"Results\", \"6 - Data Visualization\")\r\n\r\n\r\n\r\nLoad Data\r\nLoad processed ROI measurement data from the 4 - Spectral Clustering directory.\r\n\r\n\r\nall = readRDS(file.path(dir4, \"Z-Score Data.rds\"))\r\n\r\n\r\n\r\nDefine Plotting Functions\r\nDefine variables which contain theme options.\r\n\r\n\r\n# define theme options\r\nmarker_theme = theme(\r\n  plot.title = element_text(size = 16, hjust = 0.5, face = \"bold.italic\"),\r\n  \r\n  # axes\r\n  axis.title.y = element_text(size = 12, face = \"bold\"),\r\n  axis.title.x = element_blank(),\r\n  axis.text.x = element_text(size = 12, face = \"bold\", color = \"black\"),\r\n  axis.ticks.x = element_blank(),\r\n  \r\n  # panel\r\n  panel.background = element_rect(fill = \"#EBEBEB\"),\r\n  panel.border = element_rect(colour = \"black\", fill = NA, size = 0.8),\r\n  panel.grid = element_blank(),\r\n  \r\n  # legend\r\n  legend.title = element_text(size = 14, face = \"bold\"),\r\n  legend.text = element_text(size = 12),\r\n  legend.position = \"bottom\")\r\n\r\n\r\n# modify theme for proportions\r\nprop_theme = marker_theme + theme(\r\n  legend.position = \"right\",\r\n  plot.title = element_text(size = 16, hjust = 0.5, face = \"bold\"),\r\n  legend.text = element_text(size = 10, face = \"plain\"),\r\n  panel.grid.major.y = element_line(size = 0.4, color = \"#333333\"),\r\n  strip.text = element_text(size = 12, face = \"bold\", color = \"white\"),\r\n  strip.background = element_rect(color = \"black\", fill = \"#3D3D3D\",\r\n                                  size = 0.8, linetype = \"solid\"))\r\n\r\n# modify theme for bar graph\r\nbg_theme = prop_theme + theme(\r\n  panel.grid.major.y = element_line(size = 0.2, color = \"#333333\"),\r\n  panel.grid.minor.y = element_line(size = 0.2, color = \"#333333\"))\r\n\r\n\r\n# modify theme for histogram\r\nhist_theme = prop_theme + theme(\r\n  axis.text.x = element_text(size = 10, face = \"plain\", color = \"black\"),\r\n  axis.text.y = element_text(size = 10, face = \"plain\", color = \"black\"),\r\n  axis.ticks.x = element_line(size = 0.5, color = \"black\"),\r\n  axis.ticks.y = element_line(size = 0.5, color = \"black\"))\r\n\r\n\r\n# modify theme for density\r\ndensity_theme = hist_theme\r\n\r\n\r\n\r\nDefine plotting functions to visualize data by marker, state, and layer.\r\n\r\n\r\n# create boxplots for each marker\r\nplot_marker = function(dat, mx, grp, grpcol, legend = FALSE,\r\n                       fname = NULL, facet = NULL) {\r\n  \r\n  # base plot\r\n  marker_plot = ggplot(dat, aes(x = get(grp), y = get(mx), color = get(grp))) +\r\n    geom_boxplot() +\r\n    scale_color_manual(grp, values = levels(dat[[grpcol]])) + \r\n    ggtitle(mx) +\r\n    labs(x = grp, y = \"Mean Gray Intensity (MGI)\")\r\n  \r\n  # split by layer and assign appropriate theme\r\n  if(!is.null(facet)) {\r\n    marker_plot = marker_plot +\r\n      facet_wrap(. ~ Layer, nrow = 1,\r\n                 labeller = function(x) return(map(x, ~paste(\"Layer\", .x)))) +\r\n      prop_theme + theme(plot.title = element_text(size = 16, hjust = 0.5,\r\n                                                   face = \"bold.italic\"))\r\n  } else {\r\n    marker_plot = marker_plot + marker_theme\r\n  }\r\n  \r\n  # plot legend\r\n  if(!legend) { marker_plot = marker_plot + theme(legend.position = \"none\") }\r\n  \r\n  # save file\r\n  if(!is.null(fname)) { ggsave(paste0(fname, \".pdf\"), marker_plot, width = 4, height = 6) }\r\n  \r\n  # return modified plot\r\n  return(marker_plot + theme(axis.text.x = element_blank(), plot.margin = margin(0.5, 0.5, 0.5, 0.5, \"cm\")))\r\n  \r\n}\r\n\r\n# shared y-axis\r\nshared_y = function(p, idx, nwidth) {if((idx - 1) %% nwidth == 0) return(p) else return(p + rremove(\"ylab\"))}\r\n\r\n# arrange plots\r\narrange_plots = function(plist, leg, lab, grplab, nwidth = ceiling(length(plist)/2), nheight = ceiling(length(plist)/nwidth), title = TRUE) {\r\n  \r\n  # create shared y-axis per row\r\n  plist = imap(plist, ~shared_y(.x, .y, nwidth))\r\n  \r\n  # join plots together\r\n  composite = ggarrange(plotlist = plist, ncol = nwidth, nrow = nheight, legend.grob = leg, legend = \"bottom\")\r\n  \r\n  # add title\r\n  if(title) { composite = annotate_figure(composite, top = text_grob(paste(lab, \"Marker Expression by\", grplab), size = 20, face = \"bold\")) }\r\n  \r\n  # return composite\r\n  return(composite)\r\n  \r\n}\r\n\r\n\r\n\r\nPlot stacked boxplots where ROIs are split by Control/Alzheimer, then grouped by stratified Distance, Layer, or some other grouping variable. Relative proportions within each group are visualized.\r\n\r\n\r\nplot_prop = function(dat, grpvar, grpcol, lab, fname = NULL) {\r\n  \r\n  grpcols = c(grpvar, \"Condition\", \"State\", grpcol)\r\n  \r\n  # group by grouping variable\r\n  prop = dat %>%\r\n    .[, .N, by = grpcols] %>%\r\n    .[order(.[, ..grpcols]), ] %>%\r\n    .[, Proportion := map(.(N), ~.x*100/sum(N)), by = c(grpvar, \"Condition\")] %>%\r\n    .[, Label := paste0(round(Proportion, 1), \"%\")]\r\n  \r\n  if(grpvar == \"Layer\") { prop[, Layer := paste(\"Layer\", Layer)] }\r\n  \r\n  # plot proportions data\r\n  prop_plot = ggplot(prop, aes(x = get(grpvar), y = Proportion,\r\n                               fill = State, label = Label)) +\r\n    geom_bar(position = \"stack\", stat = \"identity\", width = 0.5,\r\n             color = \"black\", size = 0.4) +\r\n    facet_grid(. ~ Condition) +\r\n    scale_fill_manual(grpvar, values = levels(prop[[grpcol]])) +\r\n    scale_y_continuous(expand = expansion(mult = c(0, 0))) +\r\n    geom_text(size = 3, position = position_stack(vjust = 0.5)) +\r\n    # ggtitle(paste(lab, \"State Across\", grpvar)) +\r\n    labs(x = gsub(\"Bin\", \"\", grpvar), y = \"Proportion\", fill = \"State\") +\r\n    prop_theme\r\n  \r\n  if(!is.null(fname)) ggsave(paste0(fname, \".pdf\"), prop_plot, width = 14, height = 6) else return(prop_plot)\r\n  \r\n}\r\n\r\n\r\n\r\nPlot bargraph where ROIs are split by Control/Alzheimer, then grouped by stratified Distance, Layer, or some other grouping variable. Relative proportions within each phenotypic state are visualized (or, phenotypic state within the grouping variable; i.e., x-axis can be phenotypic state or other grouping variable).\r\n\r\n\r\nplot_bg = function(dat, grpvar, grpcol, lab, fname = NULL, xvar = \"State\") {\r\n  \r\n  grpcols = c(\"Condition\", xvar, grpvar, grpcol)\r\n  \r\n  # group by grouping variable\r\n  bg = dat %>%\r\n    .[, .N, by = grpcols] %>%\r\n    .[order(.[, ..grpcols]), ] %>%\r\n    .[, Proportion := map(.(N), ~.x*100/sum(N)), by = c(\"Condition\")] %>%\r\n    .[, Label := paste0(round(Proportion, 1), \"%\")] %>%\r\n    .[, Fraction :=  map(.(N), ~paste0(.x, \"/\", sum(N))), by = c(\"Condition\")]\r\n  \r\n  # plot proportions data\r\n  bg_plot = ggplot(bg, aes(x = get(xvar), y = Proportion,\r\n                           fill = get(grpvar), label = Fraction)) +\r\n    geom_bar(stat = \"identity\", position = position_dodge(0.6),\r\n             width = 0.4, color = \"black\", size = 0.4) +\r\n    facet_grid(. ~ Condition) +\r\n    scale_fill_manual(grpvar, values = levels(bg[[grpcol]])) + \r\n    scale_y_continuous(expand = expansion(mult = c(0, .1))) +\r\n    geom_text(size = 2.5, position = position_dodge(0.6), vjust = -1.5) +\r\n    # ggtitle(paste(lab, grpvar, \"Across State\")) +\r\n    labs(x = gsub(\"Bin\", \"\", xvar), y = \"Proportion\") +\r\n    bg_theme\r\n  \r\n  if(!is.null(fname)) ggsave(paste0(fname, \".pdf\"), bg_plot, width = 14, height = 6) else return(bg_plot)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to plot histogram of distance.\r\n\r\n\r\n# plot grouped density\r\nplot_density = function(dat, grpvar, grpcol, linecol, lab, maxlim) {\r\n  \r\n  density_plot = ggplot(dat, aes(x = get(grpvar), group = State)) +\r\n    geom_density(aes(fill = State), alpha = 0.5) +\r\n    scale_fill_manual(values = levels(dat[[grpcol]])) +\r\n    geom_density(color = \"black\", size = 0.3) +\r\n    # geom_density(aes(color = State)) +\r\n    # scale_color_manual(values = levels(dat[[linecol]])) +\r\n    labs(x = grpvar, y = \"Density\") +\r\n    scale_x_continuous(expand = c(0, 0), breaks = seq(0, 500, by = 50)) +\r\n    scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +\r\n    density_theme + theme(legend.position = \"none\")\r\n  \r\n  return(density_plot)\r\n  \r\n}\r\n\r\n\r\n# plot individual histogram\r\nplot_hist = function(dat, grpvar, grpcol, lab, stateidx = 1:3, legend = F,\r\n                     bin_width = 20, t_d = NULL, max_x = 500, max_y = 1) {\r\n  \r\n  hist_plot = ggplot(dat, aes(x = get(grpvar), fill = State)) +\r\n    geom_histogram(\r\n      aes(y = ..count../t_d),\r\n      # aes(y = ..density..),\r\n      breaks = seq(0, max(dat[, ..grpvar] + bin_width), by = bin_width),\r\n      position = \"identity\", size = 0.3,\r\n      color = \"black\") +\r\n    scale_fill_manual(values = levels(dat[[grpcol]])[stateidx]) +\r\n    # geom_density(fill = \"white\", alpha = 0.2) +\r\n    labs(x = grpvar, y = \"Proportion\", fill = \"State\") +\r\n    scale_x_continuous(limits = c(0, max_x), expand = c(0.02, 0.02)) +\r\n    scale_y_continuous(limits = c(0, max_y), \r\n                       expand = expansion(mult = c(0, 0.05))) +\r\n    facet_wrap(. ~ State, scales = \"free_y\") +\r\n    hist_theme + theme(legend.position = \"bottom\")\r\n  \r\n  if(legend) return(hist_plot) else return(hist_plot +\r\n                                             theme(legend.position = \"none\"))\r\n  \r\n}\r\n\r\n\r\n# get maximum y-value\r\nmax_y = function(dat, bin_width, t_d, total_denominator = F) {\r\n  \r\n  if(total_denominator) t_d = t_d[State == dat[1, State], N]\r\n  \r\n  dat = dat[, !c(\"State\")]\r\n  \r\n  maximum_y = dat %>%\r\n    { cut(.[[1]], breaks = seq(0, max(. + bin_width), by = bin_width),\r\n          include.lowest = T) } %>%\r\n    summary() %>% { ./t_d } %>% max() %>% return()\r\n  \r\n}\r\n\r\n\r\n# plot composite histograms\r\nplot_hists = function(my_dat, grpvar, grpcol, lab, fname = NULL,\r\n                      condvar = c(\"Control\", \"Alzheimer\"),\r\n                      smplvar = NULL,\r\n                      bin_width = 25, total_denominator = F) {\r\n  \r\n  if(!is.null(smplvar)) my_dat = my_dat[Sample %in% smplvar]\r\n  \r\n  # should the denominator be ALL astrocytes within Condition?\r\n  og_total_denominator = nrow(my_dat[Condition %in% condvar])\r\n  \r\n  # should the denominator be TOTAL Homeostatic astrocytes for Homeostatic plot,\r\n  # TOTAL Intermediate astrocytes for Intermeidate plot, etc. (within Condition)\r\n  og_state_denominator = my_dat[Condition %in% condvar, .N, by = \"State\"]\r\n  \r\n  # REMOVE crops WITHOUT plaques (but keep whole denominator)\r\n  dat = copy(my_dat) %>%\r\n    .[is.na(get(grpvar)), c(grpvar) := 500] %>%\r\n    .[get(grpvar) > 500, c(grpvar) := 500] %>%\r\n    .[Condition %in% condvar]\r\n  \r\n  # create density plot\r\n  density_plot = plot_density(dat, grpvar, grpcol, \"StateColors\",\r\n                              lab, maxlim)\r\n  \r\n  # get maximum x-value\r\n  max_x = max(dat[, ..grpvar], na.rm = T)\r\n  \r\n  # create individual histograms\r\n  if(total_denominator) {\r\n    \r\n    # get maximum y-value\r\n    max_y = dat[, max_y(.SD, bin_width, og_total_denominator, F),\r\n                  .SDcols = c(grpvar, \"State\"), by = \"State\"][, max(V1)]\r\n    \r\n    # plot histogram\r\n    hist_plots = imap(levels(dat[, State]),\r\n                      ~plot_hist(dat[State == .x], grpvar, grpcol, lab,\r\n                                 stateidx = .y, bin_width = bin_width,\r\n                                 t_d = og_total_denominator,\r\n                                 max_x = max_x, max_y = max_y))\r\n  \r\n  } else  { \r\n    \r\n    # get maximum value\r\n    max_y = dat[, max_y(.SD, bin_width, og_state_denominator, T),\r\n                  .SDcols = c(grpvar, \"State\"), by = \"State\"][, max(V1)]\r\n    \r\n    # plot histogram\r\n    hist_plots = imap(levels(dat[, State]),\r\n                      ~plot_hist(dat[State == .x], grpvar, grpcol, lab,\r\n                                 stateidx = .y, bin_width = bin_width,\r\n                                 t_d = og_state_denominator[State == .x, N],\r\n                                 max_x = max_x, max_y = max_y))\r\n  \r\n  }\r\n  \r\n  # get composite legend\r\n  hist_legend = get_legend(plot_hist(dat, grpvar, grpcol, lab, legend = T, t_d = nrow(dat)))\r\n  \r\n  # create composite histogram\r\n  comp_plot = arrange_plots(rev(hist_plots), hist_legend, nwidth = 3, title = F)\r\n  \r\n  # add density plot\r\n  comp_plot = ggarrange(density_plot, comp_plot, ncol = 1)\r\n  \r\n  # save or return plot\r\n  if(!is.null(fname)) ggsave(paste0(fname, \".pdf\"), comp_plot, width = 10, height = 8) else return(comp_plot)\r\n  \r\n}\r\n\r\n\r\n\r\nMixed Effects Models\r\nFunction to run mixed effects regression models.\r\n\r\n\r\nmixed_effects = function(dat, my_formula, model_name,\r\n                         ldir = NULL, marker = \"N/A\") {\r\n  \r\n  # run mixed model\r\n  my_model = lmerTest::lmer(my_formula, REML = T, data = dat)\r\n  my_summary = summary(my_model)\r\n  my_confint = confint(my_model)\r\n  \r\n  # get model results\r\n  mcols = c(\"Marker\", \"Model\", \"Comparison\", \"Estimate\", \"Pr(>|t|)\", \"Std. Error\")\r\n  \r\n  # model results\r\n  model_results = my_summary$coefficients %>%\r\n    as.data.table(keep.rownames = \"Comparison\") %>%\r\n    .[, Marker := ..marker] %>%\r\n    .[, Model := ..model_name] %>%\r\n    .[, .SD, .SDcols = mcols] %>%\r\n    merge(as.data.table(my_confint, keep.rownames = \"Comparison\"),\r\n          by = \"Comparison\")\r\n  \r\n  # write output\r\n  if(!is.null(ldir)) {\r\n    sink(file = ldir, append = T)\r\n    cat(\"\\n\", rep(\"_\", 80), sep = \"\")\r\n    cat(\"\\n\\n\\n>>>\", toupper(model_name), \"MODEL:\\n\\n\"); print(my_model)\r\n    cat(\"\\n\\n>>> SUMMARY:\\n\\n\"); print(my_summary)\r\n    cat(\"\\n\\n>>> CONFIDENCE INTERVALS:\\n\\n\"); print(my_confint)\r\n    sink()\r\n  }\r\n  \r\n  # change names and set order\r\n  setnames(model_results, c(\"2.5 %\", \"97.5 %\"), c(\"Lower CI\", \"Upper CI\"))\r\n  setcolorder(model_results, c(\"Marker\", \"Model\"))\r\n  return(model_results)\r\n  \r\n}\r\n\r\n# run multiple models per marker\r\nmixed_marker = function(marker, dat, mxdir) {\r\n  \r\n  # create file\r\n  ldir = file.path(mxdir, paste(marker, \"Mixed Effects Model.txt\"))\r\n  if(file.exists(ldir)) file.remove(ldir) else file.create(ldir)\r\n  \r\n  # log message\r\n  sink(file = ldir, append = T)\r\n  cat(\">>> MARKER: \", marker, \"\\n\", sep = \"\")\r\n  sink()\r\n  \r\n  # run model 1\r\n  m1 = mixed_effects(dat, get(marker) ~ State + (1|Sample), \"State\", ldir, marker)\r\n  m2 = mixed_effects(dat, get(marker) ~ Condition + (1|Sample), \"Condition\",\r\n                     ldir, marker)\r\n  \r\n  # final model results\r\n  mres = rbind(m1, m2)\r\n  \r\n  return(mres)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine Iteration Functions\r\nDefine function to create plots.\r\n\r\n\r\nplot_data = function(dat, lab, mx, pcols, pwb) {\r\n  \r\n  # create subdirectory if needed\r\n  wdir = file.path(dir6, lab)\r\n  mxdir = file.path(wdir, \"Mixed Effects Models\")\r\n  hdir = file.path(wdir, \"Distance Histograms\")\r\n  bgdir = file.path(wdir, \"Distance Bar Graphs\")\r\n  if(!dir.exists(wdir)) {dir.create(wdir); dir.create(mxdir);\r\n    dir.create(hdir); dir.create(bgdir)}\r\n  \r\n  # group None with > 50\r\n  hmdists = colnames(dat) %>% .[grep(\"Bin\", .)]\r\n  group_none = function(x) dat[get(x) == \"None\", c(x) := \"> 50 um\"]\r\n  walk(hmdists, group_none)\r\n  \r\n  # define plotting colors\r\n  dat = dat %>%\r\n    .[, StateColors := factor(State, labels = pcols$State)] %>%\r\n    .[, StatePastelColors := factor(State, labels = pcols$StatePastel)] %>%\r\n    .[, SampleColors := factor(Sample, labels = pcols$Sample)] %>%\r\n    .[, ConditionColors := factor(Condition, labels = pcols$Condition)] %>%\r\n    .[, ConditionPastelColors := factor(Condition,\r\n                                        labels = pcols$ConditionPastel)] %>%\r\n    .[, LayerColors := factor(Layer, labels = pcols$Layer)] %>%\r\n    .[, DistanceBinColors := factor(DistanceBin, labels = pcols$DistanceBin)]\r\n  \r\n  \r\n  ## MIXED EFFECTS MODELS\r\n  \r\n  # run models\r\n  mxef = map(mx, ~mixed_marker(.x, dat, mxdir))\r\n  mxef = rbindlist(mxef)\r\n  \r\n  # add distance mixed models\r\n  m3 = mixed_effects(dat, Distance ~ State + (1|Sample), \"Distance\")\r\n  m4 = mixed_effects(dat[Condition == \"Control\"],\r\n                     Distance ~ State + (1|Sample), \"Distance in CTRL\")\r\n  m5 = mixed_effects(dat[Condition == \"Alzheimer\"],\r\n                     Distance ~ State + (1|Sample), \"Distance in AD\")\r\n  \r\n  # bind mixed model data\r\n  mxef = rbind(mxef, m3, m4, m5)\r\n  \r\n  # write to file\r\n  brainstorm::add_worksheet(pwb, lab, mxef)\r\n  wb_colors = list(# State = \"#DCE5DF\", Condition = \"#E4DEDD\",\r\n    State = \"#BDDBC8\", Condition = \"#E2D0CA\",\r\n    Distance = \"#E0EAF5\", `Distance in CTRL` = \"#D1E0F0\", `Distance in AD` = \"#C1D6EB\")\r\n  iwalk(wb_colors, ~addStyle(pwb, lab, createStyle(fgFill = .x),\r\n                             rows = which(mxef$Model == .y) + 1,\r\n                             cols = 2, stack = T))\r\n  \r\n  ## SUMMARY PLOT\r\n  cond_dat = copy(dat) %>%\r\n    .[, .N, by = c(\"State\", \"Condition\")] %>%\r\n    .[order(.[, c(\"State\", \"Condition\")]), ] %>%\r\n    .[, Proportion := map(.(N), ~.x*100/sum(N)), by = c(\"Condition\")] %>%\r\n    .[, Label := paste0(round(Proportion, 1), \"%\")]\r\n  \r\n  state_dat = copy(dat) %>%\r\n    .[, .N, by = c(\"State\", \"Condition\")] %>%\r\n    .[order(.[, c(\"State\", \"Condition\")]), ] %>%\r\n    .[, Proportion := map(.(N), ~.x*100/sum(N)), by = c(\"State\")] %>%\r\n    .[, Label := paste0(round(Proportion, 1), \"%\")]\r\n  \r\n  \r\n  # plot proportions data\r\n  cond_plot = ggplot(cond_dat, aes(x = Condition, y = Proportion, fill = State, label = Label)) +\r\n    geom_bar(position = \"stack\", stat = \"identity\", ,\r\n             width = 0.5, color = \"black\", size = 0.4) +\r\n    scale_fill_manual(values = levels(dat[[\"StatePastelColors\"]])) + \r\n    scale_y_continuous(expand = expansion(mult = c(0, 0))) +\r\n    geom_text(size = 3, position = position_stack(vjust = 0.5)) +\r\n    labs(x = \"Condition\", y = \"Proportion\") +\r\n    bg_theme + theme(legend.position = \"none\")\r\n  \r\n  # plot proportions data\r\n  state_plot = ggplot(state_dat, aes(x = State, y = Proportion, fill = Condition, label = Label)) +\r\n    geom_bar(position = \"stack\", stat = \"identity\", ,\r\n             width = 0.5, color = \"black\", size = 0.4) +\r\n    scale_fill_manual(values = levels(dat[[\"ConditionPastelColors\"]])) + \r\n    scale_y_continuous(expand = expansion(mult = c(0, 0))) +\r\n    geom_text(size = 3, position = position_stack(vjust = 0.5)) +\r\n    labs(x = \"State\", y = \"Proportion\") +\r\n    bg_theme + theme(legend.position = \"none\")\r\n  \r\n  comb_plot = ggarrange(cond_plot, state_plot, ncol = 1)\r\n  \r\n   ggsave(file.path(wdir, \"Proportions Summary.pdf\"), comb_plot, width = 4, height = 12)\r\n  \r\n  \r\n  ## CONDITION/STATE BOXPLOTS\r\n  \r\n  # create boxplots\r\n  condition_plots = map(mx, ~plot_marker(dat, .x, \"Condition\", \"ConditionColors\"))\r\n  state_plots = map(mx, ~plot_marker(dat, .x, \"State\", \"StateColors\"))\r\n  \r\n  # get legends\r\n  condition_legend = get_legend(plot_marker(dat, mx[1], \"Condition\", \"ConditionColors\", legend = TRUE))\r\n  state_legend = get_legend(plot_marker(dat, mx[1], \"State\", \"StateColors\", legend = TRUE))\r\n  \r\n  # create composite plots\r\n  ggsave(file.path(wdir, \"Marker Expression by Condition.pdf\"), arrange_plots(condition_plots, condition_legend, lab, \"Condition\"),\r\n         width = ceiling(length(mx)/2)*3, height = 10)\r\n  \r\n  ggsave(file.path(wdir, \"Marker Expression by State.pdf\"), arrange_plots(state_plots, state_legend, lab, \"State\"),\r\n         width = ceiling(length(mx)/2)*3, height = 10)\r\n  \r\n  \r\n  ## LAYER BOXPLOTS\r\n  \r\n  # create boxplots\r\n  layer_condition_plots = map(mx, ~plot_marker(dat, .x, \"Condition\", \"ConditionColors\", facet = \"Layer\"))\r\n  layer_state_plots = map(mx, ~plot_marker(dat, .x, \"State\", \"StateColors\", facet = \"Layer\"))\r\n  \r\n  # get legends\r\n  layer_condition_legend = get_legend(plot_marker(dat, mx[1], \"Condition\", \"ConditionColors\", legend = TRUE, facet = \"Layer\"))\r\n  layer_state_legend = get_legend(plot_marker(dat, mx[1], \"State\", \"StateColors\", legend = TRUE, facet = \"Layer\"))\r\n  \r\n  # create composite plots\r\n  ggsave(file.path(wdir, \"Marker Expression by Condition per Layer.pdf\"),\r\n         arrange_plots(layer_condition_plots, layer_condition_legend, lab,\r\n                       \"Condition per Layer\", nwidth = 2),\r\n         width = 24, height = length(mx)*3)\r\n  \r\n  ggsave(file.path(wdir, \"Marker Expression by State per Layer.pdf\"),\r\n         arrange_plots(layer_state_plots, layer_state_legend, lab,\r\n                       \"State per Layer\", nwidth = 2),\r\n         width = 24, height = length(mx)*3)\r\n\r\n  \r\n  ## BAR GRAPHS\r\n  \r\n  # define distance metrics\r\n  dists = c(\"Distance\")\r\n  \r\n  # plot bar graphs for state\r\n  walk(dists, ~plot_bg(dat, \"State\", \"StatePastelColors\", lab, file.path(bgdir, paste(\"State Within\", .x)), paste0(.x, \"Bin\")))\r\n  \r\n  # plot bar graphs for distance\r\n  walk(dists, ~plot_bg(dat, paste0(.x, \"Bin\"), \"DistanceBinColors\", lab, file.path(bgdir, paste(.x, \"Within State\")), \"State\"))\r\n  \r\n  \r\n  ## HISTOGRAMS\r\n  \r\n  walk(dists, ~plot_hists(dat, .x, \"StatePastelColors\", lab, fname = file.path(hdir, paste(.x, \"in Select CTRL with Total Denominator\")), condvar = c(\"Control\"), smplvar = c(\"2169\", \"2250\"), bin_width = 25, total_denominator = T))\r\n  \r\n  walk(dists, ~plot_hists(dat, .x, \"StatePastelColors\", lab, fname = file.path(hdir, paste(.x, \"in CTRL with Total Denominator\")), condvar = c(\"Control\"), bin_width = 25, total_denominator = T))\r\n  \r\n      walk(dists, ~plot_hists(dat, .x, \"StatePastelColors\", lab, fname = file.path(hdir, paste(.x, \"in AD with Total Denominator\")), condvar = c(\"Alzheimer\"), bin_width = 25, total_denominator = T))\r\n    \r\n  # return data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nCreate Plots\r\nCreate the plots specified in plot_data by mapping over all.\r\n\r\n\r\n# define markers of interest\r\nmarkers = list(\r\n  Astrocyte = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"),\r\n  Microglia = c(\"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"),\r\n  Vessel = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"))\r\n\r\n# define distance colors\r\ndistcols = c('< 25 um' = \"#FFAF85\", '25-50 um' = \"#FFED85\", '> 50 um' = \"#96BDD9\")\r\n\r\n# define color palette\r\ncols = list(\r\n  DistanceBin = distcols,\r\n  Layer = c(II = \"#DDF2B2\", III = \"#8DD2B9\", IV = \"#39AEC3\", V = \"#2072B1\", VI = \"#0C2C84\"),\r\n  Sample = c('1190' = \"#A6CEE3\", '1301' = \"#5D9FC9\", '1619' = \"#2A7FB0\", '1684' = \"#79B79A\", '1820' = \"#9ED57B\", '2124' = \"#5AB348\", '2148' = \"#619E45\", '2157' = \"#CC9B7F\", '2169' = \"#F37272\", '2191' = \"#E62D2F\", '2207' = \"#ED593B\", '2242' = \"#FBB268\", '2250' = \"#FDA13B\", '2274' = \"#FF7F00\"),\r\n  Condition = c(Control = \"#377EB8\", Alzheimer = \"#CE6D8B\"),\r\n  State = c('Homeostatic' = \"#39B200\", 'Intermediate' = \"#F0C808\", 'Reactive' = \"#960200\"),\r\n  StatePastel = c('Homeostatic' = \"#9ECC7F\", 'Intermediate' = \"#EADA86\", 'Reactive' = \"#B67977\"),\r\n  ConditionPastel = c(Control = \"#B0C6DE\", Alzheimer = \"#E4C2CC\")\r\n)\r\n\r\n# create plots\r\nwb = createWorkbook()\r\nplots = imap(all, ~plot_data(.x, .y, markers[[.y]], cols, wb))\r\nsaveWorkbook(wb, file.path(dir6, \"Mixed Effects Models.xlsx\"), overwrite = TRUE)\r\n\r\n\r\n\r\nDistance to Plaques\r\nNow, get summary statistics for distance to plaques to compute Chi-squared test.\r\n\r\n\r\ncount_distance = function(dat, lab, pwb) {\r\n  \r\n  # create data frames\r\n  close_plaques = dat[Distance <= 50, .N, by = c(\"Condition\", \"State\")]\r\n  far_plaques = dat[Distance > 50 | is.na(Distance), .N,\r\n                    by = c(\"Condition\", \"State\")]\r\n  \r\n  # set names\r\n  setnames(close_plaques, \"N\", \"Close to Plaques/Tangles\")\r\n  setnames(far_plaques, \"N\", \"Far from Plaques/Tangles\")\r\n  \r\n  # merge data\r\n  pdata = merge(close_plaques, far_plaques, by = c(\"Condition\", \"State\"), sort = F)\r\n  \r\n  # add to Excel\r\n  brainstorm::add_worksheet(pwb, lab, pdata)\r\n  \r\n}\r\n\r\n\r\n\r\nGet summary statistics by mapping over all.\r\n\r\n\r\n# create plots\r\nplaque_wb = createWorkbook()\r\nplots = imap(all, ~count_distance(.x, .y, plaque_wb))\r\nsaveWorkbook(plaque_wb, file.path(dir6, \"Distance to Neuropathology Proportions.xlsx\"), overwrite = TRUE)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:19:36-07:00"
    },
    {
      "path": "dimensionality-reduction.html",
      "title": "Dimensionality Reduction",
      "description": "This R script performs dimensionality reduction and identifies representative astrocytes/microglia in each phenotypic cluster.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nDefine Plotting Functions\r\nRepresentative Crops\r\nDefine t-SNE Function\r\nPerform t-SNE\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that three packages are sourced from GitHub: coolbutuseless/ggblur to create the background blur, eliocamp/ggnewscale to use multiple scales (see this post) in a single plot, and my personal utilities package, ayushnoori/brainstorm.\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# t-SNE\r\nlibrary(Rtsne)\r\nlibrary(ggplot2)\r\n\r\n# convex hull, blur, and multiple scales\r\nlibrary(ggblur)\r\nlibrary(ggnewscale)\r\n\r\n# read TIFF files\r\nlibrary(tiff)\r\nlibrary(RColorBrewer)\r\nlibrary(pheatmap)\r\nlibrary(ggpubr)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"3 - ROIs\")\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\ndir5 = file.path(\"Results\", \"5 - Dimensionality Reduction\")\r\n\r\n# set seed\r\nset.seed(1234)\r\n\r\n\r\n\r\nLoad Data\r\nLoad processed ROI measurement data from the 4 - Spectral Clustering directory.\r\n\r\n\r\nall = readRDS(file.path(dir4, \"Z-Score Data.rds\"))\r\n\r\n\r\n\r\nLoad and process GBM data.\r\n\r\n\r\nstate_cols = c(\"Homeostatic\", \"Intermediate\", \"Reactive\")\r\ntmp = fread(\"Results/7 - Gradient Boosting Machines/State/Astrocyte/GBM Probabilities.csv\")[, Max := pmap(.SD, ~which.max(as.numeric(c(...)))), .SDcols = state_cols ][, Max := factor(Max, levels = c(1, 2, 3), labels = state_cols)]\r\n\r\ntmp_h = tmp[State == \"Homeostatic\"]\r\n\r\n\r\n\r\nDefine Plotting Functions\r\nDefine plotting functions for t-distributed stochastic neighbor embedding (t-SNE) data.\r\n\r\n\r\n# plot t-SNE data\r\nplot_tsne = function(tsne, grp, grpcol, group, fname,\r\n                     area = NULL, areacol = NULL,\r\n                     PCA = FALSE, highlight = NULL, highlight_col = NULL) {\r\n  \r\n  tsne_plot = if(PCA) ggplot(tsne, aes(x = PC1, y = PC2)) else ggplot(tsne, aes(x = TSNE1, y = TSNE2))\r\n  \r\n  if(!is.null(area)) {\r\n    \r\n    tsne_plot = tsne_plot +\r\n      geom_point_blur(data = tsne, mapping = aes(color = get(area), fill = get(area)), blur_size = 30, blur_steps = 20) +\r\n      scale_color_manual(area, values = levels(tsne[[areacol]])) +\r\n      scale_fill_manual(area, values = levels(tsne[[areacol]])) +\r\n      new_scale_fill()\r\n\r\n  }\r\n  \r\n  tsne_plot = tsne_plot + \r\n    geom_point(data = tsne, mapping = aes(fill = get(grp)), shape = 21, color = \"black\", stroke = 0.1, alpha = 0.8) +\r\n    scale_fill_manual(grp, values = levels(tsne[[grpcol]])) +\r\n    theme(\r\n        plot.title = element_text(hjust = 0.5, size=16, face = \"bold\"),\r\n        axis.title.x = element_text(size=12, face = \"bold\"),\r\n        axis.title.y = element_text(size=12, face = \"bold\"),\r\n        legend.title = element_text(size=12, face = \"bold\"),\r\n        legend.position = \"right\")\r\n  \r\n  if(PCA) {\r\n    tsne_plot = tsne_plot + ggtitle(paste(group, \"PCA Plot\")) +\r\n      labs(x = \"PC1\", y = \"PC2\")\r\n  } else {\r\n    tsne_plot = tsne_plot + ggtitle(paste(group, \"t-SNE Plot\")) +\r\n      labs(x = \"t-SNE 1\", y = \"t-SNE 2\")\r\n  }\r\n  \r\n  if(!is.null(highlight)) {\r\n    tsne_plot = tsne_plot +\r\n      geom_point(data = tsne[ID %in% highlight], fill = highlight_col, shape = 21, color = \"black\", stroke = 0.1, alpha = 1)\r\n  }\r\n  \r\n  ggsave(paste0(fname, \".pdf\"), tsne_plot, width = 8, height = 6)\r\n  \r\n}\r\n\r\n\r\n\r\nRepresentative Crops\r\nFunction to retrieve and plot TIFF images.\r\n\r\n\r\n# generate color palette\r\ngenerate_colors = function(col) {\r\n  cols = colorRampPalette(c(\"#FFFFFF\", col))(100)\r\n  cols[1] = \"#0A0A0A\"\r\n  return(cols)\r\n}\r\n\r\n# plot TIFF from ID\r\nplot_tiff = function(dat, my_ID, mx, sel = c(\"Correlation\", \"Distance\")) {\r\n \r\n  # get disease abbreviation\r\n  dislab = factor(dat[ID == my_ID, Condition], levels = c(\"Control\", \"Alzheimer\"),\r\n                  labels = c(\"CTRL\", \"AD\"))\r\n  \r\n  # get file path\r\n  fpath = file.path(ddir, dat[ID == my_ID, file.path(dislab, paste0(Sample, \"_Layer\", Layer, \"_crop\", Crop), paste(Group, \"ROIs\"), paste0(dislab, \"_\", ID, \".tif\"))])\r\n  \r\n  # read TIFF file\r\n  my_tiff = suppressWarnings(readTIFF(fpath, all = T, info = T, as.is = T)) %>%\r\n   { if(length(dim(.[[1]])) > 2) map(., \\(x) x[,,1] + x[,,2] + x[,,3]) else . }\r\n  \r\n  # set labels\r\n  tiff_lab = c(\"DAPI\", \"ALDH1L1\", \"IBA1\", \"GFAP\", \"MHC2\", \"TSPO\", \"EAAT2\", \"TMEM119\", \"CD68\", \"EAAT1\", \"VIM\", \"FTL\", \"YKL40\", \"GS\", \"HuCD\", \"ABETA\", \"PHF1\")\r\n  names(my_tiff) = tiff_lab\r\n  \r\n  # set color palette\r\n  tiff_cols = rep_len(c(\"#064789\", \"#D33E43\", \"#65A48F\", \"#DC6ACF\", \"#009FB7\", \"#F18805\", \"#88726D\", \"#A05CFF\"), length(my_tiff))\r\n  names(tiff_cols) = names(my_tiff)\r\n  \r\n  # select labels/colors\r\n  my_tiff = my_tiff[mx]\r\n  tiff_cols = tiff_cols[mx]\r\n  \r\n  # generate scale\r\n  my_breaks = unlist(my_tiff) %>% { seq(from = 0, to = max(.),\r\n                                               length.out = 101) }\r\n  \r\n  # plot images\r\n  my_img = imap(my_tiff, ~pheatmap(.x, main = .y,\r\n                                   color = generate_colors(tiff_cols[[.y]]),\r\n                                   breaks = my_breaks,\r\n                                   border_color = NA,\r\n                                   cluster_rows = F, cluster_cols = F,\r\n                                   legend = F, silent = T))\r\n  \r\n  # set annotation color\r\n  annot_col = if(dislab == \"AD\") \"#D33E43\" else \"#65A48F\"\r\n  \r\n  # aggregate plots\r\n  my_grobs = map(my_img, ~.[[4]])\r\n  comp_img = ggarrange(plotlist = my_grobs, nrow = 1) %>%\r\n    annotate_figure(top = text_grob(dat[ID == my_ID, paste0(Sample, \" Layer \", Layer, \" Crop \", Crop, \", \", Group, \" #\", Number, \": \", round(.SD, 4)), .SDcols = sel], color = annot_col, face = \"bold\", size = 14)) %>%\r\n    {. + theme(plot.margin = margin(t = 0.2, b = 0.2, unit = \"in\"))}\r\n  \r\n  return(comp_img)\r\n  \r\n}\r\n\r\n\r\n\r\nIdentify representative crops in each state across all cell-types (i.e., groups).\r\n\r\n\r\n# function to compute distance\r\ncentroid_distance = function(pc1, pc2, ct1, ct2) {\r\n  return(sqrt((ct1 - pc1)^2 + (ct2 - pc2)^2))\r\n}\r\n\r\n# identify centroid crops\r\ncentroid_crops = function(dat, full_dat, mx, ctdir, lab, ncrops = 10) {\r\n  \r\n  # find state\r\n  my_state = dat[1, State]\r\n  message(lab, \" Centroid Crops: \", my_state)\r\n  \r\n  # calculate centroid\r\n  ctx = dat[, mean(PC1)]; cty = dat[, mean(PC2)]\r\n  \r\n  # compute distances to centroid, rank by least distance\r\n  dat = copy(dat) %>%\r\n    .[, CentroidDistance := pmap_dbl(dat[, .(PC1, PC2)],\r\n                                ~centroid_distance(.x, .y, ctx, cty))] %>%\r\n    setcolorder(c(\"ID\", \"CentroidDistance\")) %>%\r\n    .[order(CentroidDistance), ]\r\n  \r\n  # write to file\r\n  fwrite(dat, file = file.path(ctdir, paste(my_state, \"Centroid Crops.csv\")))\r\n  \r\n  # plot PCA with highlights\r\n  plot_tsne(full_dat, \"State\", \"PCAColors\", lab,\r\n            file.path(ctdir, paste(my_state, \"PCA Plot\")), PCA = TRUE,\r\n            highlight = dat[1:ncrops, ID], highlight_col = dat[1, StateColors])\r\n  \r\n  # select markers to plot\r\n  plot_mx = if(lab == \"Microglia\") c(\"DAPI\", \"IBA1\", mx) else c(\"DAPI\", \"ALDH1L1\", mx)\r\n  \r\n  # create composite images for top 10 ROIs\r\n  imgs = map(dat[1:ncrops, ID], ~plot_tiff(dat, .x, plot_mx, \"CentroidDistance\"))\r\n  comp_imgs = ggarrange(plotlist = imgs, ncol = 1, nrow = 6)\r\n  \r\n  # save plots to multiple pages\r\n  ggexport(comp_imgs, filename = file.path(ctdir, paste(my_state, \"Centroid Crops.pdf\")), width = 8.5, height = 11)\r\n  \r\n  # save plots\r\n  ggsave(file.path(ctdir, paste(my_state, \"Centroid Crops.pdf\")), width = length(plot_mx), height = 1.4*ncrops + 4, limitsize = F)\r\n  \r\n  # return data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nIdentify most extreme crops.\r\n\r\n\r\n# function to compute distance\r\npca_distance = function(pc1, pc2, other_dat) {\r\n    \r\n  other_dat %>%\r\n    .[, DistancePCA := sqrt((PC1 - pc1)^2 + (PC2 - pc2)^2)] %>%\r\n    .[, sum(DistancePCA)] %>% return()\r\n  \r\n}\r\n\r\n# identify extreme crops\r\nextreme_crops = function(dat, full_dat, mx, exdir, lab, ncrops = 10) {\r\n  \r\n  # find state\r\n  my_state = dat[1, State]\r\n  other_dat = full_dat[State != my_state, ]\r\n  message(lab, \" Extreme Crops: \", my_state)\r\n  \r\n  # compute sum PCA distances\r\n  dat = copy(dat) %>%\r\n    .[, PCADistance := pmap_dbl(dat[, .(PC1, PC2)],\r\n                                ~pca_distance(.x, .y, other_dat))] %>%\r\n    setcolorder(c(\"ID\", \"PCADistance\")) %>%\r\n    .[order(-PCADistance), ]\r\n  \r\n  # write to file\r\n  fwrite(dat, file = file.path(exdir, paste(my_state, \"Extreme Crops.csv\")))\r\n  \r\n  # plot PCA with highlights\r\n  plot_tsne(full_dat, \"State\", \"PCAColors\", lab,\r\n            file.path(exdir, paste(my_state, \"PCA Plot\")), PCA = TRUE,\r\n            highlight = dat[1:ncrops, ID], highlight_col = dat[1, StateColors])\r\n  \r\n  # select markers to plot\r\n  plot_mx = if(lab == \"Microglia\") c(\"DAPI\", \"IBA1\", mx) else c(\"DAPI\", \"ALDH1L1\", mx)\r\n  \r\n  # create composite images for top 10 ROIs\r\n  imgs = map(dat[1:ncrops, ID], ~plot_tiff(dat, .x, plot_mx, \"PCADistance\"))\r\n  comp_imgs = ggarrange(plotlist = imgs, ncol = 1, nrow = 6)\r\n  \r\n  # save plots to multiple pages\r\n  ggexport(comp_imgs, filename = file.path(exdir, paste(my_state, \"Extreme Crops.pdf\")), width = 8.5, height = 11)\r\n  \r\n  # return data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine t-SNE Function\r\nDefine function to perform t-SNE. Note that Rtsne::normalize_input is not called as coordinates (i.e., z-scores) are not very large. The argument do_PCA is currently NOT utilized (included for consistency) as the resulting principal components are used to identify the most extreme astrocytes, or those closest to the centroid.\r\n\r\n\r\napply_tsne = function(dat, lab, mx, pcols, do_TSNE = TRUE, do_PCA = TRUE) {\r\n  \r\n  # create subdirectories if needed\r\n  wdir = file.path(dir5, lab)\r\n  ctdir = file.path(wdir, \"Centroid Crops\")\r\n  exdir = file.path(wdir, \"Extreme Crops\")\r\n  if(!dir.exists(wdir)) { dir.create(wdir); dir.create(ctdir); dir.create(exdir) }\r\n  \r\n  # define plotting colors\r\n  dat = dat %>%\r\n    .[, StateColors := factor(State, labels = pcols$State)] %>%\r\n    .[, SampleColors := factor(Sample, labels = pcols$Sample)] %>%\r\n    .[, ConditionColors := factor(Condition, labels = pcols$Condition)] %>%\r\n    .[, PCAColors := factor(State, labels = pcols$PCA)]\r\n  \r\n  if(do_TSNE) {\r\n\r\n    # perform t-SNE\r\n    res = Rtsne(dat[, ..mx], verbose = TRUE, pca = FALSE,\r\n                normalize = FALSE, theta = 0)\r\n    res = as.data.table(res$Y)[, .(ID = dat$ID, TSNE1 = V1, TSNE2 = V2)]\r\n  \r\n    # join data with t-SNE results\r\n    dat = merge(dat, res, all = TRUE,  by = \"ID\")\r\n    \r\n    # plot t-SNE results\r\n    plot_tsne(dat, \"State\", \"StateColors\", lab,\r\n              file.path(wdir, \"State t-SNE Plot\"))\r\n    plot_tsne(dat, \"Sample\", \"SampleColors\", lab,\r\n              file.path(wdir, \"Sample t-SNE Plot\"))\r\n    plot_tsne(dat, \"Condition\", \"ConditionColors\", lab,\r\n              file.path(wdir, \"Condition t-SNE Plot\"))\r\n    \r\n    # plot combination t-SNE plots\r\n    plot_tsne(dat, \"Condition\", \"ConditionColors\", lab,\r\n              file.path(wdir, \"Condition + State t-SNE Plot\"),\r\n              \"State\", \"StateColors\")\r\n    plot_tsne(dat, \"State\", \"StateColors\", lab,\r\n              file.path(wdir, \"State + Condition t-SNE Plot\"),\r\n              \"Condition\", \"ConditionColors\")\r\n  \r\n  }\r\n  \r\n  # perform PCA\r\n  res_pca = as.data.frame(dat[, ..mx]) %>%\r\n    magrittr::set_rownames(dat[, ID]) %>%\r\n    prcomp() %>% .$x %>%\r\n    as.data.table(keep.rownames = \"ID\") %>%\r\n    .[, .(ID, PC1, PC2)]\r\n  \r\n  # join data with PCA results\r\n  dat = merge(dat, res_pca, by = \"ID\")\r\n  \r\n  # plot PCA results\r\n  plot_tsne(dat, \"State\", \"StateColors\", lab,\r\n            file.path(wdir, \"State PCA Plot\"), PCA = TRUE)\r\n  plot_tsne(dat, \"Sample\", \"SampleColors\", lab,\r\n            file.path(wdir, \"Sample PCA Plot\"), PCA = TRUE)\r\n  plot_tsne(dat, \"Condition\", \"ConditionColors\", lab,\r\n            file.path(wdir, \"Condition PCA Plot\"), PCA = TRUE)\r\n  \r\n  # compute centroid crops by phenotypic state\r\n  dat = dat[, centroid_crops(.SD, dat, mx, ctdir, lab, ncrops = 50),\r\n            .SDcols = colnames(dat), by = \"State\"][, -1]\r\n  \r\n  # compute extreme crops by phenotypic state\r\n  dat = dat[, extreme_crops(.SD, dat, mx, exdir, lab, ncrops = 50),\r\n            .SDcols = colnames(dat), by = \"State\"][, -1]\r\n  \r\n  # return data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nPerform t-SNE\r\nPerform t-SNE by mapping over all. Also, identify representative crops.\r\n\r\n\r\n# define markers of interest\r\nmarkers = list(Astrocyte = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\",\r\n                             \"EAAT1\", \"EAAT2\", \"GS\"),\r\n               Microglia = c(\"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"),\r\n               Vessel = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"))\r\n\r\n# define color palette\r\ncols = list(\r\n  Sample = c('1190' = \"#A6CEE3\", '1301' = \"#5D9FC9\", '1619' = \"#2A7FB0\", '1684' = \"#79B79A\", '1820' = \"#9ED57B\", '2124' = \"#5AB348\", '2148' = \"#619E45\", '2157' = \"#CC9B7F\", '2169' = \"#F37272\", '2191' = \"#E62D2F\", '2207' = \"#ED593B\", '2242' = \"#FBB268\", '2250' = \"#FDA13B\", '2274' = \"#FF7F00\"),\r\n  Condition = c(Control = \"#377EB8\", Alzheimer = \"#CE6D8B\"),\r\n  State = c('Homeostatic' = \"#39B200\", 'Intermediate' = \"#F0C808\", 'Reactive' = \"#960200\"),\r\n  PCA = c('Homeostatic' = \"#EAFCE2\", 'Intermediate' = \"#FCF9E9\", 'Reactive' = \"#FCE0E0\")\r\n  )\r\n\r\n# perform t-SNE\r\ntsne = imap(all, ~apply_tsne(.x, .y, markers[[.y]], cols,\r\n                             do_TSNE = FALSE, do_PCA = TRUE))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:19:55-07:00"
    },
    {
      "path": "gbm-condition.html",
      "title": "Gradient Boosting Machines by Condition",
      "description": "This R script trains gradient boosting machines (GBM) models to perform the binary condition classification task (i.e., predict CTRL vs. AD).\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nMerge Data\r\nTrain GBM Model\r\nPerform Machine Learning\r\n\r\nDependencies\r\nLoad requisite packages and define directories.\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\n\r\n# fast file system operations\r\nlibrary(fs)\r\n\r\n# gradient boosted machines\r\nlibrary(caret)\r\nlibrary(gbm)\r\n\r\n# ROC curve\r\nlibrary(pROC)\r\nlibrary(plotROC)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# create file structure\r\ncelltypes = c(\"Astrocyte\", \"Microglia\", \"Vessel\") %>% purrr::set_names()\r\n\r\n# set directories\r\nddir = file.path(\"Results\", \"CNN\", \"1.1 - Condition Partition\")\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\ndir7 = file.path(\"Results\", \"7 - Gradient Boosting Machines\", \"Condition\")\r\n\r\n# create directory\r\nif(!dir.exists(dir7)) {dir.create(dir7)}\r\n\r\n# set seed\r\nset.seed(1234)\r\n\r\n\r\n\r\nLoad Data\r\nLoad processed ROI measurement data from the 4 - Spectral Clustering directory. Note that this script uses the same train/test/validation split as the convolutional neural network (CNN) by loading the data object created by the CNN/1 - Partition ROIs script.\r\n\r\n\r\nall = readRDS(file.path(dir4, \"Z-Score Data.rds\"))\r\nsplit = readRDS(file.path(ddir, \"ROI Partition by Condition.rds\"))\r\n\r\n\r\n\r\nMerge Data\r\nDefine function to merge ROI measurement data with the predetermined train/test/validation split.\r\n\r\n\r\n# function to parse and merge data\r\nmerge_data = function(allx, splitx) {\r\n  \r\n  # parse split data\r\n  splitx = splitx %>%\r\n    .[, ID := gsub(\"(\\\\.tif|AD_|CTRL_)\", \"\", Name)] %>%\r\n    .[, .(ID, Partition)]\r\n\r\n  # merge data\r\n  allx = merge(allx, splitx, by = \"ID\", all.x = TRUE, all.y = FALSE)\r\n  return(allx)\r\n  \r\n}\r\n\r\n\r\n\r\nMap function over data objects for cell-types with CNN output data.\r\n\r\n\r\n# function to parse and merge data\r\nall = map(celltypes, ~merge_data(all[[.x]], split[[.x]]))\r\n\r\n\r\n\r\nTrain GBM Model\r\nDefine function to plot ROC curves.\r\n\r\n\r\n# function to plot ROC\r\nplot_roc = function(dat, truth, prob, auc_lab) {\r\n  \r\n  # print AUC\r\n  cat(paste0(auc_lab, \"\\n\"))\r\n  \r\n  # plot ROC curve\r\n  p = ggplot(dat, aes(d = get(truth), m = get(prob))) +\r\n    ggtitle(\"Gradient Boosting Machines ROC\") +\r\n    geom_abline(aes(intercept = 0, slope = 1, color = \"AUC = 0.5\"), linetype = \"dashed\", size = 1)+\r\n    geom_roc(aes(color = auc_lab), labels = FALSE, pointsize = 0) +\r\n    geom_roc(linealpha = 0, n.cuts = 12, labelround = 2, labelsize = 3) +\r\n    scale_colour_manual(values = c(\"#FF9B71\", \"#63B0CD\")) +\r\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", color = \"Area Under the Curve (AUC)\", subtitle = auc_lab) + theme_bw() +\r\n    theme(plot.title = element_text(size = 16, face = \"bold\"),\r\n          plot.subtitle = element_text(face = \"italic\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=12),\r\n          legend.position = c(0.72, 0.14),\r\n          legend.background = element_rect(fill = \"white\", color = \"black\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nFunction to plot multiple ROC curves including single-marker data.\r\n\r\n\r\n# function to plot multiple ROC curves\r\nplot_roc = function(dat, truth, prob, auc_lab) {\r\n  \r\n  # print AUC\r\n  cat(paste0(auc_lab, \"\\n\"))\r\n  \r\n  # plot ROC curve\r\n  p = ggplot(dat, aes(d = get(truth), m = get(prob))) +\r\n    ggtitle(\"Gradient Boosting Machines ROC\") +\r\n    geom_abline(aes(intercept = 0, slope = 1, color = \"AUC = 0.5\"), linetype = \"dashed\", size = 1)+\r\n    geom_roc(aes(color = auc_lab), labels = FALSE, pointsize = 0) +\r\n    geom_roc(linealpha = 0, n.cuts = 12, labelround = 2, labelsize = 3) +\r\n    scale_colour_manual(values = c(\"#FF9B71\", \"#63B0CD\")) +\r\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", color = \"Area Under the Curve (AUC)\", subtitle = auc_lab) + theme_bw() +\r\n    theme(plot.title = element_text(size = 16, face = \"bold\"),\r\n          plot.subtitle = element_text(face = \"italic\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=12),\r\n          legend.position = c(0.72, 0.14),\r\n          legend.background = element_rect(fill = \"white\", color = \"black\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to plot variable importance scores.\r\n\r\n\r\n# function to plot variable importance\r\nplot_imp = function(imp) {\r\n  \r\n  # convert to data table\r\n  imp = as.data.table(imp$importance, keep.rownames = \"Marker\") %>%\r\n    setnames(\"Overall\", \"Importance\") %>%\r\n    .[order(-Importance)] %>%\r\n    .[, Marker := factor(Marker, levels = rev(Marker))]\r\n  \r\n  # plot variable importance\r\n  p = ggplot(imp, aes(x = Importance, y = Marker, fill = Importance,\r\n                      label = round(Importance, 2))) +\r\n    geom_bar(stat = \"identity\", width = 0.7, color = \"black\") +\r\n    scale_fill_gradient(low = \"#EADA86\", high = \"#B67977\") +\r\n    geom_text(size = 3, hjust = 1.2, fontface = \"bold\")+\r\n    scale_x_continuous(limits = c(-0.4, max(imp$Importance)), \r\n                       expand = expansion(mult = c(0, 0.05))) +\r\n    theme_bw() +\r\n    theme(plot.title = element_text(size = 16, hjust = 0.5, face = \"bold\"),\r\n          axis.title.y = element_blank(),\r\n          axis.text.y = element_text(size = 10, color = \"black\"),\r\n          axis.title.x = element_text(size = 12, face = \"bold\"),\r\n          axis.ticks.x = element_line(color = \"black\"),\r\n          axis.ticks.y = element_blank(),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1),\r\n          legend.position = \"none\")\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to train single marker model.\r\n\r\n\r\nsingle_marker = function(sm, train_dat, test_dat, tC) {\r\n  \r\n  # train model on training set (80%)\r\n  sm_model = train(x = train_dat[, ..sm], y = train_dat[, Condition],\r\n                    method = \"gbm\", trControl = tC)\r\n  \r\n  # test model on test set (20%)\r\n  sm_pred = predict(sm_model, test_dat[, ..sm])\r\n  sm_cm = confusionMatrix(sm_pred, test_dat[, Condition])\r\n  sm_prob = data.table(predict(sm_model, test_dat[, ..sm], type = \"prob\"),\r\n                        test_dat[, .(Condition)])\r\n  \r\n  # calculate AUC\r\n  sm_roc = roc(response = sm_prob$Condition, predictor = sm_prob$Control)\r\n  \r\n  # return output\r\n  sm_list = list(Prediction = sm_pred, CM = sm_cm, Probs = sm_prob, ROC = sm_roc)\r\n  return(sm_list)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to train the gradient boosting machines (GBM) model and save output.\r\n\r\n\r\ntrain_gbm = function(dat, lab, mx, sm, scols) {\r\n  \r\n  # create subdirectory if needed\r\n  wdir = file.path(dir7, lab)\r\n  if(!dir.exists(wdir)) {dir.create(wdir)}\r\n  \r\n  # partition data into training/test\r\n  train_dat =  dat[Partition %in% c(\"Train\", \"Validation\"), ]\r\n  test_dat = dat[Partition == \"Test\", ]\r\n  \r\n  # establish 10-fold cross validation to determine the out-of-sample error\r\n  tC = trainControl(method = \"cv\", number = 10, savePredictions = TRUE,\r\n                    classProbs = TRUE, verboseIter = TRUE)\r\n  \r\n  # estimate pre-processing transformation (centering, scaling, remove zero\r\n  # variance) from training data, apply to all data\r\n  normalize = preProcess(train_dat[, ..mx],\r\n                         method = c(\"center\", \"scale\", \"zv\"), verbose = TRUE)\r\n  train_dat[, (mx) := predict(normalize, train_dat[, mx, with = FALSE])]\r\n  test_dat[, (mx) := predict(normalize, test_dat[, mx, with = FALSE])]\r\n  \r\n  # train model on training set (80%)\r\n  gbm_model = train(x = train_dat[, ..mx], y = train_dat[, Condition],\r\n                    method = \"gbm\", trControl = tC)\r\n  gbm_imp = varImp(gbm_model, scale = FALSE)\r\n  \r\n  # plot variable importance\r\n  ggsave(file.path(wdir, \"Variable Importance.pdf\"), plot_imp(gbm_imp),\r\n         width = 8, height = 2.5 + length(mx)/2)\r\n  \r\n  # test model on test set (20%)\r\n  gbm_pred = predict(gbm_model, test_dat[, ..mx])\r\n  gbm_cm = confusionMatrix(gbm_pred, test_dat[, Condition])\r\n  gbm_prob = data.table(predict(gbm_model, test_dat[, ..mx], type = \"prob\"),\r\n                        test_dat[, .(Condition)])\r\n  \r\n  # calculate AUC\r\n  roc_calc = roc(response = gbm_prob$Condition, predictor = gbm_prob$Control)\r\n  roc_plot = plot_roc(gbm_prob, \"Condition\", \"Control\",\r\n                      paste0(\"AUC = \", round(roc_calc$auc, 4)))\r\n  \r\n  # save ROC curve\r\n  ggsave(file.path(wdir, \"ROC Curve.pdf\"), roc_plot, width = 6, height = 6)\r\n  \r\n  # create single-marker models\r\n  sm_models = map(sm, ~single_marker(.x, train_dat, test_dat, tC)) %>%\r\n    purrr::set_names(sm)\r\n  \r\n  # plot ROC curve\r\n  mx_auc_lab = paste0(\"Multiplex AUC = \", round(roc_calc$auc, 4))\r\n  sm_p = ggplot(gbm_prob, aes(d = Condition, m = Control)) +\r\n    ggtitle(\"Gradient Boosting Machines ROC\") +\r\n    geom_abline(aes(intercept = 0, slope = 1), linetype = \"dashed\", size = 1, color = \"gray\")\r\n  \r\n  # here, I use the bang-bang operator in quasiquotation (see rlang::nse-force)\r\n  for(i in 1:length(sm)) {\r\n    sm_auc_lab = paste0(sm[i], \" AUC = \", round(sm_models[[sm[i]]]$ROC$auc, 4))\r\n    sm_p = sm_p + geom_roc(data = sm_models[[sm[i]]]$Probs, aes(d = Condition, m = Control, color = !!sm_auc_lab), labels = FALSE, pointsize = 0)\r\n  }\r\n  \r\n  sm_p = sm_p +\r\n    geom_roc(aes(color = mx_auc_lab), labels = FALSE,\r\n             pointsize = 0) +\r\n    geom_roc(linealpha = 0, n.cuts = 12, labelround = 2, labelsize = 3) +\r\n    scale_colour_manual(values = scols) +\r\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", color = \"Area Under the Curve (AUC)\", subtitle = mx_auc_lab) + theme_bw() +\r\n    theme(plot.title = element_text(size = 16, face = \"bold\"),\r\n          plot.subtitle = element_text(face = \"italic\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=12),\r\n          legend.position = c(0.72, 0.12 + 0.03*length(sm)),\r\n          legend.background = element_rect(fill = \"white\", color = \"black\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  # save ROC curve\r\n  ggsave(file.path(wdir, \"Single-Marker ROC Curve.pdf\"), sm_p, width = 6, height = 6)\r\n  \r\n  # send output to external file\r\n  logf = file.path(wdir, \"GBM Log.txt\")\r\n  if (file.exists(logf)) { file.remove(logf) }\r\n  \r\n  # establish sink\r\n  sink(logf)\r\n  gbm_model %>%\r\n    list(., .$results, .$finalModel, gbm_imp,\r\n         as.matrix(gbm_imp$importance), gbm_cm) %>%\r\n    walk(., print)\r\n  sink()\r\n  \r\n  # return full list of output\r\n  return(list(Test = test_dat, Train = train_dat, Model = gbm_model,\r\n              Prediction = gbm_pred, CM = gbm_cm, Scores = gbm_prob,\r\n              ROC = roc_calc, Importance = gbm_imp, Baseline = sm_models))\r\n  \r\n}\r\n\r\n\r\n\r\nPerform Machine Learning\r\nTrain the GBM model by mapping over all.\r\n\r\n\r\n# define markers of interest\r\nmarkers = list(Astrocyte = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\",\r\n                             \"EAAT1\", \"EAAT2\", \"GS\"),\r\n               Microglia = c(\"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"),\r\n               Vessel = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"))\r\n\r\n# single markers\r\nsingle_markers = list(Astrocyte = \"GFAP\",\r\n                      Microglia = c(\"CD68\", \"MHC2\"),\r\n                      Vessel = \"GFAP\")\r\n\r\nsingle_colors = list(Astrocyte = c(\"#577399\", \"#FE7A71\"),\r\n                 Microglia = c(\"#577399\",\"#BDD5EA\", \"#FE7A71\"),\r\n                 Vessel = c(\"#577399\", \"#FE7A71\"))\r\n\r\n# train GBM model\r\ngbm_results = imap(all, ~train_gbm(.x, .y, markers[[.y]], single_markers[[.y]], single_colors[[.y]]))\r\n\r\n# save output\r\nsaveRDS(gbm_results, file.path(dir7, \"GBM Results.rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:20:24-07:00"
    },
    {
      "path": "gbm-state.html",
      "title": "Gradient Boosting Machines by State",
      "description": "This R script trains gradient boosting machines (GBM) models to perform the state classification task (i.e., predict homeostatic vs. intermediate vs. reactive).\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nMerge Data\r\nTrain GBM Model\r\nPerform Machine Learning\r\n\r\nDependencies\r\nLoad requisite packages and define directories.\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\n\r\n# fast file system operations\r\nlibrary(fs)\r\n\r\n# gradient boosted machines\r\nlibrary(caret)\r\nlibrary(gbm)\r\n\r\n# ROC curve\r\nlibrary(pROC)\r\nlibrary(plotROC)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# create file structure\r\ncelltypes = c(\"Astrocyte\", \"Microglia\", \"Vessel\") %>% purrr::set_names()\r\n\r\n# set directories\r\nddir = file.path(\"Results\", \"CNN\", \"1.2 - State Partition\")\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\ndir7 = file.path(\"Results\", \"7 - Gradient Boosting Machines\", \"State\")\r\n\r\n# create directory\r\nif(!dir.exists(dir7)) {dir.create(dir7)}\r\n\r\n# set seed\r\nset.seed(1234)\r\n\r\n\r\n\r\nLoad Data\r\nLoad processed ROI measurement data from the 4 - Spectral Clustering directory. Note that this script uses the same train/test/validation split as the convolutional neural network (CNN) by loading the data object created by the CNN/1 - Partition ROIs script.\r\n\r\n\r\nall = readRDS(file.path(dir4, \"Z-Score Data.rds\"))\r\nsplit = readRDS(file.path(ddir, \"ROI Partition by State.rds\"))\r\n\r\n\r\n\r\nMerge Data\r\nDefine function to merge ROI measurement data with the predetermined train/test/validation split.\r\n\r\n\r\n# function to parse and merge data\r\nmerge_data = function(allx, splitx) {\r\n  \r\n  # parse split data\r\n  splitx = splitx %>%\r\n    .[, ID := gsub(\"(\\\\.tif|AD_|CTRL_)\", \"\", Name)] %>%\r\n    .[, .(ID, Partition)]\r\n\r\n  # merge data\r\n  allx = merge(allx, splitx, by = \"ID\", all.x = TRUE, all.y = FALSE)\r\n  return(allx)\r\n  \r\n}\r\n\r\n\r\n\r\nMap function over data objects for cell-types with CNN output data.\r\n\r\n\r\n# function to parse and merge data\r\nall = map(celltypes, ~merge_data(all[[.x]], split[[.x]]))\r\n\r\n\r\n\r\nTrain GBM Model\r\nDefine function to plot variable importance scores.\r\n\r\n\r\n# function to plot variable importance\r\nplot_imp = function(imp) {\r\n  \r\n  # convert to data table\r\n  imp = as.data.table(imp$importance, keep.rownames = \"Marker\") %>%\r\n    setnames(\"Overall\", \"Importance\") %>%\r\n    .[order(-Importance)] %>%\r\n    .[, Marker := factor(Marker, levels = rev(Marker))]\r\n  \r\n  # plot variable importance\r\n  p = ggplot(imp, aes(x = Importance, y = Marker, fill = Importance,\r\n                      label = round(Importance, 2))) +\r\n    geom_bar(stat = \"identity\", width = 0.7, color = \"black\") +\r\n    scale_fill_gradient(low = \"#EADA86\", high = \"#B67977\") +\r\n    geom_text(size = 3, hjust = 1.2, fontface = \"bold\")+\r\n    scale_x_continuous(limits = c(-0.4, max(imp$Importance)), \r\n                       expand = expansion(mult = c(0, 0.05))) +\r\n    theme_bw() +\r\n    theme(plot.title = element_text(size = 16, hjust = 0.5, face = \"bold\"),\r\n          axis.title.y = element_blank(),\r\n          axis.text.y = element_text(size = 10, color = \"black\"),\r\n          axis.title.x = element_text(size = 12, face = \"bold\"),\r\n          axis.ticks.x = element_line(color = \"black\"),\r\n          axis.ticks.y = element_blank(),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1),\r\n          legend.position = \"none\")\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to train the gradient boosting machines (GBM) model and save output\r\n\r\n\r\ntrain_gbm = function(dat, lab, mx) {\r\n  \r\n  # create subdirectory if needed\r\n  wdir = file.path(dir7, lab)\r\n  if(!dir.exists(wdir)) {dir.create(wdir)}\r\n  \r\n  # partition data into training/test\r\n  train_dat =  dat[Partition %in% c(\"Train\", \"Validation\"), ]\r\n  test_dat = dat[Partition == \"Test\", ]\r\n  \r\n  # establish 10-fold cross validation to determine the out-of-sample error\r\n  tC = trainControl(method = \"cv\", number = 10, savePredictions = TRUE,\r\n                    classProbs = TRUE, verboseIter = TRUE)\r\n  \r\n  # estimate pre-processing transformation (centering, scaling, remove zero\r\n  # variance) from training data, apply to all data\r\n  normalize = preProcess(train_dat[, ..mx],\r\n                         method = c(\"center\", \"scale\", \"zv\"), verbose = TRUE)\r\n  train_dat[, (mx) := predict(normalize, train_dat[, mx, with = FALSE])]\r\n  test_dat[, (mx) := predict(normalize, test_dat[, mx, with = FALSE])]\r\n  \r\n  # train model on training set (80%)\r\n  gbm_model = train(x = train_dat[, ..mx], y = train_dat[, State],\r\n                    method = \"gbm\", trControl = tC)\r\n  gbm_imp = varImp(gbm_model, scale = FALSE)\r\n  \r\n  # plot variable importance\r\n  ggsave(file.path(wdir, \"Variable Importance.pdf\"), plot_imp(gbm_imp),\r\n         width = 8, height = 2.5 + length(mx)/2)\r\n  \r\n  # test model on test set (20%)\r\n  gbm_pred = predict(gbm_model, test_dat[, ..mx])\r\n  gbm_cm = confusionMatrix(gbm_pred, test_dat[, State])\r\n  gbm_prob = data.table(predict(gbm_model, test_dat[, ..mx], type = \"prob\"),\r\n                        test_dat[, .(State)])\r\n  \r\n  # write GBM probabilities to file\r\n  fwrite(gbm_prob, file.path(wdir, \"GBM Probabilities.csv\"))\r\n  \r\n  # calculate multiclass AUC\r\n  roc_calc = multiclass.roc(response = gbm_prob$State, predictor = gbm_prob[, .(Homeostatic, Intermediate, Reactive)])\r\n  \r\n  # define aes values\r\n  h_i = copy(gbm_prob)[State %in% c(\"Homeostatic\", \"Intermediate\")][, State := droplevels(State)]\r\n  h_r = copy(gbm_prob)[State %in% c(\"Homeostatic\", \"Reactive\")][, State := droplevels(State)]\r\n  i_r = copy(gbm_prob)[State %in% c(\"Intermediate\", \"Reactive\")][, State := droplevels(State)]\r\n  \r\n  # plot multiclass AUC curve\r\n  roc_plot = ggplot() +\r\n    ggtitle(\"Gradient Boosting Machines ROC\") +\r\n    geom_abline(aes(intercept = 0, slope = 1), linetype = \"dashed\", size = 1, color = \"gray\") +\r\n    geom_roc(data = h_i, aes(d = State, m = Intermediate, color = \"Homeostatic/Intermediate\"), labels = FALSE, pointsize = 0) +\r\n    geom_roc(data = i_r, aes(d = State, m = Reactive, color = \"Intermediate/Reactive\"), labels = FALSE, pointsize = 0) +\r\n    geom_roc(data = h_r, aes(d = State, m = Reactive, color = \"Reactive/Homeostatic\"), labels = FALSE, pointsize = 0) +\r\n    scale_colour_manual(values = c(\"#39B200\", \"#F0C808\", \"#960200\")) +\r\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", color = \"Comparison\", subtitle = paste(\"Multi-Class AUC =\", round(as.numeric(roc_calc$auc), 4))) + theme_bw() +\r\n    theme(plot.title = element_text(size = 16, face = \"bold\"),\r\n          plot.subtitle = element_text(face = \"italic\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=12),\r\n          legend.position = c(0.72, 0.17),\r\n          legend.background = element_rect(fill = \"white\", color = \"black\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  # save ROC curve\r\n  ggsave(file.path(wdir, \"Multi-Class ROC Curve.pdf\"), roc_plot, width = 6, height = 6.2)\r\n  \r\n  # send output to external file\r\n  logf = file.path(wdir, \"GBM Log.txt\")\r\n  if (file.exists(logf)) { file.remove(logf) }\r\n  \r\n  # establish sink\r\n  sink(logf)\r\n  gbm_model %>%\r\n    list(., .$results, .$finalModel, gbm_imp,\r\n         as.matrix(gbm_imp$importance), gbm_cm) %>%\r\n    walk(., print)\r\n  cat(paste0(\"\\nMulti-Class AUC = \", round(as.numeric(roc_calc$auc), 4)))\r\n  sink()\r\n  \r\n  # return full list of output\r\n  return(list(Test = test_dat, Train = train_dat, Model = gbm_model,\r\n              Prediction = gbm_pred, CM = gbm_cm, Scores = gbm_prob,\r\n              ROC = roc_calc, Importance = gbm_imp))\r\n  \r\n}\r\n\r\n\r\n\r\nPerform Machine Learning\r\nTrain the GBM model by mapping over all.\r\n\r\n\r\n# define markers of interest\r\nmarkers = list(Astrocyte = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\",\r\n                             \"EAAT1\", \"EAAT2\", \"GS\"),\r\n               Microglia = c(\"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"),\r\n               Vessel = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"))\r\n\r\n# train GBM model\r\ngbm_results = imap(all, ~train_gbm(.x, .y, markers[[.y]]))\r\n\r\n# save output\r\nsaveRDS(gbm_results, file.path(dir7, \"GBM Results.rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:20:36-07:00"
    },
    {
      "path": "iba1-extraction.html",
      "title": "Microglia Channel Extraction",
      "description": "This ImageJ script extracts the IBA1 channel from multi-channel TIFF images and assigns each image a random alphanumeric code for blinded microglia annotation.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\nThis script is written in the ImageJ Macro Language (IJM).\r\nmacro \"IBA1 Channel Extraction\" {\r\n\r\n    setBatchMode(true);\r\n\r\n    input = getDirectory(\"Choose input data folder.\");\r\n    files = getFileList(input);\r\n    // Array.show(files);\r\n\r\n    dir = \"C:/Users/ayush/Dropbox (Partners HealthCare)/Single-Cell Multiplex IHC/Multiplex IHC Project/Multiplex IHC (GitLab)/\";\r\n    datadir = dir + \"Data/2 - Channel Extraction/Microglia/\";\r\n\r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  FUNCTION FOR RANDOM ID\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    function randomString(length, chars) {\r\n        result = \"\";\r\n        for (i = 0; i < length; i++) {\r\n            maxlen = lengthOf(chars)-1;\r\n            rand = round(random * maxlen);\r\n            result +=  substring(chars, rand, rand+1);\r\n        }\r\n        return result;\r\n    }\r\n    \r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  ITERATE OVER IMAGES\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    for (f = 0; f < files.length; f++) {\r\n\r\n        open(input + files[f]);\r\n        Roi.remove; // remove active selection, if any\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  LOAD IMAGE + DEFINE MARKERS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n        filename = substring(image, 0, indexOf(image, \"_Reordered.tif\"));\r\n        \r\n        splitname = split(filename, \"_\");   \r\n        sample = splitname[0];\r\n        layer = splitname[1];\r\n        crop = splitname[2];\r\n        crop = substring(crop, 4);\r\n        \r\n        if (sample == \"1190\" || sample == \"1301\" || sample == \"1619\" || sample == \"2169\" || sample == \"2191\" || sample == \"2250\" || sample == \"2274\") {\r\n            condition = \"CTRL\";\r\n        } else {\r\n            condition = \"AD\";\r\n        }\r\n        \r\n        print(filename);\r\n\r\n        ////////////////////////////////////////////////////////////\r\n        /////  RANDOMIZE CROP\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        id = randomString(6, \"0123456789abcdefghijklmnopqrstuvwxyz\");\r\n        // print(id);\r\n\r\n        Table.set(\"ID\", f, id);\r\n        Table.set(\"Sample\", f, sample);\r\n        Table.set(\"Layer\", f, layer);\r\n        Table.set(\"Crop\", f, crop);\r\n        Table.set(\"Condition\", f, condition);\r\n        Table.set(\"File\", f, filename);\r\n        Table.update();\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE IBA1 CHANNEL\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        // duplicate IBA1 channel\r\n        selectImage(image); // shift focus to original\r\n        run(\"Duplicate...\", \"title=IBA1 duplicate channels=3\");\r\n\r\n        run(\"Enhance Contrast...\", \"saturated=0.1\"); // only for visualization purposes\r\n        \r\n        selectWindow(\"IBA1\"); // shift focus to original\r\n        saveAs(\"Png\", datadir + condition + \"/\" + id + \".png\");\r\n        close();\r\n\r\n        selectImage(image);\r\n        close();\r\n    \r\n    }\r\n\r\n    // save table with mappings\r\n    Table.save(datadir + \"ID Mappings.csv\")\r\n\r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:51:31-07:00"
    },
    {
      "path": "index.html",
      "title": "Cyclic Multiplex Fluorescent Immunohistochemistry and Machine Learning Reveal Distinct States of Astrocytes and Microglia in Normal Aging and Alzheimer’s Disease",
      "description": "We have developed a methodology of cyclic multiplex fluorescent immunohistochemistry on human postmortem brain sections followed by an image analysis and machine learning pipeline that enables a deep morphological characterization of astrocytes and microglia in the Alzheimer's brain.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nWorkflow\r\nDocumentation\r\nCode Availability\r\n\r\nDependencies\r\nTo run our code, please install the following dependencies:\r\n\r\n\r\n\r\n\r\nAdditional required libraries are specified in each script. Image segmentation was performed with the FIJI distribution (Schindelin et al. 2012) of the open-source Java-based image analysis program ImageJ (Rueden et al. 2017). Convolutional neural networks (CNN) were constructed using the PyTorch open-source deep learning library in the Python programming language (version 3.8.5) (Paszke et al. 2019). Unless otherwise indicated, all other analyses were performed in the R programming language and statistical computing environment (version 4.1.0).\r\nWorkflow\r\nPlease see the analysis workflow below. Click on any icon to be navigated to the appropriate page.\r\n\r\n\r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\n      \r\n    \r\nDocumentation\r\nTo read our documented code, please visit www.serranopozolab.org/glia-ihc.\r\nCode Availability\r\nOur full codebase is available for download on GitHub.\r\n\r\n\r\n\r\nPaszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019. “PyTorch: An Imperative Style, High-Performance Deep Learning Library.” In Advances in Neural Information Processing Systems 32, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. Alché-Buc, E. Fox, and R. Garnett, 8024–35. Curran Associates, Inc. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf.\r\n\r\n\r\nRueden, Curtis T., Johannes Schindelin, Mark C. Hiner, Barry E. DeZonia, Alison E. Walter, Ellen T. Arena, and Kevin W. Eliceiri. 2017. “ImageJ2: ImageJ for the Next Generation of Scientific Image Data.” BMC Bioinformatics 18 (1): 529. https://doi.org/10.1186/s12859-017-1934-z.\r\n\r\n\r\nSchindelin, Johannes, Ignacio Arganda-Carreras, Erwin Frise, Verena Kaynig, Mark Longair, Tobias Pietzsch, Stephan Preibisch, et al. 2012. “Fiji: An Open-Source Platform for Biological-Image Analysis.” Nature Methods 9 (7): 676–82. https://doi.org/10.1038/nmeth.2019.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:20:47-07:00"
    },
    {
      "path": "microglia-cnn.html",
      "title": "Convolutional Neural Network for Microglia Classification",
      "description": "This Python script trains a convolutional neural network to predict diagnosis (i.e., CTRL vs. AD) at the single-microglia level using raw image features.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        },
        {
          "name": {},
          "url": {}
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nDefine Data Transformations\r\nLoad Data\r\nDefine Model Architecture\r\nDefine Training Loop\r\nTrain Model\r\nVisualize Training\r\nEvaluate on Test Set\r\nPlot ROC Curve\r\n\r\nModel Interpretability\r\nSave Notebook\r\n\r\nDependencies\r\n\r\n# data manipulation and visualization\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.pyplot import *\r\nfrom skimage import io\r\n\r\n# PyTorch\r\nimport torch\r\nfrom torch import nn, optim\r\nimport torchvision\r\nfrom torchvision import transforms, datasets, models\r\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\r\nfrom torch.utils.data.sampler import SubsetRandomSampler\r\n\r\n# file management and time\r\nimport time\r\nfrom datetime import datetime\r\nimport os\r\n\r\n# create time object used for file names\r\nmy_time = datetime.now()\r\n\r\nbase_dir = \"<insert your directory here>\"\r\n\r\n# set seeds to make computations deterministic\r\ntorch.manual_seed(1234)\r\nnp.random.seed(1234)\r\n\r\n# set CUDA device\r\ndevice = torch.device('cuda:1')\r\nprint(torch.cuda.is_available())\r\nprint(torch.cuda.get_device_name(1))\r\n\r\ndef togpu(x):\r\n    # return x.cuda()\r\n    return x.to(device)\r\n\r\ndef tocpu(x):\r\n    return x.cpu()\r\n\r\nDefine Data Transformations\r\nThe order of astrocyte markers (out of 17 markers in the original crops) prior to data transformation is specified below, used in the select_channels() function (zero-indexed).\r\nDAPI\r\nIBA1\r\nMHC2\r\nCD68\r\nTMEM119\r\nTSPO\r\nFTL\r\n1\r\n3\r\n5\r\n9\r\n8\r\n6\r\n12\r\n\r\ndef to_tensor(x):\r\n    x = np.ndarray.astype(x, float)\r\n    x /= 255 # normalize to a 0-1 distribution\r\n    return torch.from_numpy(x)\r\n\r\ndef select_channels(x):\r\n    return x[[0, 2, 4, 8, 7, 5, 11]]\r\n\r\ndef norm(x): # calculate mean and std for each channel\r\n    my_mean = []; my_std = []\r\n\r\n    for c in x:\r\n        channel_std = c.std().item() # return std of channel n as float\r\n        if channel_std == 0: # prevent division by zero error\r\n            channel_std += 1e-05\r\n\r\n        my_mean.append(c.mean().item()) # return mean of channel n as float, append\r\n        my_std.append(channel_std) # append std of channel n\r\n\r\n    return torchvision.transforms.functional.normalize(x, tuple(my_mean), tuple(my_std))\r\n\r\n# define data transforms\r\ndata_transform = transforms.Compose([\r\n    to_tensor,\r\n    select_channels,\r\n    norm # mean is 0 and std is 1 for all images\r\n    ])\r\n\r\nLoad Data\r\nLoad data into workspace, use sci-kit loader as PIL truncates at three channels.\r\n\r\n# load data\r\ntrain_data = datasets.ImageFolder(data_dir + \"Train\", transform = data_transform, loader = io.imread)\r\nval_data = datasets.ImageFolder(data_dir + \"Validation\", transform = data_transform, loader = io.imread)\r\ntest_data = datasets.ImageFolder(data_dir + \"Test\", transform = data_transform, loader = io.imread)\r\n\r\nnum_workers = 0 # number of subprocesses to use for data loading\r\n\r\nFunction to visualize specific astrocytes.\r\n\r\nfrom matplotlib.colors import Colormap, ListedColormap\r\n\r\nmarker = [\"DAPI\", \"IBA1\", \"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"]\r\ncolormaps = [\"Blues\", \"Greens\", \"Reds\", \"RdPu\", \"BuGn\", \"BuPu\", \"Oranges\"]\r\n\r\ndef plotMicroglia(img, lab, idx, outdir = None): # dat = test_data or train_data\r\n\r\n    # given that train_data.class_to_idx is {'AD': 0, 'CTRL': 1}\r\n    if lab == 0:\r\n        img_title = \"Alzheimer\"\r\n    else:\r\n        img_title = \"Control\"\r\n\r\n    fig, axs = plt.subplots(2, 4, figsize = (10, 4))\r\n    plt.suptitle(\"Microglia #\" + str(idx + 1) + \": \" + img_title, fontsize = 14, fontweight = \"bold\")\r\n    fig.tight_layout(h_pad = 1)\r\n    i = 0\r\n\r\n    for r in range(2):\r\n        for c in range(4):\r\n            if(i < len(marker)):\r\n                cm = get_cmap(colormaps[i])(range(255))\r\n                cm = ListedColormap(cm)\r\n\r\n                axs[r, c].imshow(img[i], cmap = cm)\r\n                axs[r, c].set_title(marker[i])\r\n                i += 1\r\n                axs[r, c].get_xaxis().set_visible(False)\r\n                axs[r, c].get_yaxis().set_visible(False)\r\n    \r\n    axs[1, 3].set_axis_off()\r\n\r\nGet dataset lengths.\r\n\r\n# obtain training, validation, and test length\r\nnum_train = len(train_data)\r\nnum_val = len(val_data)\r\nnum_test = len(test_data)\r\n\r\n# define testing data loader\r\ntest_loader = DataLoader(test_data, batch_size = 20, shuffle = False)\r\n\r\n# print output\r\nprint(\"Train: \" + str(num_train) + \"\\t\\t\" + \"Validation: \" + str(num_val) + \"\\t\\t\" + \"Test: \" + str(num_test))\r\n\r\nDefine Model Architecture\r\nModel architecture is defined with four convolutional layers and three dense layers. All convolutional layers use the ReLU (rectified linear unit) activation function, and the first three convolutional layers are followed by max-pooling and dropout layers. The number of output channels and dropout probabilities are set as tunable hyperparameters.\r\n\r\nfrom torch.autograd import Variable\r\nimport torch.nn.functional as F\r\nimport torch.optim as optim\r\n\r\nclass MicrogliaCNN(torch.nn.Module):\r\n    \r\n    def __init__(self, trial):\r\n        super(MicrogliaCNN, self).__init__()\r\n\r\n        # define number of outgoing filters\r\n        out_channels_1 = trial.suggest_int(\"out_channels_1\", 64, 256)\r\n        out_channels_2 = trial.suggest_int(\"out_channels_2\", 64, out_channels_1)\r\n        out_channels_3 = trial.suggest_int(\"out_channels_3\", 32, out_channels_2)\r\n        out_channels_4 = trial.suggest_int(\"out_channels_4\", 8, 32)\r\n        self.feature_length = out_channels_4\r\n\r\n        # the shape of the input images are 7 x 64 x 64\r\n        self.conv1 = torch.nn.Conv2d(in_channels=7, out_channels=out_channels_1, kernel_size=3, padding=1)\r\n        self.conv2 = torch.nn.Conv2d(in_channels=out_channels_1, out_channels=out_channels_2, kernel_size=3, padding=1)\r\n        self.conv3 = torch.nn.Conv2d(in_channels=out_channels_2, out_channels=out_channels_3, kernel_size=3, padding=1)\r\n        self.conv4 = torch.nn.Conv2d(in_channels=out_channels_3, out_channels=out_channels_4, kernel_size=3, padding=1)\r\n        \r\n        # after pooling, the input feature vector should be 64 x 8 x 8\r\n        self.fc1 = torch.nn.Linear(in_features=(out_channels_4 * 8 * 8), out_features=1024)\r\n        self.fc2 = torch.nn.Linear(in_features=1024, out_features=64)\r\n        self.fc3 = torch.nn.Linear(in_features=64, out_features=2)\r\n\r\n        # define ReLU and max-pooling layers\r\n        self.relu = torch.nn.ReLU(inplace=False)\r\n        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\r\n\r\n        # define dropout layers\r\n        dropout_prob_1 = trial.suggest_float(\"dropout_prob_1\", 0.2, 0.8)\r\n        self.dropout1 = torch.nn.Dropout(p = dropout_prob_1, inplace=False)\r\n        \r\n        dropout_prob_2 = trial.suggest_float(\"dropout_prob_2\", 0.2, 0.8)\r\n        self.dropout2 = torch.nn.Dropout(p = dropout_prob_2, inplace=False) \r\n\r\n        dropout_prob_3 = trial.suggest_float(\"dropout_prob_3\", 0.2, 0.8)\r\n        self.dropout3 = torch.nn.Dropout(p = dropout_prob_3, inplace=False)\r\n\r\n        self.loss_list = []\r\n        self.acc_list = []\r\n        self.val_acc = []\r\n        self.val_loss = []\r\n        self.epoch_val_loss = []\r\n        self.epoch_val_auc = []\r\n\r\n        # print all of the hyperparameters of the training iteration:\r\n        print(\"\\n\\n====== MICROGLIA CNN ======\")\r\n        print(\"Dropout Probabilities: [1] {} --> [2] {} --> [3] {}\".format(dropout_prob_1, dropout_prob_2, dropout_prob_3))\r\n        print(\"Number of Kernels: [1] {} --> [2] {} --> [3] {} --> [4] {}\".format(out_channels_1, out_channels_2, out_channels_3, out_channels_4))\r\n        print(\"=\" * 27)\r\n\r\n        \r\n    def forward(self, x):\r\n\r\n        ## FEATURE EXTRACTOR\r\n\r\n        # size changes from (9, 64, 64) to (64, 64, 64)\r\n        x = self.relu(self.conv1(x)) # first convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 64, 64) to (64, 32, 32)\r\n\r\n        x = self.dropout1(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 32, 32) to (64, 32, 32)\r\n        x = self.relu(self.conv2(x)) # second convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 32, 32) to (64, 16, 16)\r\n\r\n        x = self.dropout2(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 16, 16) to (64, 16, 16)\r\n        x = self.relu(self.conv3(x)) # third convolution, then ReLU non-linearity\r\n        x = self.pool(x) # max-pooling to downsample (64, 16, 16) to (64, 8, 8)\r\n\r\n        x = self.dropout3(x) # dropout layer to prevent overfitting\r\n\r\n        # (64, 8, 8) to (64, 8, 8)\r\n        x = self.relu(self.conv4(x)) # four convolution, then ReLU non-linearity\r\n\r\n        ## COLLAPSE TO FEATURE VECTOR\r\n\r\n        x = x.reshape(-1, self.feature_length * 8 * 8) # reshape data, then pass to dense classifier\r\n\r\n        ## DENSE NETWORK TO CLASSIFY\r\n\r\n        x = self.relu(self.fc1(x)) # 4096 to 1024\r\n        x = self.relu(self.fc2(x)) # 1024 to 64\r\n        x = self.fc3(x) # 64 to 2\r\n        \r\n        return x\r\n\r\nHere, the loss function is defined as cross-entropy loss. The loss function is defined as cross-entropy loss. Cross-entropy is a measure from the field of information theory to calculate the difference between two probability distributions.\r\nThe optimizer, learning rate, and weight decay are set as tunable hyperparameters. Of note, one of the possible optimizers is the Adam optimization algorithm, a variant of stochastic gradient descent (SGD). Adam was introduced in Kingma and Ba (2017) as follows:\r\n\r\n“We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.”\r\n\r\nStochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training. When using Adam, a learning rate is maintained for each network parameter and separately adapted as learning unfolds. The other possible optimizers are SGD and root mean square propagation (RMSprop).\r\nIn defining the optimizer, establishing a small value for weight_decay enables L2, or ridge, regularization which penalizes large weights and counteracts model overfitting.\r\n\r\ndef createLossAndOptimizer(net, trial):\r\n\r\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\r\n    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\r\n    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-1, log=True)\r\n\r\n    loss = torch.nn.CrossEntropyLoss()\r\n    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\r\n    \r\n    return(loss, optimizer, optimizer_name, learning_rate, weight_decay)\r\n\r\nDefine Training Loop\r\nWhen defining the training loop, early stopping (regularization used to avoid overfitting on the training data) is implemented based on the EarlyStopping class in pytorchtool.py from Bjarten/early-stopping-pytorch (which in turn is inspired by the class of the same name from pytorch/ignite. Early stopping patience is the the number of epochs to wait after the last time the validation loss improved before “terminating” the training loop. Note that the training loop is allowed to continue, but a checkpoint is created, and model parameters at the last checkpoint are loaded at the end of trainNet().\r\nThe following function is called by trainNet().\r\n\r\ndef train_function(net, train_loader, optimizer, loss, epoch, verbose):\r\n\r\n    running_loss = 0.0\r\n    n_batches = len(train_loader)\r\n    print_every = n_batches // 5 # print 5 times total each epoch\r\n    start_time = time.time()\r\n    total_train_loss = 0\r\n    \r\n    # batch iteration\r\n    for i, data in enumerate(train_loader, 0):\r\n        \r\n        inputs, labels = data\r\n        # print(inputs, labels)\r\n        \r\n        # perform backpropagation and Adam optimization\r\n        inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\r\n\r\n        # clear gradients\r\n        optimizer.zero_grad()\r\n\r\n        # perform forward propagation\r\n        outputs = net(inputs)\r\n\r\n        # calculate cross-entropy loss\r\n        loss_size = loss(outputs, labels)\r\n        net.loss_list.append(loss_size.item())\r\n\r\n        # calculate gradients and update weights via Adam optimizer\r\n        loss_size.backward()\r\n        optimizer.step()\r\n        \r\n        # print(loss_size.data.item())\r\n        running_loss += loss_size.data.item()\r\n        total_train_loss += loss_size.data.item()\r\n        \r\n        # track the accuracy\r\n        total = labels.size(0)\r\n        _, predicted = torch.max(outputs.data, 1)\r\n        correct = (predicted == labels).sum().item()\r\n        net.acc_list.append(correct / total)\r\n        \r\n        if (i % print_every == print_every - 1) and verbose:\r\n            time_delta = time.time() - start_time\r\n            print(\"Epoch {}, {:d}% \\t Training Loss: {:.4f} \\t Accuracy: {:.2f}% \\t Took: {:.2f}s\".format(epoch + 1, int(100 * (i + 1) / n_batches), running_loss / print_every, (correct / total) * 100, time_delta))\r\n            running_loss = 0.0\r\n            start_time = time.time()\r\n\r\nThis is the central function which implements the model training loop. The Optuna optimizer maximizes the out-of-sample area under the receiver operating characteristic (ROC) curve (AUC), which is determined by 3-fold cross-validation using the scikit-learn cross-validator within the 80% training set for each Optuna trial (i.e., Bayesian meta-optimization) (Pedregosa et al. 2011).\r\n\r\nimport sklearn.metrics as metrics\r\nfrom statistics import mean\r\nfrom itertools import chain\r\nfrom pytorchtools import EarlyStopping\r\nfrom sklearn.model_selection import KFold\r\n\r\n# checkpoint_dir = results_dir + \"Early Stopping\\\\\"\r\ncheckpoint_dir = results_dir + \"Early Stopping/\"\r\n\r\ndef trainNet(trial, batch_size, n_epochs, patience, k_folds):\r\n\r\n    # print all of the hyperparameters of the training iteration:\r\n    print(\"\\n===== HYPERPARAMETERS =====\")\r\n    print(\"Trial Number: {}\".format(trial.number))\r\n    print(\"Batch Size: \", batch_size)\r\n    print(\"Epochs: \", n_epochs)\r\n    print(\"Folds: \", k_folds)\r\n    print(\"=\" * 27)\r\n\r\n    # concatenate original training and validation split\r\n    full_data = ConcatDataset([train_data, val_data])\r\n\r\n    # define the K-fold cross validator\r\n    kfold = KFold(n_splits = k_folds, shuffle = True)\r\n\r\n    # average max. validation AUC across k-folds\r\n    average_max_val_auc = []\r\n\r\n    # k-fold cross validation model evaluation\r\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(full_data)):\r\n\r\n        # generate the model\r\n        net = togpu(MicrogliaCNN(trial)).double()\r\n\r\n        # define loss and optimizer\r\n        loss, optimizer, optimizer_name, learning_rate, weight_decay = createLossAndOptimizer(net, trial)\r\n\r\n        # print fold statement\r\n        print(\"\\n>>> BEGIN FOLD #{}\".format(fold + 1))\r\n        print(\"Optimizer: \", optimizer_name)\r\n        print(\"Learning Rate: \", learning_rate)\r\n        print(\"Weight Decay: \", weight_decay)\r\n\r\n        # sample elements randomly from a given list of ids, no replacement\r\n        train_sampler = SubsetRandomSampler(train_idx)\r\n        val_sampler = SubsetRandomSampler(val_idx)\r\n\r\n        # define train and validation data loaders\r\n        train_loader = DataLoader(full_data, batch_size = batch_size, sampler = train_sampler)\r\n        val_loader = DataLoader(full_data, batch_size = 32, sampler = val_sampler)\r\n\r\n        # initialize the early stopping object\r\n        early_stopping = EarlyStopping(patience = patience, verbose = True, path = checkpoint_dir + \"checkpoint.pt\")\r\n\r\n        # set start data\r\n        training_start_time = time.time()        \r\n        min_val_loss = float('inf')\r\n        max_val_auc = 0\r\n\r\n        # epoch iteration\r\n        for epoch in range(n_epochs):\r\n            \r\n            print(\"\\n----- TRIAL #{} FOLD #{} EPOCH #{} -----\".format(trial.number + 1, fold + 1, epoch + 1))\r\n\r\n            # set model to training mode\r\n            net.train()\r\n\r\n            # batch iteration\r\n            train_function(net, train_loader, optimizer, loss, epoch, verbose = False)\r\n                    \r\n            # set model to evaluation mode\r\n            net.eval()\r\n            val_true = []; val_score = [];\r\n            total_val_loss = 0\r\n\r\n            # validation set iteration\r\n            for inputs, labels in val_loader:\r\n                inputs, labels = Variable(togpu(inputs)), Variable(togpu(labels))\r\n                \r\n                val_outputs = net(inputs)\r\n                val_loss_size = loss(val_outputs, labels)\r\n                total_val_loss += val_loss_size.data.item()\r\n                net.val_loss.append(val_loss_size.item())\r\n\r\n                val_total = labels.size(0)\r\n                _, val_predicted = torch.max(val_outputs.data, 1)\r\n                val_correct = (val_predicted == labels).sum().item()\r\n                net.val_acc.append(val_correct / val_total)\r\n\r\n                # for ROC calculation\r\n                val_ctrl_probs = [x[1] for x in F.softmax(val_outputs.data).tolist()]\r\n                val_score.append(val_ctrl_probs); val_true.append(labels.tolist())\r\n\r\n            # get validation accuracy\r\n            print(\"\\nValidation Accuracy = {:.2f}%\".format((val_correct / val_total) * 100))\r\n\r\n            # calculate AUC for this epoch\r\n            val_true = list(chain.from_iterable(val_true))\r\n            val_score = list(chain.from_iterable(val_score))\r\n            fpr, tpr, thresholds = metrics.roc_curve(y_true = val_true, y_score = val_score, pos_label = 1)\r\n            val_auc = metrics.auc(fpr, tpr)\r\n            net.epoch_val_auc.append(val_auc)\r\n            print(\"\\nValidation AUC = {:.4f}\".format(val_auc))\r\n\r\n            # calculate maximum validation AUC\r\n            if val_auc > max_val_auc:\r\n                print(\"New Best AUC: ({} --> {})\".format(max_val_auc, val_auc))\r\n                max_val_auc = val_auc\r\n\r\n            # get validation loss for this epoch\r\n            val_loss = total_val_loss / len(val_loader)\r\n            net.epoch_val_loss.append(val_loss)     \r\n            print(\"\\nValidation Loss = {:.4f}\".format(val_loss))\r\n\r\n            # calculate minimum validation loss\r\n            if val_loss < min_val_loss:\r\n                print(\"New Best Loss: ({} --> {})\".format(min_val_loss, val_loss))\r\n                min_val_loss = val_loss\r\n\r\n            # early stopping based on validation loss\r\n            early_stopping(total_val_loss / len(val_loader), net)\r\n            if early_stopping.early_stop:\r\n                print(\"Early Stopping at Epoch {}\".format(epoch + 1))\r\n                break\r\n\r\n        # print output\r\n        print(\"\\n>>> COMPLETE FOLD #{}\".format(fold + 1))\r\n        print(\"Training Finished, Took {:.2f}s\".format(time.time() - training_start_time))\r\n        print(\"Minimum Validation Loss: {:.4f}\".format(min_val_loss))\r\n        print(\"Maximum Validation AUC: {:.4f}\\n\".format(max_val_auc))\r\n\r\n        # append max. val AUC\r\n        average_max_val_auc.append(max_val_auc)\r\n\r\n    ############################################################\r\n\r\n    # retrain model on full dataset\r\n    final_net = togpu(MicrogliaCNN(trial)).double()\r\n\r\n    # define loss and optimizer\r\n    loss, optimizer, optimizer_name, learning_rate, weight_decay = createLossAndOptimizer(final_net, trial)\r\n\r\n    # print statements\r\n    print(\"\\n\\n>>> FINAL MODEL FOR TRIAL #{}\".format(trial.number + 1))\r\n    print(\"Optimizer: \", optimizer_name)\r\n    print(\"Learning Rate: \", learning_rate)\r\n    print(\"Weight Decay: \", weight_decay)\r\n\r\n    # sample elements randomly from full dataset\r\n    num_full = len(full_data); full_idx = list(range(num_full)); np.random.shuffle(full_idx)\r\n    full_sampler = SubsetRandomSampler(full_idx)\r\n\r\n    # define train and validation data loaders\r\n    full_loader = DataLoader(full_data, batch_size = batch_size, sampler = full_sampler)\r\n    \r\n    # iterate over full dataset to train model\r\n    final_net.train()\r\n    for epoch in range(n_epochs):\r\n        print(\"\\n----- TRIAL #{} FINAL MODEL EPOCH #{} -----\".format(trial.number + 1, epoch + 1))\r\n        train_function(final_net, full_loader, optimizer, loss, epoch, verbose = True)\r\n\r\n    # calculate average validation AUC across folds\r\n    print(\"Maximum Validation AUCs:\" + str(average_max_val_auc))\r\n    average_max_val_auc = mean(average_max_val_auc)\r\n    print(\"Average Max. Validation AUC: {:.4f}\\n\\n\".format(average_max_val_auc))\r\n\r\n    # use validation AUC as score to maximize across Optuna trials\r\n    return(final_net, average_max_val_auc)\r\n\r\nTrain Model\r\nHere, we use Optuna to optimize the hyperparameters for training (Akiba et al. 2019). First, we define the objective() function, which returns the average validation AUC for any given trial with a combination of selected hyperparameters (as discussed above). This value is then used as feedback on the performance of the trial, and the objective() function is maximized using the multivariate tree-structured Parzen estimator algorithm (Bergstra et al. 2011). The trial object is passed to various functions (define above) to tune hyperparameters.\r\n\r\nimport optuna\r\nimport pickle\r\nfrom optuna.samplers import TPESampler\r\n\r\nparam_dir = results_dir + \"Hyperparameter Optimization/\"\r\nstudy_dir = results_dir + \"Study Database/\"\r\n\r\ndef objective(trial):\r\n\r\n    # start the training loop\r\n    model, max_val_auc = trainNet(trial, batch_size = 64, n_epochs = 30, patience = 10, k_folds = 3)\r\n\r\n    # save model for this loop\r\n    torch.save(model.state_dict(), param_dir + \"microglia_cnn_{}.pt\".format(trial.number))\r\n    f = open(param_dir + \"accuracy_loss_{}.pkl\".format(trial.number), \"wb\")\r\n    pickle.dump([model.acc_list, model.loss_list, model.val_acc, model.val_loss, model.epoch_val_loss, model.epoch_val_auc], f)\r\n    f.close()\r\n\r\n    return max_val_au\r\n\r\nOptuna results are stored in a SQL database to preserve results between runs.\r\n\r\nimport logging\r\nimport sys\r\n\r\n# add stream handler of stdout to show the messages\r\noptuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\r\n\r\n# create study\r\nstudy_name = \"microglia-study\"  # unique identifier of the study\r\nstorage_name = \"sqlite:///{}.db\".format(study_dir + study_name)\r\nstudy = optuna.create_study(direction = \"maximize\", sampler = TPESampler(seed = 1234, multivariate = True), study_name = study_name, storage = storage_name, load_if_exists = True)\r\n\r\n\r\n# optimize hyperparameters\r\nstudy.optimize(objective, n_trials = 20, gc_after_trial = True)\r\n\r\nAfter the Optuna hyperparameter optimization is complete, the hyperparamters of the best performing trial are retrieved.\r\n\r\n# get pruned and complete trials\r\npruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\r\ncomplete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\r\n\r\n# print print study statistics\r\nprint(\"\\nStudy Statistics:\")\r\nprint(\"- Finished Trials: \", len(study.trials))\r\nprint(\"- Pruned Trials: \", len(pruned_trials))\r\nprint(\"- Complete Trials: \", len(complete_trials))\r\n\r\nprint(\"\\nBest Trial:\")\r\nbest_trial = study.best_trial\r\nprint(\"- Number: \", best_trial.number)\r\nprint(\"- Value: \", best_trial.value)\r\nprint(\"- Hyperparameters: \")\r\nfor key, value in best_trial.params.items():\r\n    print(\"   - {}: {}\".format(key, value))\r\n\r\n# save and view output\r\nstudy_results = study.trials_dataframe(attrs=(\"number\", \"value\", \"params\", \"state\"))\r\nstudy_results.to_csv(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_OptunaHistory.csv\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year))\r\n\r\nA new CNN is then initialized with these hyperparameter values.\r\n\r\n# define CNN and load weights and parameters\r\nCNN = togpu(MicrogliaCNN(best_trial)).double()\r\nCNN.load_state_dict(torch.load(param_dir + \"microglia_cnn_{}.pt\".format(best_trial.number)))\r\n\r\n# load accuracy and loss logs for training/validation\r\nf = open(param_dir + \"accuracy_loss_{}.pkl\".format(best_trial.number), \"rb\")\r\n[CNN.acc_list, CNN.loss_list, CNN.val_acc, CNN.val_loss, CNN.epoch_val_loss, CNN.epoch_val_auc] = pickle.load(f)\r\nf.close()\r\n\r\nHyperparameter optimization progress is visualized below.\r\n\r\nimport optuna.visualization.matplotlib as oviz\r\nfrom datetime import datetime\r\n\r\ntime = datetime.now()\r\n\r\nv1 = oviz.plot_param_importances(study)\r\nv2 = oviz.plot_optimization_history(study)\r\nv3 = oviz.plot_slice(study)\r\n\r\ndef fig_name(name):\r\n    return(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_{}.pdf\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year, name))\r\n\r\nv1.figure.savefig(fig_name(\"HyperparameterImportance\"))\r\nv2.figure.savefig(fig_name(\"OptimizationHistory\"))\r\n\r\nVisualize Training\r\nPlot the training accuracy, training loss, and validation loss from the best Optuna trial.\r\n\r\nimport itertools\r\nimport math\r\nfrom bokeh.plotting import figure, show\r\nfrom bokeh.io import output_notebook, reset_output, export_png\r\nfrom bokeh.models import LinearAxis, Range1d\r\n\r\nlen_loss = len(CNN.loss_list)\r\nmax_loss = max(CNN.loss_list)\r\nif max_loss < 1:\r\n    max_loss = 1\r\n\r\n# define figure\r\npname = \"{}:{}, {}/{}/{} - Microglia CNN Results\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\np = figure(y_axis_label=\"Loss\", x_axis_label=\"Training Iterations\", width=1400, height=750, title=pname)\r\n\r\n# range limits\r\np.x_range = Range1d(0, len_loss, bounds = (0, len_loss))\r\np.y_range = Range1d(0, 1, bounds = (0, max_loss)) # range from 0 to max_loss\r\n\r\n# define extra axes\r\np.extra_x_ranges = {\"Epochs\": Range1d(start=0, end=30, bounds = (0, 30))}\r\np.extra_y_ranges = {\"Accuracy\": Range1d(start=0, end=100, bounds = (0, max_loss * 100))}\r\n\r\n# add extra axes\r\np.add_layout(LinearAxis(y_range_name=\"Accuracy\", axis_label=\"Accuracy (%)\"), \"right\")\r\np.add_layout(LinearAxis(x_range_name=\"Epochs\", axis_label=\"Epochs\"), \"above\") # below\r\n\r\n# add graphs\r\np.line(np.arange(len_loss), CNN.loss_list, line_alpha = 0.5, legend_label = \"Training Loss\")\r\np.line(np.arange(len_loss), np.array(CNN.acc_list) * 100, y_range_name=\"Accuracy\", color=\"red\", line_alpha = 0.5, legend_label = \"Training Accuracy\")\r\n\r\n# specify options\r\np.legend.click_policy = \"hide\"\r\np.toolbar.active_drag = None\r\n\r\noutput_notebook()\r\nshow(p)\r\n\r\nEvaluate on Test Set\r\nDefine, then apply, a function to evaluate the model on test set images. Misclassified microglia in the hold-out test set can then be identified and plotted.\r\n\r\nfrom itertools import chain\r\n\r\ndef testNet(net, verbose = True):\r\n\r\n    cpuCNN = tocpu(CNN)\r\n\r\n    # initialize empty values\r\n    test_output = []; correct = 0; total = 0\r\n\r\n    # test the model\r\n    cpuCNN.eval()\r\n    with torch.no_grad():\r\n        for i, (images, labels) in enumerate(test_loader):\r\n\r\n            # evaluate images\r\n            outputs = cpuCNN(images)\r\n\r\n            # get prediction label, probability\r\n            _, predicted = torch.max(outputs.data, 1)\r\n            probs = F.softmax(outputs.data).tolist()\r\n            ad_probs = [x[0] for x in probs]; ctrl_probs = [x[1] for x in probs]\r\n\r\n            # get and parse file name\r\n            fname = test_loader.dataset.samples[(i*20):((i*20)+len(images))]\r\n            fname = [x[0].split(\"\\\\\").pop() for x in fname]\r\n\r\n            # update counter\r\n            total += labels.size(0)\r\n            correct += (predicted == labels).sum().item()\r\n\r\n            test_output.append([fname, predicted.tolist(), labels.tolist(), ctrl_probs, ad_probs, torch.chunk(images, 20, 0)])\r\n\r\n    # calculate accuracy\r\n    test_acc = (correct / total) * 100\r\n\r\n    # parse output\r\n    test_output = [list(x) for x in zip(*test_output)]\r\n    test_output = [list(chain.from_iterable(x)) for x in test_output]\r\n    test_output = pd.DataFrame(test_output).transpose()\r\n    test_output.columns = [\"File\", \"PredictedLabel\", \"TrueLabel\", \"ProbabilityCTRL\", \"ProbabilityAD\", \"Image\"]\r\n    \r\n    if verbose:\r\n        print(\"Accuracy on the {} Test Images: {}%\".format(len(test_data), test_acc))\r\n\r\n    return(test_acc, test_output)\r\n\r\nApply the function on the independnet test set.\r\n\r\n# test data\r\nacc, dat = testNet(CNN)\r\n\r\n# save and view output\r\ndat.to_csv(results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_TestSetResults.csv\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year))\r\ndat.head(10)\r\n\r\nPlot ROC Curve\r\n\r\nimport sklearn.metrics as metrics\r\n\r\nfpr, tpr, thresholds = metrics.roc_curve(y_true = dat.TrueLabel.to_list(), y_score = dat.ProbabilityCTRL.to_list(), pos_label = 1)\r\nroc_auc = metrics.auc(fpr, tpr)\r\n\r\nplt.title('Receiver Operating Characteristic')\r\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\r\nplt.legend(loc = 'lower right')\r\nplt.plot([0, 1], [0, 1],'r--'); plt.xlim([0, 1]); plt.ylim([0, 1])\r\nplt.ylabel('True Positive Rate'); plt.xlabel('False Positive Rate')\r\n\r\nrfname = results_dir + \"Output/\" + \"{}.{}_{}.{}.{}_ROCCurve.pdf\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\nplt.savefig(rfname, bbox_inches=\"tight\")\r\n\r\nprint(\"AUC: \" + str(roc_auc))\r\n\r\nModel Interpretability\r\nUsing the captum library for model interpretability in PyTorch (see CIFAR tutorial here) (Kokhlikyan et al. 2019).\r\nFirst, define attributeFeatures(), which is a generic function that will be used for calling an attribute on the attribution algorithm defined in input. Then, choose a test set image at index idx and define interpretMicroglia(), which will apply the selected attribution algorithms on that image. The model (i.e., cpuCNN) should be set to eval mode from the prior chunk.\r\nWithin interpretMicroglia(), compute gradients with respect to the class of the test set image, then, apply the integrated gradients attribution algorithm on the test set image. Integrated Gradients computes the integral of the gradients of the output prediction with respect to the input image pixels. More details about integrated gradients can be found in the original paper (Sundararajan, Taly, and Yan 2017).\r\nTranspose the image and gradients for visualization purposes. Also, note that the classification label assumes that test_data.class_to_idx is {'AD': 0, 'CTRL': 1}.\r\n\r\nfrom captum.attr import Saliency\r\nfrom captum.attr import IntegratedGradients\r\nfrom captum.attr import GuidedGradCam\r\nfrom captum.attr import visualization as viz\r\n\r\n# get model\r\ncpuCNN = tocpu(CNN).eval()\r\n\r\n# define generic attribution function\r\ndef attributeFeatures(idx, algorithm, input, **kwargs):\r\n    cpuCNN.zero_grad()\r\n    tensor_attributions = algorithm.attribute(input, target = dat.TrueLabel[idx], **kwargs)\r\n    return tensor_attributions\r\n\r\n# utility function\r\ndef scale(x):\r\n    return (x - np.min(x))/(np.max(x) - np.min(x))\r\n\r\n# function for model interpretability\r\ndef interpretMicroglia(idx):\r\n\r\n    # select test image\r\n    input = dat.Image[idx]\r\n    input.requires_grad = True\r\n\r\n    # saliency\r\n    saliency = Saliency(cpuCNN)\r\n    grads = saliency.attribute(input, target = dat.TrueLabel[idx])\r\n    grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n\r\n    # integrated gradients\r\n    ig = IntegratedGradients(cpuCNN)\r\n    attr_ig, delta_ig = attributeFeatures(idx, ig, input, baselines = input * 0, return_convergence_delta=True)\r\n    attr_ig = np.transpose(attr_ig.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n\r\n    # guided gradcam\r\n    gc = GuidedGradCam(cpuCNN, cpuCNN.conv4)\r\n    attr_gc = attributeFeatures(idx, gc, input)\r\n    attr_gc = np.transpose(attr_gc.squeeze().cpu().detach().numpy(), (1, 2, 0))\r\n    \r\n    # scale image to 0-1 distribution and transpose for visualization\r\n    original = input.cpu().detach().numpy()[0]\r\n    original = np.array([scale(x) for x in original])\r\n    original = np.transpose(original, (1, 2, 0))\r\n\r\n    return(idx, original, grads, attr_ig, attr_gc)\r\n\r\nNext, define a function to visualize results of attribution algorithms across all channels.\r\n\r\nimport regex as re\r\n\r\nmarker = [\"DAPI\", \"IBA1\", \"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"]\r\ncolormaps = [\"Blues\", \"Greens\", \"Reds\", \"RdPu\", \"BuGn\", \"BuPu\", \"Oranges\"]\r\n\r\n# function to visualize attribution across channels\r\ndef visualizeAttribution(idx, original, grads, attr_ig, attr_gc):\r\n\r\n    # print predicted class, classification probability, and true class\r\n    classes = (\"Alzheimer\", \"Control\")\r\n    my_fname, my_pred, my_lab, my_ctrl, my_ad = dat.iloc[idx, 0:5]\r\n    my_pred = classes[my_pred]; my_lab = classes[my_lab]\r\n\r\n    # define plot\r\n    fig, axs = plt.subplots(nrows = 4, ncols = 8, figsize = (24, 15))\r\n    fig.tight_layout(h_pad = 2)\r\n\r\n    # parse filename\r\n    my_fname = my_fname.split(\"/\")[11]\r\n    prse = my_fname.split(\"_\")\r\n    sample = prse[1]; layer = re.sub(\"Layer\", \"\", prse[2])\r\n    crop = re.sub(\"crop\", \"\", prse[3])\r\n    lab = re.sub(\"(\\\\.tif|Microglia)\", \"\", prse[4])\r\n\r\n    # annotation text\r\n    plt.figtext(x = 0.52, y = 0.24, s = r\"$\\bf{Sample:~}$\" + sample + r\"$\\bf{~~~Layer:~}$\" + layer + r\"$\\bf{~~~Crop:~}$\" + crop + r\"$\\bf{~~~Number:~}$\" + lab + \"\\n\" + r\"$\\bf{Predicted:~}$\" + my_pred + \"\\n\" +  r\"$\\bf{Truth:~}$\" + my_lab + \"\\n\" + r\"$\\bf{Control\\ Probability:~}$\" + str(round(my_ctrl*100, 4)) + \"%\\n\" + r\"$\\bf{AD\\ Probability:~}$\" + str(round(my_ad*100, 4)) + \"%\\n\" + r\"$\\bf{Index:~}$\" + str(idx), fontsize = 18, linespacing = 2, ha = \"left\", va = \"top\")\r\n\r\n    for c in range(len(marker)):\r\n\r\n        # plot indexing\r\n        cl = [c]\r\n        x_idx = 0 if c < 4 else 4\r\n        y_idx = c % 4\r\n\r\n        # original image (with transforms)\r\n        _ = viz.visualize_image_attr(original[:, :, cl], original[:, :, cl], method = \"heat_map\", cmap = colormaps[c], title = r\"$\\bf{\" + marker[c] + r\"}$\", plt_fig_axis = (fig, axs[y_idx, 0 + x_idx]), use_pyplot = False)\r\n\r\n        # saliency gradient\r\n        _ = viz.visualize_image_attr(grads[:, :, cl], original[:, :, cl], method = \"masked_image\", sign = \"absolute_value\", show_colorbar = True, title = marker[c] + \" Gradient Magnitudes\", plt_fig_axis = (fig, axs[y_idx, 1 + x_idx]), use_pyplot = False)\r\n\r\n        # integrated gradient\r\n        if attr_ig[:, :, cl].sum() != 0: # if no signal\r\n            _ = viz.visualize_image_attr(attr_ig[:, :, cl], original[:, :, cl], method = \"blended_heat_map\", alpha_overlay = 0.85, sign = \"all\", show_colorbar = True, title = marker[c] + \" Integrated Gradients\", plt_fig_axis = (fig, axs[y_idx, 2 + x_idx]), use_pyplot = False)\r\n        else:\r\n            axs[y_idx, 2 + x_idx].set_visible(False)\r\n\r\n        # guided gradcam\r\n        _ = viz.visualize_image_attr(attr_gc[:, :, cl], original[:, :, cl], method = \"blended_heat_map\", alpha_overlay = 0.85, sign = \"absolute_value\", show_colorbar = True, title = marker[c] + \" Guided GradCAM\", plt_fig_axis = (fig, axs[y_idx, 3 + x_idx]), use_pyplot = False)\r\n\r\n    # remove axes\r\n    for remove in range(4,8):\r\n        axs[3, remove].set_visible(False)\r\n\r\n    # save figure\r\n    plt.savefig(results_dir + \"Model Interpretation/\" + re.sub(\".tif\", \"\", my_fname) + \"_Index\" + str(idx) + \".pdf\", bbox_inches=\"tight\")\r\n\r\nIdentify microglia with extreme classification probabilities.\r\n\r\ntop_n = 20\r\n\r\ntop_ad = dat.sort_values(\"ProbabilityAD\", ascending = False).head(top_n).index\r\ntop_ctrl = dat.sort_values(\"ProbabilityCTRL\", ascending = False).head(top_n).index\r\ntop_idx = top_ctrl.append(top_ad)\r\n\r\nprint(\"Top {} Alzheimer/Control Classifications:\".format(top_n))\r\ndat.iloc[top_idx]\r\n\r\nVisualize attribution functions for these astrocytes with extreme classification probabilities.\r\n\r\n%%capture\r\n\r\nfor i in top_idx:\r\n    try:\r\n        visualizeAttribution(*interpretMicroglia(i))\r\n    except IndexError as e:\r\n        print(\"Failed to compute attribution for #\" + str(i) + \".\")\r\n    except AssertionError as e:\r\n        print(\"Failed to normalize #\" + str(i) + \".\") \r\n\r\nSave Notebook\r\n\r\n# use time object imported above for loss/accuracy plot\r\ncname = base_dir + \"Code/CNN/3 - Microglia CNN.ipynb\"\r\nfname = results_dir + \"CNN Training/\" + \"{}.{}_{}.{}.{}_MicrogliaCNN.html\".format(my_time.hour, my_time.minute, my_time.month, my_time.day, my_time.year)\r\ncmd = 'jupyter nbconvert --to html ' + '\"' + cname + '\"' + ' --output ' + '\"' + fname + '\"'\r\n\r\n\r\n\r\n\r\nAkiba, Takuya, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019. “Optuna: A Next-Generation Hyperparameter Optimization Framework.” arXiv:1907.10902 [Cs, Stat], July. http://arxiv.org/abs/1907.10902.\r\n\r\n\r\nBergstra, James, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. 2011. “Algorithms for Hyper-Parameter Optimization.” Advances in Neural Information Processing Systems 24. https://proceedings.neurips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html.\r\n\r\n\r\nKingma, Diederik P., and Jimmy Ba. 2017. “Adam: A Method for Stochastic Optimization.” arXiv:1412.6980 [Cs], January. http://arxiv.org/abs/1412.6980.\r\n\r\n\r\nKokhlikyan, Narine, Vivek Miglani, Miguel Martin, Edward Wang, Jonathan Reynolds, Alexander Melnikov, Natalia Lunova, and Orion Reblitz-Richardson. 2019. “PyTorch Captum.” GitHub. https://github.com/pytorch/captum.\r\n\r\n\r\nPedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” Journal of Machine Learning Research 12 (85): 2825–30. http://jmlr.org/papers/v12/pedregosa11a.html.\r\n\r\n\r\nSundararajan, Mukund, Ankur Taly, and Qiqi Yan. 2017. “Axiomatic Attribution for Deep Networks.” arXiv:1703.01365 [Cs], June. http://arxiv.org/abs/1703.01365.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:20:53-07:00"
    },
    {
      "path": "parse-measurements.html",
      "title": "Parse ROI Measurements",
      "description": "This R script parses the measurements obtained from the previous ROI segmentation script in ImageJ.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nDefine Functions\r\nParse ImageJ ROI Data\r\nNormalize Data\r\nSave Data\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that this script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\n\r\n# Excel manipulation\r\nlibrary(openxlsx)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"3 - ROIs\")\r\ndir3 = file.path(\"Results\", \"3 - ROI Measurements\")\r\ndir3.1 = file.path(dir3, \"3.1 - Normalization Plots\")\r\n\r\n\r\n\r\nDefine Functions\r\nDefine function to retrieve the coordinate data, then convert from pixels to microns based on the crop resolution metadata.\r\n\r\n\r\nget_coordinates = function(cname, fname) {\r\n  \r\n  # read coordinate and resolution data\r\n  coords = fread(file.path(fname, paste0(cname, \"_ROIs.csv\")))\r\n  res = fread(file.path(fname, paste0(cname, \"_Resolution.txt\")))$V1\r\n  \r\n  # calculate center of VIA annotation relative to crop\r\n  coords %>%\r\n    .[, CenterX := X + Width/2] %>%\r\n    .[, CenterY := Y + Height/2]\r\n  \r\n  # convert coordinates from pixels to microns (approx. 6.1 pixels : 1 micron)\r\n  coords[, c(\"Width\", \"Height\", \"CenterX\", \"CenterY\") := map(.(Width, Height, CenterX, CenterY), ~.x/res)]\r\n  \r\n  # replace old X and Y coordinates with new coordinates\r\n  coords = coords[, .(Name, Width, Height, CenterX, CenterY,\r\n                      Type, Quality, Annotator)]\r\n  setnames(coords, c(\"CenterX\", \"CenterY\"), c(\"X\", \"Y\"))\r\n  \r\n  return(coords)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to calculate the distance to the nearest plaque or tangle, where coord is the coordinate pair for a specific ROI, while neuropath is a data.table containing parsed plaque and/or tangle ROI data. Note that distances cannot be less than 0. Also, the Radius for tangle ROIs is set to 0 in the subsequent chunk.\r\n\r\n\r\n# function to compute distance\r\ncompute_distance = function(x, y, neuropath) {\r\n  \r\n  if(nrow(neuropath) == 0) return(NA) else {\r\n    \r\n    neuropath = neuropath %>% \r\n    .[, Raw := sqrt((X - x)^2 + (Y - y)^2)] %>%\r\n    .[, Distance := Raw - Radius] %>%\r\n    .[Distance < 0, Distance := 0]\r\n  \r\n  return(neuropath[, min(Distance)]) \r\n    \r\n  }\r\n  \r\n}\r\n\r\n# function to assign distance based on filter, which must be wrapped in expr()\r\nassign_distance = function(listobj, lab, filter) { \r\n  \r\n  # list contains both data and neuropathology objects\r\n  dat = listobj[[1]]\r\n  neuropath = listobj[[2]]\r\n  \r\n  # assign distance\r\n  dat[, (lab) := pmap_dbl(dat[, .(X, Y)], ~compute_distance(.x, .y, neuropath[eval(filter), ]))]\r\n  \r\n  # return new list\r\n  return(invisible(list(dat, neuropath)))\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to extract and aggregate ROI data from individual crops.\r\n\r\n\r\nparse_crop = function(fname) {\r\n  \r\n  # extract crop attributes\r\n  cinfo = strsplit(fname, \"/\")[[1]]\r\n  cname = cinfo[4]; csplit = strsplit(cname, \"_\")[[1]]\r\n  message(paste(c(\"-\", csplit), collapse = \" \"))\r\n  \r\n  # read and parse data\r\n  dat = fread(file.path(fname, paste0(cname, \"_Measurements.csv\"))) %>% \r\n    .[, ROI := map_chr(strsplit(Label, \":\"), 1)] %>%\r\n    .[, Marker := map_chr(strsplit(Label, \":\"), 3)]\r\n  \r\n  # reshape data from long to wide to extract MGI\r\n  wdat = dat[, .(ROI, Marker, Mean)] %>% dcast(ROI ~ ..., value.var = \"Mean\")\r\n  \r\n  # keep Area and Perimeter variables, overwrite long data\r\n  dat = dat[!duplicated(ROI), .(ROI, Area, Perim.)] %>% \r\n    merge(wdat, ., by = \"ROI\", all.x = TRUE)\r\n    \r\n  # populate with metadata\r\n  dat %>%\r\n    .[, ID := paste(cname, ROI, sep=\"_\")] %>%\r\n    .[, Group := gsub(\"[0-9]\", \"\", ROI)] %>%\r\n    .[, Number := as.numeric(gsub(\"[a-zA-Z]\", \"\", ROI))] %>%\r\n    .[, Condition := cinfo[3]] %>%\r\n    .[, Sample := csplit[1]] %>%\r\n    .[, Layer := gsub(\"Layer\", \"\", csplit[2])] %>%\r\n    .[, Crop := gsub(\"crop\", \"\", csplit[3])]\r\n  \r\n  # join coordinates with ROI measurements\r\n  dat = get_coordinates(cname, fname) %>% \r\n    merge(dat, ., by.x = \"ROI\", by.y = \"Name\", all.x = TRUE)\r\n  \r\n  # separate neuropathology ROIs and calculate radius\r\n  neuropath = dat %>%\r\n    .[Group %in% c(\"Plaque\", \"Tangle\"), ] %>%\r\n    .[, .(Group, Type, ROI, Area, X, Y, Width, Height)] %>%\r\n    .[, Radius := sqrt(Area/pi)] %>%\r\n    .[Group == \"Tangle\", Radius := 0]\r\n  \r\n  # remove neuropathology\r\n  dat = dat[!(Group %in% c(\"Plaque\", \"Tangle\")), ]\r\n  \r\n  # compute distance\r\n  list(dat, neuropath) %>%\r\n    assign_distance(\"Distance\", expr(Group %in% c(\"Plaque\", \"Tangle\"))) %>%\r\n    assign_distance(\"Plaque\", expr(Group == \"Plaque\")) %>%\r\n    assign_distance(\"Large\", expr(Group == \"Plaque\" & Area > 50)) %>%\r\n    assign_distance(\"Compact\", expr(Group == \"Plaque\" & Type == \"compact\")) %>%\r\n    assign_distance(\"Diffuse\", expr(Group == \"Plaque\" & Type == \"diffuse\")) %>%\r\n    assign_distance(\"Tangle\", expr(Group == \"Tangle\")) %>%\r\n    assign_distance(\"Intraneuronal\", expr(Group == \"Tangle\" & Type == \"intra\")) %>%\r\n    assign_distance(\"Extraneuronal\", expr(Group == \"Tangle\" & Type == \"extra\"))\r\n  \r\n  # set column order\r\n  setcolorder(dat, c(\"ROI\", \"ID\", \"Group\", \"Number\", \"Condition\",\r\n                     \"Sample\", \"Layer\", \"Crop\"))\r\n  \r\n  return(dat[, ROI := NULL])\r\n  \r\n}\r\n\r\n\r\n\r\nParse ImageJ ROI Data\r\nMap the parse_crop function over the list of crops measured by ImageJ.\r\n\r\n\r\n# get crop list\r\ncrops = list.files(file.path(ddir, c(\"CTRL\", \"AD\")), full.names = TRUE)\r\n\r\n# map over crop list\r\nmessage(\"Parsing ROI Data:\")\r\noutput = map_dfr(crops, ~parse_crop(.x))\r\n\r\n# convert condition factor and order ROIs\r\noutput = output %>%\r\n  .[, Condition := factor(Condition, levels = c(\"CTRL\", \"AD\"), labels = c(\"Control\", \"Alzheimer\"))] %>%\r\n  .[order(Condition, Sample, Layer, Crop, Group, Number), ]\r\n\r\n\r\n\r\nNormalize Data\r\nRename certain columns to create syntactically valid names.\r\n\r\n\r\n# rename specific columns\r\nsetnames(output, c(\"Ferritin\", \"HuC/D\", \"PHF1-tau\", \"Vimentin\", \"Perim.\"), c(\"FTL\", \"HuC.D\", \"PHF1.tau\", \"VIM\", \"Perimeter\"))\r\n\r\n# get marker list\r\nmetadata = c(\"ID\", \"Group\", \"Number\", \"Condition\", \"Sample\", \"Layer\", \"Crop\",\r\n             \"Area\", \"Perimeter\", \"Width\", \"Height\", \"X\", \"Y\", \"Type\", \"Quality\",\r\n             \"Annotator\", \"Distance\", \"Plaque\", \"Large\", \"Compact\",\r\n             \"Diffuse\", \"Tangle\", \"Intraneuronal\", \"Extraneuronal\")\r\nmarkers = colnames(output) %>% .[!(. %in% metadata)]\r\n\r\n\r\n\r\nNormalize mean gray intensity (MGI) values by applying a log-transformation and computing z-scores.\r\n\r\n\r\n# function to compute z-scores.\r\ncompute_z = function(x) { return((x-mean(x))/sd(x)) }\r\n\r\n# copy non-normalized data\r\nraw = copy(output)\r\n\r\n# normalize data\r\noutput[, (markers) := map_dfc(.SD, ~compute_z(log(.x + 1))),\r\n       .SDcols = markers, by = .(Group)]\r\n\r\n# show output\r\nshow_table(output[, map(.SD, ~mean(.x)), .SDcols = markers, by = Group])\r\nshow_table(output[, map(.SD, ~sd(.x)), .SDcols = markers, by = Group])\r\n\r\n\r\n\r\nSave Data\r\nSave output and display table. Tables in Excel are styled with the openxlsx package. Visualize data normalization by plotting histograms of raw and normalized MGI values.\r\n\r\n\r\nfwrite(output, file.path(dir3, \"ROI Measurements.csv\"))\r\n\r\nshow_table(output[sample(nrow(output), 40), ])\r\n\r\n\r\n\r\nPlot histograms of before and after normalization.\r\n\r\n\r\nplot_data = function(dat_long, lab) {\r\n  \r\n  p = ggplot(dat_long, aes(x = value, fill = Condition)) +\r\n    geom_histogram(bins = 30, alpha = 0.5, color = \"black\") +\r\n    facet_wrap(~ variable, ncol = 6, scales = \"free\") +\r\n    scale_fill_manual(values = c(\"#377EB8\", \"#CE6D8B\")) + \r\n    labs(title = lab,\r\n         x = \"Normalized Mean Gray Intensity\",\r\n         y = \"Frequency\",\r\n         fill = \"Condition\") +\r\n    theme(plot.title = element_text(hjust = 0.5, size = 16, face=\"bold\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=10), legend.position = \"bottom\",\r\n          strip.text = element_text(size=10, face=\"bold\"),\r\n          strip.background = element_rect(color=\"black\", fill=\"#D9D9D9\",\r\n                                          size=1, linetype=\"solid\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n}\r\n\r\n# plot raw data\r\nraw_long = melt(raw, id.vars = c(\"ID\", \"Condition\", \"Group\"),\r\n                measure.vars = markers)\r\nraw_plot = plot_data(raw_long, \"Pre-Normalization Histograms\")\r\nprint(raw_plot)\r\nggsave(file.path(dir3, \"Pre-Normalization Histograms.pdf\"),\r\n       raw_plot, width = 24, height = 12)\r\n\r\n# plot normalized data\r\noutput_long = melt(output, id.vars = c(\"ID\", \"Condition\", \"Group\"),\r\n                   measure.vars = markers)\r\noutput_plot = plot_data(output_long, \"Post-Normalization Histograms\")\r\nprint(output_plot)\r\nggsave(file.path(dir3, \"Post-Normalization Histograms.pdf\"),\r\n       output_plot, width = 24, height = 12)\r\n\r\n\r\n\r\nSave data to a formatted Excel file for readability.\r\n\r\n\r\n# create workbook\r\nwb = createWorkbook()\r\nsname = \"ROI Measurements\"\r\n\r\n# header for metadata\r\nhs1 = createStyle(fgFill = \"#A37C40\", fontColour = \"#FFFFFF\", fontName = \"Arial Black\", halign = \"center\", valign = \"center\", textDecoration = \"Bold\", border = \"Bottom\", borderStyle = \"thick\", fontSize = 14)\r\n\r\n# header for markers\r\nhs2 = createStyle(fgFill = \"#1D3557\", fontColour = \"#FFFFFF\", fontName = \"Arial Black\", halign = \"center\", valign = \"center\", textDecoration = \"Bold\", border = \"Bottom\", borderStyle = \"thick\", fontSize = 14)\r\n\r\n# create worksheet\r\ntcols = ncol(output)\r\naddWorksheet(wb, sheetName = sname)\r\nwriteDataTable(wb, sname, x = output, tableStyle = \"TableStyleMedium15\",\r\n               bandedRows = FALSE)\r\nsetColWidths(wb, sname, cols = 1:tcols, widths = \"auto\")\r\nsetColWidths(wb, sname, cols = 8:24, widths = 12)\r\nsetColWidths(wb, sname, cols = 25:26, widths = 14)\r\nsetColWidths(wb, sname, cols = 27:28, widths = 18)\r\nsetColWidths(wb, sname, cols = 34:tcols, widths = 22)\r\nsetRowHeights(wb, sname, rows = (1:nrow(output))+1, heights = 18)\r\nfreezePane(wb, sname, firstActiveRow = 2, firstActiveCol = 8)\r\n\r\n# style headers\r\naddStyle(wb, sname, hs1, rows = 1, cols = c(1:7, 25:tcols))\r\naddStyle(wb, sname, hs2, rows = 1, cols = 8:24)\r\n\r\n# style marker data\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#FFFFFF\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = which(1:nrow(output) %% 2 == 0) + 1, cols = 8:24, gridExpand = TRUE)\r\n\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#F3F4F6\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = which(1:nrow(output) %% 2 != 0) + 1, cols = 8:24, gridExpand = TRUE)\r\n\r\n# style other columns\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#F6F4F4\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = 1:nrow(output) + 1, cols = c(1:7, 25:tcols), gridExpand = TRUE)\r\n\r\n# style metadata\r\n\r\n# astrocyte metadata\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#FDEDEE\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = which(output$Group == \"Astrocyte\") + 1, cols = c(1:7),\r\n         gridExpand = TRUE)\r\n\r\n# astrocyte header\r\naddStyle(wb, sname, createStyle(fontColour = \"#FFFFFF\", fgFill = \"#C98686\",\r\n                                fontName = \"Arial\", textDecoration = \"Bold\",\r\n                                fontSize = 10, halign = \"center\",\r\n                                valign = \"center\"),\r\n         rows = which(output$Group == \"Astrocyte\") + 1, cols = 2,\r\n         gridExpand = TRUE)\r\n\r\n# microglia metadata\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#F4F6F4\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = which(output$Group == \"Microglia\") + 1, cols = c(1:7),\r\n         gridExpand = TRUE)\r\n\r\n# microglia header\r\naddStyle(wb, sname, createStyle(fontColour = \"#FFFFFF\", fgFill = \"#708B75\",\r\n                                fontName = \"Arial\", textDecoration = \"Bold\",\r\n                                fontSize = 10, halign = \"center\",\r\n                                valign = \"center\"),\r\n         rows = which(output$Group == \"Microglia\") + 1, cols = 2,\r\n         gridExpand = TRUE)\r\n\r\n# vessel metadata\r\naddStyle(wb, sname, createStyle(fontColour = \"#1A1D23\", fgFill = \"#F1F6F9\",\r\n                                fontName = \"Arial\", fontSize = 10,\r\n                                halign = \"center\", valign = \"center\"),\r\n         rows = which(output$Group == \"Vessel\") + 1, cols = c(1:7),\r\n         gridExpand = TRUE)\r\n\r\n# vessel header\r\naddStyle(wb, sname, createStyle(fontColour = \"#FFFFFF\", fgFill = \"#457B9D\",\r\n                                fontName = \"Arial\", textDecoration = \"Bold\",\r\n                                fontSize = 10, halign = \"center\",\r\n                                valign = \"center\"),\r\n         rows = which(output$Group == \"Vessel\") + 1, cols = 2, gridExpand = TRUE)\r\n\r\n# add conditional formatting\r\nfor(i in 34:tcols) {\r\n  conditionalFormatting(wb, sname, cols = i, rows = 1:nrow(output) + 1,\r\n                        type = \"colourScale\",\r\n                        style = c(\"#D9A3A3\", \"#F8F6F6\", \"#8DAE93\"))\r\n}\r\n  \r\n# save workbook\r\nsaveWorkbook(wb, file.path(dir3, \"ROI Measurements.xlsx\"), overwrite = TRUE)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:21:11-07:00"
    },
    {
      "path": "parse-rois.html",
      "title": "Parse VIA ROIs",
      "description": "This R script parses manual astrocyte, microglia, plaque, and tangle annotations created using the VGG Image Annotator tool into an ImageJ-readable format.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRead Mappings\r\nRead Annotations\r\nParse Annotations\r\nWrite VIA ROIs\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that this script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# string manipulation\r\nlibrary(stringi)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"2 - Channel Extraction\")\r\ndir2 = file.path(\"Results\", \"2 - ROI Annotations\")\r\ndir2.1 = file.path(dir2, \"2.1 - VIA Annotations\")\r\n\r\n\r\n\r\nRead Mappings\r\nRead mappings between true crop labels and random alphanumeric IDs generated by prior ImageJ script.\r\n\r\n\r\ncelltypes = c(\"Astrocyte\", \"Microglia\", \"Plaque\", \"Tangle\")\r\n\r\n# read astrocyte, microglia, and plaque mappings\r\nread_map = function(celltype) { return(fread(file.path(ddir, celltype, \"ID Mappings.csv\"))[, Type := celltype]) }\r\nIDmap = rbindlist(map(celltypes, ~read_map(.x)))[, V1 := NULL]\r\nsetnames(IDmap, \"Type\", \"Group\")\r\n\r\nshow_table(head(IDmap, 20))\r\n\r\n\r\n\r\nRead Annotations\r\nRead VGG Image Annotator (VIA) annotations from the output .csv files.\r\n\r\n\r\nflist = list.files(path = dir2.1, pattern = \"\\\\.csv$\")\r\n\r\n# function to read annotations\r\nread_annot = function(file) {\r\n  fread(file.path(dir2.1, file)) %>%\r\n    .[, c(\"Annotator\", \"Group\") := as.list(stri_split_fixed(file, \"_\", simplify = T)[1:2])] %>%\r\n    return()\r\n}\r\n\r\n# read annotations\r\nannot = rbindlist(map(flist, ~read_annot(.x)))\r\n\r\n# remove empty file labels and .png extension suffix\r\nannot = annot %>%\r\n  .[region_shape_attributes != \"{}\", ] %>%\r\n  .[, Filename := gsub(\".png\", \"\", filename)] %>%\r\n  .[, Annotator := factor(Annotator, levels = c(\"alberto\", \"ayush\", \"clara\"), labels = c(\"ASP\", \"AN\", \"CMC\"))] %>%\r\n  .[, Group := factor(Group, levels = c(\"astrocyte\", \"microglia\", \"plaque\", \"tangle\"), labels = celltypes)]\r\n\r\nshow_table(annot[sample(nrow(annot), 40), ])\r\n\r\n\r\n\r\nParse Annotations\r\nDefine function to parse VIA annotations into format readable by ImageJ. To conform with ImageJ naming conventions, the cell-type of each ROI is specified by Group, while the subtype (e.g., compact vs. diffuse or soma vs. process) is specified by type.\r\n\r\n\r\n# define function to parse label based on VIA output\r\nparse_label = function(label, grp = c(\"region\", \"region_shape\")) {\r\n  \r\n  label = label %>%\r\n    strsplit(., \",\", fixed = TRUE) %>% .[[1]] %>% # split by comma to separate vars\r\n    gsub(\"[{, }, \\\"]\", \"\", .) %>% # remove brackets and quotes \r\n    strsplit(., \":\")\r\n  \r\n  # extract second elements in list, then assign first elements as names\r\n  parsed = map(label, 2)\r\n  names(parsed) = map_chr(label, 1)\r\n  \r\n  # replace tangle annotation name\r\n  if(\"tangle\" %in% names(parsed)) { names(parsed) = \"type\"; parsed[[\"quality\"]] = \"none\" }\r\n\r\n  # return statement\r\n  if(grp == \"region\") return(parsed[c(\"type\", \"quality\")]) else return(parsed[c(\"x\", \"y\", \"width\", \"height\")])\r\n  \r\n}\r\n\r\n\r\n\r\nApply parse_label function to VIA annotations, and join with IDmap.\r\n\r\n\r\n# parse annotations\r\nannot = annot %>%\r\n  .[, c(\"Type\", \"Quality\") := map_dfr(region_attributes, ~parse_label(.x, \"region\"))] %>%\r\n  .[, c(\"X\", \"Y\", \"Width\", \"Height\") := map_dfr(region_shape_attributes, ~parse_label(.x, \"region_shape\"))] %>%\r\n  .[Type == \"vessel\", Group := \"Vessel\"] %>%\r\n  .[, filename := gsub(\".png\", \"\", filename)]\r\n\r\n# join with ID mapping information, consolidate microglia and plaque categories, order table\r\nIDmap[, Group := NULL]\r\ndat = merge(IDmap, annot, by.x = \"ID\", by.y = \"filename\", all.y = TRUE) %>%\r\n  .[, .(Sample, Layer, Crop, Condition, File, Group, X, Y, Width, Height, Type, Quality, Annotator)] %>% \r\n  .[order(Sample, Layer, Crop, Group, as.numeric(X)), ]\r\n\r\n# total ROI count\r\nsummary(factor(dat[, Group]))\r\nshow_table(dat[sample(nrow(dat), 40), ])\r\n\r\n\r\n\r\nWrite VIA ROIs\r\nWrite VIA ROIs to appropriate output.\r\n\r\n\r\n# remove prior output\r\nrmlist = list.files(path = dir2, pattern = \"\\\\.csv$\")\r\nfor (rm in rmlist){ file.remove(file.path(dir2, rm)) }\r\n\r\n# write file list\r\nfiles = unique(dat$File)\r\ncat(paste0(\"Annotated Crops: \", length(files), \"\\n\"))\r\nwrite(c(\"Annotated TIFFs\", files), file.path(dir2, \"Annotated TIFFs.txt\"))\r\n\r\n# save VIA annotations of each crop after ordering by Type, then X coord.\r\nwalk(files, ~fwrite(dat[File == .x, ], file.path(dir2, paste0(.x, \".csv\"))))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:21:28-07:00"
    },
    {
      "path": "partition-condition.html",
      "title": "Partition by Condition",
      "description": "This R script partitions the data into training, test, and validation sets using stratified random sampling by condition (i.e., CTRL vs. AD).\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRetrieve ROI Paths\r\nPartition ROIs\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that this script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# fast file system operations\r\nlibrary(fs)\r\n\r\n# partition data\r\nlibrary(caret)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"3 - ROIs\")\r\npdir = file.path(\"Data\", \"4 - Condition Partition\")\r\ndir1 = file.path(\"Results\", \"CNN\", \"1.1 - Condition Partition\")\r\n\r\n# create file structure\r\ncelltypes = c(\"Astrocyte\", \"Microglia\", \"Vessel\") %>% purrr::set_names()\r\ngrp = c(\"Train\", \"Test\", \"Validation\") %>% purrr::set_names()\r\npheno = c(\"CTRL\", \"AD\") %>% purrr::set_names()\r\ndirs = pmap_chr(expand.grid(pdir, celltypes, grp, pheno), file.path)\r\n\r\n# remove prior directories/files if they exist\r\ncheck_dir = function(fname) {if(fs::dir_exists(fname)) fs::dir_delete(fname); fs::dir_create(fname)}\r\nwalk(dirs, check_dir)\r\n\r\n\r\n\r\nRetrieve ROI Paths\r\nWrite function to retrieve ROI paths.\r\n\r\n\r\nretrieve_paths = function(fname) {\r\n  \r\n  # list TIFF files in \"/<celltype> ROIs\" subdirectories\r\n  tiffs = map(celltypes, ~paste(.x, \"ROIs\") %>%\r\n                file.path(fname, .) %>%\r\n                list.files(pattern = \"\\\\.tif$\", full.names = TRUE))\r\n  \r\n  return(tiffs)\r\n  \r\n}\r\n\r\n\r\n\r\nThen, map function over crop list.\r\n\r\n\r\n# get crop list\r\ncrops = file.path(ddir, pheno) %>% list.files(full.names = TRUE)\r\n\r\n# get TIFF file paths\r\ntiffs = map(crops, retrieve_paths)\r\n\r\n# aggregate TIFF file paths by cell type\r\ntiffs = map(celltypes, ~unlist(map(tiffs, .x), use.names = FALSE))\r\n\r\n\r\n\r\nPartition ROIs\r\nDefine function to partition ROIs into training, test, and validation sets.\r\n\r\n\r\npartition_rois = function(flist, lab) {\r\n  \r\n  # construct data table\r\n  dat = data.table(Path = flist)\r\n  \r\n  # parse metadata from file path\r\n  dat %>%\r\n    .[, Name := basename(Path)] %>% \r\n    .[, Group := lab] %>% \r\n    .[, Condition := map_chr(strsplit(Path, \"/\"), 3)] %>%\r\n    .[, Sample := flist %>% strsplit(\"/\") %>% map_chr(4) %>%\r\n        strsplit(\"_\") %>% map_chr(1)] %>%\r\n    .[, Batch := ifelse(Sample %in% c(\"1190\", \"1301\", \"2148\", \"2157\",\r\n                                      \"2191\", \"2207\"), 1, 2)]\r\n  \r\n  # partition into test, training, and validation sets\r\n  train_lab = dat[createDataPartition(Condition, p = 0.6, list = FALSE), Name]\r\n  test_lab = dat[!Name %in% train_lab] %>%\r\n    .[createDataPartition(Condition, p = 0.5, list = FALSE), Name]\r\n  \r\n  # create partition variable\r\n  dat %>%\r\n    .[, Partition := \"Validation\"] %>%\r\n    .[Name %in% train_lab, Partition := \"Train\"] %>%\r\n    .[Name %in% test_lab, Partition := \"Test\"] \r\n  \r\n  # construct output path\r\n  dat[, Output := file.path(pdir, Group, Partition, Condition, Name)]\r\n  \r\n  # copy TIFF files to appropriate output folder\r\n  pwalk(dat[, .(Path, Output)], ~fs::file_copy(.x, .y))\r\n  \r\n  # print results\r\n  cat(paste(\"\\n\", lab, \"ROIs:\\n\"))\r\n  walk(dat[, .(Condition, Partition, Sample)], ~print(summary(factor(.x))))\r\n\r\n  # return data table\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nMap function over TIFF file paths.\r\n\r\n\r\n# partition ROIs\r\nall = imap(tiffs, partition_rois)\r\n\r\n# save partition result\r\nsaveRDS(all, file.path(dir1, \"ROI Partition by Condition.rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:21:35-07:00"
    },
    {
      "path": "partition-state.html",
      "title": "Partition by State",
      "description": "This R script partitions the data into training, test, and validation sets using stratified random sampling by State (i.e., homeostatic vs. intermediate vs. reactive).\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRetrieve ROI Paths\r\nPartition ROIs\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that this script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(“ayushnoori/brainstorm”).\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# fast file system operations\r\nlibrary(fs)\r\n\r\n# partition data\r\nlibrary(caret)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\nddir = file.path(\"Data\", \"3 - ROIs\")\r\npdir = file.path(\"Data\", \"5 - State Partition\")\r\ndir1 = file.path(\"Results\", \"CNN\", \"1.2 - State Partition\")\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\n\r\n# create file structure\r\ncelltypes = c(\"Astrocyte\", \"Microglia\", \"Vessel\") %>% purrr::set_names()\r\ngrp = c(\"Train\", \"Test\", \"Validation\") %>% purrr::set_names()\r\npheno = c(\"CTRL\", \"AD\") %>% purrr::set_names()\r\nstate = c(\"Homeostatic\", \"Intermediate\", \"Reactive\") %>% purrr::set_names()\r\ndirs = pmap_chr(expand.grid(pdir, celltypes, grp, state), file.path)\r\n\r\n# remove prior directories/files if they exist\r\ncheck_dir = function(fname) {if(fs::dir_exists(fname)) fs::dir_delete(fname); fs::dir_create(fname)}\r\nwalk(dirs, check_dir)\r\n\r\n\r\n\r\nRetrieve ROI Paths\r\nWrite function to retrieve ROI paths.\r\n\r\n\r\nretrieve_paths = function(fname) {\r\n  \r\n  # list TIFF files in \"/<celltype> ROIs\" subdirectories\r\n  tiffs = map(celltypes, ~paste(.x, \"ROIs\") %>%\r\n                file.path(fname, .) %>%\r\n                list.files(pattern = \"\\\\.tif$\", full.names = TRUE))\r\n  \r\n  return(tiffs)\r\n  \r\n}\r\n\r\n\r\n\r\nThen, map function over crop list.\r\n\r\n\r\n# get crop list\r\ncrops = file.path(ddir, pheno) %>% list.files(full.names = TRUE)\r\n\r\n# get TIFF file paths\r\ntiffs = map(crops, retrieve_paths)\r\n\r\n# aggregate TIFF file paths by cell type\r\ntiffs = map(celltypes, ~unlist(map(tiffs, .x), use.names = FALSE))\r\n\r\n\r\n\r\nPartition ROIs\r\nDefine function to partition ROIs into training, test, and validation sets.\r\n\r\n\r\npartition_rois = function(flist, lab, sc) {\r\n  \r\n  # construct data table\r\n  dat = data.table(Path = flist)\r\n  message(\"\\n\", toupper(lab), \" ANALYSIS:\")\r\n  message(\"Total TIFF Files: \", nrow(dat))\r\n  message(\"Total ROI Measurements: \", nrow(sc))\r\n  \r\n  # parse metadata from file path\r\n  dat = dat %>%\r\n    .[, Name := basename(Path)] %>% \r\n    .[, Group := lab] %>% \r\n    .[, Condition := map_chr(strsplit(Path, \"/\"), 3)] %>%\r\n    .[, Sample := flist %>% strsplit(\"/\") %>% map_chr(4) %>%\r\n        strsplit(\"_\") %>% map_chr(1)] %>%\r\n    .[, Batch := ifelse(Sample %in% c(\"1190\", \"1301\", \"2148\", \"2157\",\r\n                                      \"2191\", \"2207\"), 1, 2)] %>%\r\n    .[, ID := gsub(\"(AD_|CTRL_|.tif)\", \"\", Name)] %>%\r\n    merge(sc[, .(ID, State)], by = \"ID\", all = T)\r\n  \r\n  # partition into test, training, and validation sets\r\n  train_lab = dat[createDataPartition(paste(State, Condition, sep = \"_\"),\r\n                                      p = 0.6, list = FALSE), Name]\r\n  test_lab = dat[!Name %in% train_lab] %>%\r\n    .[createDataPartition(paste(State, Condition, sep = \"_\"),\r\n                          p = 0.5, list = FALSE), Name]\r\n  \r\n  # create partition variable\r\n  dat %>%\r\n    .[, Partition := \"Validation\"] %>%\r\n    .[Name %in% train_lab, Partition := \"Train\"] %>%\r\n    .[Name %in% test_lab, Partition := \"Test\"] \r\n  \r\n  # construct output path\r\n  dat[, Output := file.path(pdir, Group, Partition, State, Name)]\r\n  \r\n  # copy TIFF files to appropriate output folder\r\n  pwalk(dat[, .(Path, Output)], ~fs::file_copy(.x, .y))\r\n  \r\n  # print results\r\n  cat(paste(\"\\n\", lab, \"ROIs:\\n\"))\r\n  walk(dat[, .(Condition, Partition, Sample)], ~print(summary(factor(.x))))\r\n\r\n  # return data table\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nMap function over TIFF file paths.\r\n\r\n\r\n# read spectral clustering data\r\nall_sc = readRDS(file.path(dir4, \"Z-Score Data.rds\"))\r\n\r\n# partition ROIs\r\nall = imap(tiffs, ~partition_rois(.x, .y, all_sc[[.y]]))\r\n\r\n# save partition result\r\nsaveRDS(all, file.path(dir1, \"ROI Partition by State.rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:21:43-07:00"
    },
    {
      "path": "performance-evaluation.html",
      "title": "Performance Evaluation",
      "description": "This R script evaluates GBM/CNN performance by bootstrapping across 500 iterations of the independent test set.\n",
      "author": [
        {
          "name": {},
          "url": {}
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nRead Data\r\nCompute Model Performance\r\n\r\nDependencies\r\nLoad requisite packages and define directories.\r\n\r\n\r\nlibrary(data.table)\r\nlibrary(ROCR)\r\nlibrary(pROC)\r\nlibrary(purrr)\r\nlibrary(glmnet)\r\nlibrary(dbplyr)\r\nlibrary(PRROC)\r\nlibrary(rms)\r\n\r\n\r\n\r\nRead Data\r\nRead test set classification probabilities from gradient boosting machines (GBM) and convolutional neural network (CNN) model output. To comply with the bootstrapping function, datasets must have a column called labels (has true labels) and column called predictions (has predicted probability).\r\n\r\n\r\n# parse GBM data\r\ngbm <- readRDS('data/AD vs. CTRL GBM Results.rds')\r\n\r\n# parse astrocyte GBM\r\ngbm_astrocyte <- gbm[['Astrocyte']]$Scores[,2:3]\r\nsetnames(gbm_astrocyte,c('Condition','Alzheimer'),c('labels','predictions'))\r\ngbm_astrocyte[,labels := as.integer(labels) - 1]\r\n\r\n# parse microglia GBM\r\ngbm_microglia  <- gbm[['Microglia']]$Scores[,2:3]\r\nsetnames(gbm_microglia,c('Condition','Alzheimer'),c('labels','predictions'))\r\ngbm_microglia[,labels := as.integer(labels) - 1]\r\n\r\n# read astrocyte CNN\r\ncnn_astrocyte <- fread('data/Astrocyte CNN TestSetResults.csv')[,c('TrueLabel','ProbabilityAD')]\r\nsetnames(cnn_astrocyte,c('TrueLabel','ProbabilityAD'),c('labels','predictions'))\r\ncnn_astrocyte[,labels := ifelse(labels == 1,0,1)]\r\n\r\n# read microglia CNN\r\ncnn_microglia <- fread('data/Microglia CNN TestSetResults.csv')[,c('TrueLabel','ProbabilityAD')]\r\nsetnames(cnn_microglia,c('TrueLabel','ProbabilityAD'),c('labels','predictions'))\r\ncnn_microglia[,labels := ifelse(labels == 1,0,1)]\r\n\r\n# create named list\r\nall_experiments <- list(gbm_astrocyte = gbm_astrocyte, gbm_microglia = gbm_microglia,\r\n                        cnn_astrocyte = cnn_astrocyte,cnn_microglia = cnn_microglia)\r\n\r\n\r\n\r\nCompute Model Performance\r\nFunction to compute model performance and calculate 95% confidence intervals by boostrapping across 500 iterations of the independent test set.\r\n\r\n\r\ncompute_model_performance <- function(model_name,model_preds,metrics = c('acc', 'ppv', 'npv', 'sens', 'spec', 'f','auc','aucpr'),threshold_criteria = 'max_accuracy',marginal_thresholds = NULL){\r\n\r\n  # prediction object ROCR expects; if it is NOT ROCR class prediction then make model_preds one\r\n  if(!'prediction' %in% class(model_preds)) {\r\n    ROCR_prediction <- prediction(model_preds$predictions,model_preds$labels)\r\n  } else {ROCR_prediction <- model_preds}\r\n\r\n  # first, check if there are any threshold dependent metrics\r\n  if(any(!metrics %in% c('auc','aucpr'))){\r\n    acc <- performance(ROCR_prediction,'acc')\r\n    acc <- data.table(cutoffs = acc@x.values[[1]],accuracy = acc@y.values[[1]])\r\n    if(threshold_criteria == 'max_accuracy'){\r\n      # pick cutoff that yields max accuracy\r\n      threshold <- acc[acc[,.I[which.max(accuracy)]],cutoffs]\r\n    }\r\n    # must input all_experiments_performance_metrics_cast if using this threshold_criteria\r\n    if(threshold_criteria == 'from_marginal'){\r\n      # merge back threshold from marginal model\r\n      colnames_strip <- names(stratifed_result_indices)\r\n      from_marginal_model <- gsub(paste(colnames_strip,collapse = \"|\"),\"\",model_name)\r\n      from_marginal_model <- gsub('_\\\\b',\"\",from_marginal_model)\r\n      threshold <- marginal_thresholds[model_name == from_marginal_model,Threshold]\r\n      # need to get threshold closest to this ON the data in strata\r\n      threshold <- acc[cutoffs <= threshold,][order(-cutoffs)][1,cutoffs] # get threshold within acc object immediately BEFORE this threshold or equal to if its\r\n    }\r\n  }\r\n\r\n  # build DT for results from threshold independent metrics\r\n  ROCR_results_no_threshold <- map_dfr(metrics[metrics %in% c('auc','aucpr')],~data.table(Measure = .x,\r\n                                                                                          Value = performance(ROCR_prediction,.x)@y.values[[1]],\r\n                                                                                          model_name = model_name,\r\n                                                                                          threshold_criteria = threshold_criteria,\r\n                                                                                          threshold = 'Measure Independent of Threshold'))\r\n  \r\n  # threshold dependent methods\r\n  # index y value where x value equal to threshold selected from threshold criteria\r\n  ROCR_results_threshold <- map_dfr(metrics[!metrics %in% c('auc','aucpr')],~data.table(Measure = .x,\r\n                                                                                        Value = performance(ROCR_prediction,.x)@y.values[[1]][which(performance(ROCR_prediction,.x)@x.values[[1]] == threshold)],\r\n                                                                                        model_name = model_name,\r\n                                                                                        threshold_criteria = threshold_criteria,\r\n                                                                                        threshold = threshold\r\n  ))\r\n\r\n  # add CIs, sample 300 times w replacement and take .025 slices each end\r\n  set.seed(5281995)\r\n  seeds <- sample.int(10000000,500)\r\n\r\n  # for 1:500, compute CI for each measure\r\n  # takes a replicate index and data to resample, resamples w replacement, computes all specified measures for each replicate\r\n  boot_CIs <- function(i,data_to_resample){\r\n    # new seed for each replicate\r\n    set.seed(seed = seeds[[i]]);\r\n    # extract just preds and labels from ROCR object\r\n    data <- data.table(predictions = data_to_resample@predictions[[1]],labels = data_to_resample@labels[[1]])\r\n    # resample w replacement\r\n    data <- data[sample(1:nrow(data),replace = T),]\r\n    # make a new prediction object\r\n    ROCR_prediction <- prediction(data$predictions,data$labels)\r\n\r\n    if(any(!metrics %in% c('auc','aucpr'))){\r\n      acc <- performance(ROCR_prediction,'acc')\r\n      acc <- data.table(cutoffs = acc@x.values[[1]],accuracy = acc@y.values[[1]])\r\n      if(threshold_criteria == 'max_accuracy'){\r\n        # pick cutoff that yields max accuracy\r\n        threshold <- acc[acc[,.I[which.max(accuracy)]],cutoffs]\r\n      }\r\n    }\r\n\r\n    ROCR_results_no_threshold <- map_dfr(metrics[metrics %in% c('auc','aucpr')],~data.table(Measure = .x,\r\n                                                                                            Value = performance(ROCR_prediction,.x)@y.values[[1]],\r\n                                                                                            model_name = model_name,\r\n                                                                                            threshold_criteria = threshold_criteria,\r\n                                                                                            threshold = 'Measure Independent of Threshold',\r\n                                                                                            replicate = i))\r\n    # threshold dependent methods, index y vals where x val equal to threshold selected from threshold criteria\r\n    ROCR_results_threshold <- map_dfr(metrics[!metrics %in% c('auc','aucpr')],~data.table(Measure = .x,\r\n                                                                                          Value = performance(ROCR_prediction,.x)@y.values[[1]][which(performance(ROCR_prediction,.x)@x.values[[1]] == threshold)],\r\n                                                                                          model_name = model_name,\r\n                                                                                          threshold_criteria = threshold_criteria,\r\n                                                                                          threshold = threshold,\r\n                                                                                          replicate = i))\r\n\r\n    rbindlist(list(ROCR_results_threshold,ROCR_results_no_threshold),fill = TRUE)\r\n  }\r\n\r\n  # get results of each replicate\r\n  bootstrap_runs <- map_dfr(1:500,~boot_CIs(.x,data_to_resample = ROCR_prediction))\r\n  # cast so each row is a replicate, each col is a measure\r\n  bootstrap_runs_cast <- dcast(bootstrap_runs,model_name+threshold_criteria+replicate~Measure,value.var = 'Value')\r\n  # get quantiles accross measure cols\r\n  bootstrap_aggregation <- imap_dfr(bootstrap_runs_cast[,4:ncol(bootstrap_runs_cast)],~data.table(Measure = .y,CI_l = quantile(.x,.025,na.rm = T),CI_u = quantile(.x,.975,na.rm = T)))\r\n\r\n\r\n\r\n  # bind metrics together\r\n  final_metrics <- rbindlist(list(ROCR_results_threshold,ROCR_results_no_threshold),fill = TRUE)\r\n  final_metrics[bootstrap_aggregation,on=.(Measure),`:=` (CI_l = i.CI_l,CI_u = i.CI_u)]\r\n  return(final_metrics)\r\n}\r\n\r\n\r\n\r\nMap previously defined function.\r\n\r\n\r\nall_experiments_performance_metrics<- imap_dfr(all_experiments, ~compute_model_performance(model_name = .y, model_preds = .x))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:21:54-07:00"
    },
    {
      "path": "phf1-extraction.html",
      "title": "Tangle Channel Extraction",
      "description": "This ImageJ script extracts the PHF1 and DAPI channels from multi-channel TIFF images, merges both channels, and assigns each image a random alphanumeric code for blinded tangle annotation and classification as intraneuronal vs. extraneuronal.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\nThis script is written in the ImageJ Macro Language (IJM).\r\nmacro \"PHF1 Channel Extraction\" {\r\n\r\n    setBatchMode(true);\r\n\r\n    input = getDirectory(\"Choose input data folder.\");\r\n    files = getFileList(input);\r\n    // Array.show(files);\r\n\r\n    dir = \"<insert your directory here>\";\r\n    datadir = dir + \"Data/2 - Channel Extraction/Tangle/\";\r\n\r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  FUNCTION FOR RANDOM ID\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    function randomString(length, chars) {\r\n        result = \"\";\r\n        for (i = 0; i < length; i++) {\r\n            maxlen = lengthOf(chars)-1;\r\n            rand = round(random * maxlen);\r\n            result +=  substring(chars, rand, rand+1);\r\n        }\r\n        return result;\r\n    }\r\n    \r\n\r\n    ////////////////////////////////////////////////////////////\r\n    /////  ITERATE OVER IMAGES\r\n    ////////////////////////////////////////////////////////////\r\n    \r\n    for (f = 0; f < files.length; f++) {\r\n\r\n        open(input + files[f]);\r\n        Roi.remove; // remove active selection, if any\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  LOAD IMAGE + DEFINE MARKERS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n        filename = substring(image, 0, indexOf(image, \"_Reordered.tif\"));\r\n        \r\n        splitname = split(filename, \"_\");   \r\n        sample = splitname[0];\r\n        layer = splitname[1];\r\n        crop = splitname[2];\r\n        crop = substring(crop, 4);\r\n        \r\n        if (sample == \"1190\" || sample == \"1301\" || sample == \"1619\" || sample == \"2169\" || sample == \"2191\" || sample == \"2250\" || sample == \"2274\") {\r\n            condition = \"CTRL\";\r\n        } else {\r\n            condition = \"AD\";\r\n        }\r\n        \r\n        print(filename);\r\n\r\n        ////////////////////////////////////////////////////////////\r\n        /////  RANDOMIZE CROP\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        id = randomString(6, \"0123456789abcdefghijklmnopqrstuvwxyz\");\r\n        // print(id);\r\n\r\n        Table.set(\"ID\", f, id);\r\n        Table.set(\"Sample\", f, sample);\r\n        Table.set(\"Layer\", f, layer);\r\n        Table.set(\"Crop\", f, crop);\r\n        Table.set(\"Condition\", f, condition);\r\n        Table.set(\"File\", f, filename);\r\n        Table.update();\r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE PHF1 AND DAPI CHANNELS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        // duplicate PHF1 channel and merge with HuC/D\r\n        selectImage(image); // shift focus to original\r\n        run(\"Duplicate...\", \"title=PHF1 duplicate channels=17\");\r\n        selectImage(image);\r\n        run(\"Duplicate...\", \"title=DAPI duplicate channels=1\");\r\n\r\n        // merge channels\r\n        run(\"Merge Channels...\", \"c2=PHF1 c3=DAPI create\");\r\n        \r\n        selectWindow(\"Composite\"); // shift focus to original\r\n        saveAs(\"Png\", datadir + condition + \"/\" + id + \".png\");\r\n        close();\r\n\r\n        selectImage(image);\r\n        close();\r\n    \r\n    }\r\n\r\n    // save table with mappings\r\n    Table.save(datadir + \"ID Mappings.csv\")\r\n\r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:51:50-07:00"
    },
    {
      "path": "plot-roc-curves.html",
      "title": "Plot ROC Curves",
      "description": "This R script plots the receiver operating characteristic (ROC) curves for the convolutional neural network models and calculates the area under the ROC curves (AUC).\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nMerge Data\r\nPlot Data\r\n\r\nDependencies\r\nLoad requisite packages and define directories.\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# data visualization\r\nlibrary(ggplot2)\r\n\r\n# ROC curve\r\nlibrary(pROC)\r\nlibrary(plotROC)\r\n\r\n# utilities\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# create file structure\r\ncelltypes = c(\"Astrocyte\", \"Microglia\") %>% purrr::set_names()\r\n\r\n# set directories\r\nddir = c(\"2 - Astrocyte CNN\", \"3 - Microglia CNN\") %>% file.path(\"Results\", \"CNN\", ., \"Output\") %>% purrr::set_names(celltypes)\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\ndir8 = file.path(\"Results\", \"8 - CNN Interpretability\")\r\n\r\n\r\n\r\nLoad Data\r\nDefine function to read CNN output.\r\n\r\n\r\n# function to read CNN output\r\nread_cnn = function(fpath, lab) {\r\n  \r\n  # select most recent CNN output file\r\n  fname = list.files(fpath, pattern = \"\\\\.csv$\") %>%\r\n  .[strsplit(., \"_\") %>% { order(map_chr(., 2), map_chr(., 1)) }] %>% .[length(.)]\r\n  \r\n  # print and read file\r\n  cat(paste0(\"\\n\", toupper(lab), \"\\nTarget Directory: \", fpath, \"\\nInput File: \", fname, \"\\n\"))\r\n  if (length(fname) > 0) return(fread(file.path(fpath, fname))) else return(NULL)\r\n\r\n}\r\n\r\n\r\n\r\nLoad processed ROI measurement data from the 4 - Spectral Clustering directory and CNN output from the CNN\\2 - Astrocyte CNN\\Output directory.\r\n\r\n\r\n# read ROI data\r\nall = readRDS(file.path(dir4, \"Z-Score Data.rds\"))[names(celltypes)]\r\n\r\n# read CNN output\r\ncnn = imap(ddir, read_cnn)\r\n\r\n\r\n\r\nMerge Data\r\nDefine function to merge ROI measurement data and clustering metadata with CNN output.\r\n\r\n\r\n# function to parse and merge data\r\nmerge_data = function(allx, cnnx) {\r\n  \r\n  # parse CNN data\r\n  cnnx %>%\r\n    .[, c(\"V1\", \"Image\") := NULL] %>%\r\n    .[, File := strsplit(File, \"/\")] %>%\r\n    .[, File := map(File, ~tail(.x, 1))] %>%\r\n    .[, ID := gsub(\"(\\\\.tif|AD_|CTRL_)\", \"\", File)] %>%\r\n    .[, PredictedLabel := factor(PredictedLabel, levels = c(1, 0), labels = c(\"Control\", \"Alzheimer\"))] %>%\r\n    .[, TrueLabel := factor(TrueLabel, levels = c(1, 0), labels = c(\"Control\", \"Alzheimer\"))]\r\n  \r\n  # merge data\r\n  setcolorder(cnnx, \"ID\")\r\n  cnnx = merge(cnnx, allx, by = \"ID\", all.x = TRUE, all.y = FALSE)\r\n  return(cnnx)\r\n  \r\n}\r\n\r\n\r\n\r\nMap function over data objects for cell-types with CNN output data.\r\n\r\n\r\n# remove null CNN data\r\nkeep = names(which(!map_lgl(cnn, is.null)))\r\ncelltypes = celltypes[keep]; all = all[keep]; cnn = cnn[keep]\r\n\r\n# function to parse and merge data\r\nall = map(celltypes, ~merge_data(all[[.x]], cnn[[.x]]))\r\n\r\n\r\n\r\nPlot Data\r\nDefine function to plot histogram.\r\n\r\n\r\n# function to plot histogram\r\nplot_histogram = function(dat, grp, grpcol, facet_grp = NULL, pos = \"identity\", nbins = 30, density = FALSE) {\r\n  \r\n  p = ggplot(dat, aes(x = ProbabilityAD, fill = get(grp))) +\r\n    geom_histogram(position = pos, bins = nbins, alpha = 0.5, color = \"black\") +\r\n    scale_fill_manual(values = levels(dat[[grpcol]])) + \r\n    labs(x = \"Alzheimer Classification Probability\", y = \"Count\", fill = grp) +\r\n    theme(axis.title.x = element_text(size=14, face=\"bold\"), axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"), legend.text = element_text(size=10), legend.position = \"bottom\",\r\n          strip.text = element_text(size=16, face=\"bold\"),\r\n          strip.background = element_rect(color=\"black\", fill=\"#D9D9D9\", size=1, linetype=\"solid\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  if(!is.null(facet_grp)) {\r\n    p = p +\r\n      facet_wrap(~ get(facet_grp), ncol = 3) +\r\n      geom_density(aes(y=..density.. * 15), fill = \"white\", alpha = 0.3, linetype = \"dashed\")\r\n  }\r\n  \r\n  if(density) {\r\n    p = p + geom_density(aes(y=..density.. * 10, color = get(grp)), fill = \"white\", alpha = 0.3, linetype = \"dashed\") +\r\n      scale_color_manual(values = levels(dat[[grpcol]])) + labs(color = grp)\r\n  }\r\n  \r\n  return(p)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to create plots.\r\n\r\n\r\nplot_data = function(dat, lab, pcols) {\r\n  \r\n  # create subdirectory if needed\r\n  wdir = file.path(dir8, lab)\r\n  if(!dir.exists(wdir)) {dir.create(wdir)}\r\n  \r\n  # define plotting colors\r\n  dat = dat %>%\r\n    .[, StateColors := factor(State, labels = pcols$State)] %>%\r\n    .[, SampleColors := factor(Sample, labels = pcols$Sample)] %>%\r\n    .[, ConditionColors := factor(Condition, labels = pcols$Condition)]\r\n  \r\n  # create histograms\r\n  p_state = plot_histogram(dat, \"State\", \"StateColors\", \"State\")\r\n  p_condition = plot_histogram(dat, \"Condition\", \"ConditionColors\", nbins = 50, density = FALSE)\r\n  p_cs = plot_histogram(dat, \"Condition\", \"ConditionColors\", \"State\")\r\n  \r\n  # save histograms\r\n  ggsave(file.path(wdir, \"State Classification Probabilities.pdf\"), p_state, width = 16, height = 6)\r\n  ggsave(file.path(wdir, \"Condition Classification Probabilities.pdf\"), p_condition, width = 6, height = 6)\r\n  ggsave(file.path(wdir, \"Condition + State Classification Probabilities.pdf\"), p_cs, width = 16, height = 6)\r\n  \r\n  # calculate AUC\r\n  roc_calc = roc(response = dat$TrueLabel, predictor = dat$ProbabilityCTRL)\r\n  print(roc_calc)\r\n  \r\n  # plot ROC curve\r\n  auc_lab = paste0(\"AUC = \", round(roc_calc$auc, 4))\r\n  roc_plot = ggplot(dat, aes(d = TrueLabel, m = ProbabilityCTRL)) +\r\n    ggtitle(\"Convolutional Neural Network ROC\") +\r\n    geom_abline(aes(intercept = 0, slope = 1, color = \"AUC = 0.5\"), linetype = \"dashed\", size = 1)+\r\n    geom_roc(aes(color = auc_lab), labels = FALSE, pointsize = 0) +\r\n    geom_roc(linealpha = 0, n.cuts = 12, labelround = 2, labelsize = 3) +\r\n    # scale_colour_manual(values = c(\"#FF9B71\", \"#63B0CD\")) +\r\n    scale_colour_manual(values = c(\"#577399\", \"#F39B6D\")) +\r\n    labs(x = \"1 - Specificity\", y = \"Sensitivity\", color= \"Area Under the Curve (AUC)\") + theme_bw() +\r\n    theme(plot.title = element_text(size = 16, hjust = 0.5, face = \"bold\"),\r\n          axis.title.x = element_text(size=14, face=\"bold\"),\r\n          axis.title.y = element_text(size=14, face=\"bold\"),\r\n          legend.title = element_text(size=12, face=\"bold\"),\r\n          legend.text = element_text(size=12),\r\n          legend.position = c(0.72, 0.14),\r\n          legend.background = element_rect(fill = \"white\", color = \"black\"),\r\n          panel.border = element_rect(color = \"black\", fill = NA, size = 1))\r\n  \r\n  # save ROC curve\r\n  ggsave(file.path(wdir, \"ROC Curve.pdf\"), roc_plot, width = 6, height = 6)\r\n  # write(export_interactive_roc(roc_plot), file = file.path(wdir, \"ROC Curve.html\"))\r\n  \r\n  # return data\r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nCreate the plots specified in plot_data by mapping over all.\r\n\r\n\r\n# define color palette\r\ncols = list(\r\n  Distance = c('< 50 um' = \"#F95738\", '50-100 um' = \"#EE964B\", '> 100 um' = \"#F4D35E\", 'None' = \"#736F72\"),\r\n  Sample = c('1190' = \"#A6CEE3\", '1301' = \"#5D9FC9\", '1619' = \"#2A7FB0\", '1684' = \"#79B79A\", '1820' = \"#9ED57B\", '2124' = \"#5AB348\", '2148' = \"#619E45\", '2157' = \"#CC9B7F\", '2169' = \"#F37272\", '2191' = \"#E62D2F\", '2207' = \"#ED593B\", '2242' = \"#FBB268\", '2250' = \"#FDA13B\", '2274' = \"#FF7F00\"),\r\n  Condition = c(Control = \"#377EB8\", Alzheimer = \"#CE6D8B\"),\r\n  State = c('Homeostatic' = \"#39B200\", 'Intermediate' = \"#F0C808\", 'Reactive' = \"#960200\")\r\n)\r\n\r\n# create plots\r\nplots = imap(all, ~plot_data(.x, .y, cols))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:22:08-07:00"
    },
    {
      "path": "reorder-channels.html",
      "title": "Reorder Channels",
      "description": "This ImageJ script allows the user to reorder imaging channels as necessary to facilitate downstream analysis.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\nThis script is written in the ImageJ Macro Language (IJM).\r\nmacro \"Reorder Channels [r]\" {\r\n\r\n    // setBatchMode(true); // will bypass GUI!\r\n\r\n    dir = \"<insert your directory here>\";\r\n    output = dir + \"Converted TIFF Crops/Reordered Crops/\";\r\n\r\n    input = getDirectory(\"Choose input data folder.\");\r\n    files = getFileList(input);\r\n    Array.show(files);\r\n\r\n    \r\n    for (f = 0; f < files.length; f++) {\r\n\r\n        open(input + files[f]);\r\n        \r\n        ////////////////////////////////////////////////////////////\r\n        /////  LOAD IMAGE + DEFINE MARKERS\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n        filename = substring(image, 0, indexOf(image, \".tif\"));\r\n        \r\n        run(\"8-bit\"); // convert to 8-bit, note that will lose fluorescence granularity\r\n    \r\n        // create array to hold assigned slice names\r\n        titles = newArray(nSlices);\r\n        // list possible marker names\r\n        markerNames = newArray(\"GFAP\", \"DAPI\", \"MHC2\", \"TSPO\", \"EAAT2\", \"TMEM119\", \"CD68\", \"EAAT1\", \"ALDH1L1\", \"IBA1\", \"Vimentin\", \"Ferritin\", \"HuCD\", \"YKL40\", \"GS\", \"Abeta\", \"PHF1-tau\");\r\n        \r\n        for (i = 1; i <= nSlices; i++) {\r\n             \r\n            setSlice(i);\r\n            run(\"Enhance Contrast...\", \"saturated=0.3\"); // only for visualization purposes\r\n    \r\n            // call dialog box to assign marker name to selected slice\r\n            Dialog.create(\"Which Marker Is This?\");\r\n            Dialog.addChoice(\"Type:\", markerNames);\r\n            Dialog.show();\r\n            marker = Dialog.getChoice();\r\n    \r\n            // set slice name based on user choice\r\n            setMetadata(\"Label\", marker);\r\n            titles[i-1] = getInfo(\"slice.label\");\r\n            \r\n            markerNames = Array.deleteValue(markerNames, marker); // prevents the same marker from being assigned to multiple slices\r\n            \r\n        }   \r\n    \r\n        ////////////////////////////////////////////////////////////\r\n        /////  REORDER SLICES + DEFINE LUT\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        run(\"Stack to Images\"); // separate each slice\r\n    \r\n        // concatenate in right order - rearranges all slices\r\n        run(\"Concatenate...\", \" title=\" + image + \" open image1=DAPI image2=ALDH1L1 image3=IBA1 image4=GFAP image5=MHC2 image6=TSPO image7=EAAT2 image8=TMEM119 image9=CD68 image10=EAAT1 image11=Vimentin image12=Ferritin image13=YKL40 image14=GS image15=HuCD image16=Abeta image17=PHF1-tau\");\r\n    \r\n        // make composite image with color\r\n        run(\"Make Composite\", \"display=Color\");\r\n        \r\n        finalNames = newArray(\"DAPI\", \"ALDH1L1\", \"IBA1\", \"GFAP\", \"MHC2\", \"TSPO\", \"EAAT2\", \"TMEM119\", \"CD68\", \"EAAT1\", \"Vimentin\", \"Ferritin\", \"YKL40\", \"GS\", \"HuC/D\", \"Abeta\", \"PHF1-tau\");\r\n        colorList = newArray(\"Blue\", \"Red\", \"Green\", \"Magenta\", \"Cyan\", \"Yellow\", \"Grays\");\r\n                \r\n        for (k = 1; k <= nSlices; k++) {\r\n             \r\n            setSlice(k);\r\n            setMetadata(\"Label\", finalNames[k-1]); // set final name of slice\r\n    \r\n            run(colorList[(k-1) % colorList.length]); // apply distinct false color per slice\r\n            \r\n            // add more data pre-processing if desired!\r\n            \r\n        }\r\n        \r\n        saveAs(\"Tiff\", output + filename + \"_Reordered.tif\");\r\n        \r\n        close();\r\n\r\n    }\r\n    \r\n    \r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:22:11-07:00"
    },
    {
      "path": "roi-segmentation.html",
      "title": "ROI Segmentation",
      "description": "This ImageJ script segments the manually-defined ROIs from the multi-channel TIFFs.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nSetup\r\nRetrieve TIFFs\r\nBackground Subtraction\r\nDefine Metadata\r\nCreate ROIs\r\nSave ROI Coordinates\r\nROI Segmentation\r\nSave Measurements\r\n\r\nSetup\r\nThis script is written in the ImageJ Macro Language (IJM). For readability, the single macro has been divided into several sections here. First, the requisite directories, cell-type groups, and measurements are defined.\r\nmacro \"ROI Segmentation [m]\" {\r\n\r\n    setBatchMode(true);\r\n\r\n    // define paths\r\n    dir = \"<insert your directory here>\";\r\n    dir2 = dir + \"Results/2 - ROI Annotations/\";\r\n    outdir = dir + \"Data/3 - ROIs/\";\r\n\r\n    getDateAndTime(year, month, dayOfWeek, dayOfMonth, hour, minute, second, msec);\r\n    MonthNames = newArray(\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\");\r\n    print(\"MULTIPLEX IHC ROI EXTRACTION\");\r\n    print(\"DATE: \" + MonthNames[month] + \". \" + dayOfMonth + \", \" + year);\r\n    print(\"START TIME: \" + hour + \":\" + minute + \":\" + second);\r\n    \r\n\r\n    // define cell-type groups\r\n    celldirs = newArray(\"Astrocyte ROIs/\", \"Microglia ROIs/\", \"Vessel ROIs/\", \"Plaque ROIs/\", \"Tangle ROIs/\");\r\n    Roi.setGroupNames(\"astrocyte,microglia,vessel,plaque,tangle\");\r\n\r\n    // get input directory for final TIFF crops\r\n    input = getDirectory(\"Choose input data folder with full TIFF crops.\");\r\n    // input = dir + \"Data/1 - Test Crops/\";\r\n    files = getFileList(input);\r\n    // Array.show(files);\r\n\r\n    // set measurements to be applied on ROIs\r\n    run(\"Set Measurements...\", \"area mean standard modal min centroid center perimeter bounding shape feret's integrated median skewness area_fraction stack display redirect=None decimal=3\"); \r\n    \r\n    // open list of TIFF files which have annotations\r\n    run(\"Table... \", \"open=[\" + dir2 + \"Annotated TIFFs.txt]\");\r\n    Table.rename(\"Annotated TIFFs.txt\", \"TIFFs\");\r\nRetrieve TIFFs\r\nNext, the list of annotated TIFF files is retrieved and iterated over.\r\n    ////////////////////////////////////////////////////////////\r\n    /////  GET TIFF LIST AND OPEN FILES\r\n    ////////////////////////////////////////////////////////////\r\n\r\n    tiffs = Table.getColumn(\"Annotated TIFFs\", \"TIFFs\");\r\n    selectWindow(\"TIFFs\");\r\n    run(\"Close\");\r\n    // Array.show(tiffs);\r\n\r\n    for (f = 0; f < tiffs.length; f++) {\r\n\r\n        fname = tiffs[f];\r\n        print(\"\"); // add new line\r\n        print(\"-------- \" + f+1 + \"/\" + tiffs.length + \": \" + fname + \" --------\");\r\n        \r\n        open(input + fname + \"_Reordered.tif\");\r\n        Roi.remove; // remove active selection, if any\r\n\r\n        image = getTitle(); // get crop title\r\n        selectImage(image); // shift focus to the selected crop\r\n\r\n        // normalize with rolling ball filter\r\n        run(\"Subtract Background...\", \"rolling=200 stack\");\r\nBackground Subtraction\r\nFor each TIFF file, rolling ball background subtraction is applied with a radius of 200 pixels.\r\n        // perform background subtraction with rolling ball filter\r\n        run(\"Subtract Background...\", \"rolling=200 stack\");\r\nDefine Metadata\r\nThe condition of each sample (i.e., CTRL or AD) is defined, and the pixel-to-micron resolution is extracted from the metadata.\r\n        ////////////////////////////////////////////////////////////\r\n        /////  CLASSIFY SAMPLE CONDITION\r\n        ////////////////////////////////////////////////////////////\r\n        \r\n        sample = split(fname, \"_\"); // sample condition classified again\r\n        sample = sample[0];\r\n        \r\n        if (sample == \"1190\" || sample == \"1301\" || sample == \"1619\" || sample == \"2169\" || sample == \"2191\" || sample == \"2250\" || sample == \"2274\") {\r\n            condition = \"CTRL\";\r\n        } else {\r\n            condition = \"AD\";\r\n        }\r\n        \r\n        // create output directory\r\n        output = outdir + condition + \"/\" + fname;\r\n        File.makeDirectory(output);\r\n\r\n        // print condition\r\n        print(\"Condition: \" + condition);\r\n\r\n        // extract pixel to micron conversion which is preserved in TIFF metadata\r\n        info = getImageInfo();\r\n        res = substring(info, indexOf(info, \"X Resolution: \"), indexOf(info, \"Y Resolution: \"));\r\n        res = split(res, \" \");\r\n        res = res[2];\r\n        run(\"Set Scale...\", \"distance=\" + res + \" known=1 pixel=1.000 unit=micron\"); // set scale in pixels/micron\r\n\r\n        // print resolution\r\n        print(\"Resolution: \" + res + \" pixels per micron\");\r\n        File.saveString(res, output + \"/\" + fname + \"_Resolution.txt\") \r\nCreate ROIs\r\nROIs are created from the parsed VGG Image Annotator (VIA) annotations.\r\n        ////////////////////////////////////////////////////////////\r\n        /////  OPEN ROI LIST AND CREATE ROIS\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        // open parsed VIA annotations for this crop\r\n        run(\"Table... \", \"open=[\" + dir2 + fname + \".csv]\");\r\n        cname = fname + \" Coordinates\";\r\n        Table.rename(fname + \".csv\", cname);\r\n        selectWindow(cname);\r\n\r\n        // define ROI arrays from VIA annotations\r\n        X = Table.getColumn(\"X\", cname);\r\n        Y = Table.getColumn(\"Y\", cname);\r\n        width = Table.getColumn(\"Width\", cname);\r\n        height = Table.getColumn(\"Height\", cname);\r\n        group = Table.getColumn(\"Group\", cname);\r\n\r\n        // define property arrays from VIA annotations\r\n        type = Table.getColumn(\"Type\", cname);\r\n        quality = Table.getColumn(\"Quality\", cname);\r\n        annotator = Table.getColumn(\"Annotator\", cname);\r\n        \r\n        // shift focus to image\r\n        selectWindow(image);\r\n        // setSlice(2); // change slice to membrane marker\r\n\r\n        // set counter for astrocytes and vessels\r\n        a = 0; m = 0; v = 0; p = 0; t = 0;\r\n\r\n        // iterate over annotated regions to create ROIs\r\n        for (i = 0; i < X.length; i++) {\r\n\r\n            makeRectangle(X[i], Y[i], width[i], height[i]);\r\n            roiManager(\"add\");\r\n            roiManager(\"Select\", i);\r\n\r\n            if(group[i] == \"astrocyte\") {\r\n                Roi.setGroup(236);\r\n                Roi.setProperty(\"Type\", type[i]);\r\n                Roi.setProperty(\"Quality\", quality[i]);\r\n                Roi.setProperty(\"Annotator\", annotator[i]);\r\n                roiManager(\"update\");\r\n                a = a + 1; roiManager(\"rename\", \"Astrocyte\" + a);\r\n            }\r\n            \r\n            if(group[i] == \"microglia\") {\r\n                Roi.setGroup(227);\r\n                Roi.setProperty(\"Type\", type[i]);\r\n                Roi.setProperty(\"Quality\", quality[i]);\r\n                Roi.setProperty(\"Annotator\", annotator[i]);\r\n                roiManager(\"update\");\r\n                m = m + 1; roiManager(\"rename\", \"Microglia\" + m);\r\n            }\r\n            \r\n            if(group[i] == \"vessel\") {\r\n                Roi.setGroup(87);\r\n                Roi.setProperty(\"Type\", type[i]);\r\n                Roi.setProperty(\"Quality\", quality[i]);\r\n                Roi.setProperty(\"Annotator\", annotator[i]);\r\n                roiManager(\"update\");\r\n                v = v + 1; roiManager(\"rename\", \"Vessel\" + v);\r\n            }\r\n\r\n            if(group[i] == \"plaque\") {\r\n                Roi.setGroup(27);\r\n                Roi.setProperty(\"Type\", type[i]);\r\n                Roi.setProperty(\"Quality\", quality[i]);\r\n                Roi.setProperty(\"Annotator\", annotator[i]);\r\n                roiManager(\"update\");\r\n                p = p + 1; roiManager(\"rename\", \"Plaque\" + p);\r\n            }\r\n\r\n            if(group[i] == \"tangle\") {\r\n                Roi.setGroup(114);\r\n                Roi.setProperty(\"Type\", type[i]);\r\n                Roi.setProperty(\"Quality\", quality[i]);\r\n                Roi.setProperty(\"Annotator\", annotator[i]);\r\n                roiManager(\"update\");\r\n                t = t + 1; roiManager(\"rename\", \"Tangle\" + t);\r\n            }\r\n\r\n\r\n            \r\n        }\r\n\r\n        print(\"# of Astrocytes: \" + a);\r\n        print(\"# of Microglia: \" + m);\r\n        print(\"# of Vessels: \" + v);\r\n        print(\"# of Plaques: \" + p);\r\n        print(\"# of Tangles: \" + t);\r\nSave ROI Coordinates\r\nCoordinates of each ROI are saved.\r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE ROI COORDINATES\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        // save ROI coordinates to compare with ABETA plaques\r\n        // these coordinates are relative to entire crop\r\n        // ROI extraction only saves coordinates relative to smaller VIA annotation\r\n        roiManager(\"List\");\r\n        rname = fname + \" ROIs\";\r\n        Table.rename(\"Overlay Elements of \" + image, rname);\r\n\r\n        // create empty arrays\r\n        nROI = roiManager(\"Count\");\r\n        property_type = newArray(nROI); \r\n        property_quality = newArray(nROI); \r\n        property_annotator = newArray(nROI);\r\n        \r\n        // get ROI properties\r\n        for (k = 0; k < nROI; k++) {\r\n            roiManager(\"Select\", k);\r\n            property_type[k] = Roi.getProperty(\"Type\");\r\n            property_quality[k] = Roi.getProperty(\"Quality\");\r\n            property_annotator[k] = Roi.getProperty(\"Annotator\");\r\n        }\r\n\r\n        // add to Table\r\n        Table.setColumn(\"Type\", property_type, rname);\r\n        Table.setColumn(\"Quality\", property_quality, rname);\r\n        Table.setColumn(\"Annotator\", property_annotator, rname);\r\n        \r\n        // save coordinates\r\n        selectWindow(rname);\r\n        saveAs(\"Results\", output + \"/\" + fname + \"_ROIs.csv\");\r\n\r\n        // wipe results\r\n        Table.reset(fname + \"_ROIs.csv\");\r\n        selectWindow(fname + \"_ROIs.csv\");\r\n        run(\"Close\");\r\nROI Segmentation\r\nFor each newly-created ROI, the sub-image is segmented from the TIFF file. After adaptive thresholding using Otsu’s method, the mean gray intensity (MGI) of each channel is measured. Finally, each ROI is interpolated to a 64 x 64 image as input to the convolutional neural network (CNN).\r\n        ////////////////////////////////////////////////////////////\r\n        /////  ROI SEGMENTATION\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        // create ROI directories\r\n        dirA = output + \"/\" + celldirs[0];\r\n        dirM = output + \"/\" + celldirs[1];\r\n        dirV = output + \"/\" + celldirs[2];\r\n        dirP = output + \"/\" + celldirs[3];\r\n        dirT = output + \"/\" + celldirs[4];\r\n        File.makeDirectory(dirA); File.makeDirectory(dirA + \"/ROIs\");\r\n        File.makeDirectory(dirM); File.makeDirectory(dirM + \"/ROIs\");\r\n        File.makeDirectory(dirV); File.makeDirectory(dirV + \"/ROIs\");\r\n        File.makeDirectory(dirP); File.makeDirectory(dirP + \"/ROIs\");\r\n        File.makeDirectory(dirT); File.makeDirectory(dirT + \"/ROIs\");\r\n\r\n        // get total number of ROIs\r\n        nROI = roiManager(\"Count\");\r\n\r\n        // show all ROIs\r\n        roiManager(\"show all with labels\");\r\n        a = 0; m = 0; v = 0; p = 0; t = 0;\r\n        mycounter = 0;\r\n        \r\n        \r\n        for (k = 0; k < nROI; k++) {\r\n            \r\n            // duplicate ROI\r\n            roiManager(\"Select\", k);\r\n            if (Roi.getGroup() == 236) { cellname = \"Astrocyte\"; celldir = dirA; a = a + 1; mycounter = a; }\r\n            if (Roi.getGroup() == 227) { cellname = \"Microglia\"; celldir = dirM; m = m + 1; mycounter = m; }\r\n            if (Roi.getGroup() == 87) { cellname = \"Vessel\"; celldir = dirV; v = v + 1; mycounter = v; }\r\n            if (Roi.getGroup() == 27) { cellname = \"Plaque\"; celldir = dirP; p = p + 1; mycounter = p; }\r\n            if (Roi.getGroup() == 114) { cellname = \"Tangle\"; celldir = dirT; t = t + 1; mycounter = t; }\r\n            ROIname = cellname + mycounter;\r\n            run(\"Duplicate...\", \"title=\" + ROIname + \" duplicate\");\r\n\r\n\r\n            ////////////////////////////////////////////////////////////\r\n            /////  CREATE INSIDE ROI AND REMOVE BACKGROUND\r\n            ////////////////////////////////////////////////////////////\r\n\r\n            if (cellname == \"Astrocyte\" || cellname == \"Vessel\") {\r\n                run(\"Duplicate...\", \"title=MarkerMask duplicate channels=2\"); // duplicate ALDH1L1  \r\n            }\r\n            else if (cellname == \"Microglia\") {\r\n                run(\"Duplicate...\", \"title=MarkerMask duplicate channels=3\"); // duplicate IBA1\r\n            } else if (cellname == \"Plaque\") {\r\n                run(\"Duplicate...\", \"title=MarkerMask duplicate channels=16\"); // duplicate ABETA\r\n            } else {\r\n                run(\"Duplicate...\", \"title=MarkerMask duplicate channels=17\"); // duplicate PHF1\r\n            }\r\n\r\n            // auto-threshold using Otsu method\r\n            run(\"Auto Threshold\", \"method=Otsu white\");\r\n            run(\"Analyze Particles...\", \"include add stack\");\r\n            selectWindow(\"MarkerMask\");\r\n            close();\r\n\r\n\r\n            // create array to select only new ROIs\r\n            selectWindow(ROIname);\r\n            oldROIs = Array.getSequence(nROI);\r\n            newROIs = Array.getSequence(roiManager(\"Count\"));\r\n\r\n            // ONLY if new ROIs have been added\r\n            if (roiManager(\"Count\") > nROI) {\r\n\r\n\r\n                // delete preexisting ROI indices from new ROI array \r\n                for (r = 0; r < oldROIs.length; r++) {\r\n                    newROIs = Array.deleteIndex(newROIs, 0);\r\n                }\r\n    \r\n                // combine multiple ROIs if more than one was created\r\n                if(newROIs.length > 1) {\r\n                    roiManager(\"select\", newROIs);\r\n                    roiManager(\"combine\");\r\n                    roiManager(\"add\");\r\n                    roiManager(\"select\", newROIs);\r\n                    roiManager(\"delete\");\r\n                }\r\n\r\n                        \r\n                // clear outside of ROI\r\n                roiManager(\"Select\", nROI);\r\n                roiManager(\"rename\", cellname + mycounter + \"_ROI\");\r\n                // setBackgroundColor(255, 255, 255);\r\n                setBackgroundColor(0, 0, 0);\r\n                run(\"Clear Outside\", \"stack\");\r\n\r\n\r\n\r\n                ////////////////////////////////////////////////////////////\r\n                /////  MEASURE AND SAVE ROI\r\n                ////////////////////////////////////////////////////////////\r\n\r\n                // measure each channel based on new ROI\r\n                for (s = 1; s <= nSlices; s++) {\r\n                    setSlice(s);\r\n                    run(\"Measure\");                                     \r\n                }\r\n                \r\n                // scale for CNN and save\r\n                run(\"Size...\", \"width=64 height=64 average interpolation=None\"); // no interpolation keeps edge of ROI sharp\r\n                saveAs(\"Tiff\", celldir + \"/\" + condition + \"_\" + fname + \"_\" + cellname + mycounter + \".tif\"); // save in crop specific folder\r\n    \r\n    \r\n                // save ROI\r\n                roiManager(\"Select\", nROI);\r\n                roiManager(\"save selected\", celldir + \"/ROIs/\" + condition + \"_\" + fname + \"_\" + cellname + mycounter + \".roi\")\r\n                roiManager(\"delete\");\r\n\r\n            } else { // if no ROI was created\r\n                print(\"ROI #\" + k + \" NOT CREATED: \" + cellname + \" \" + mycounter);\r\n            }\r\n\r\n            // close image window\r\n            close();\r\n            \r\n        }\r\nSave Measurements\r\nFor each TIFF image, the ROI measurements are saved and the image is closed.\r\n        ////////////////////////////////////////////////////////////\r\n        /////  SAVE AND CLOSE CROP\r\n        ////////////////////////////////////////////////////////////\r\n\r\n        // update ROI manager GUI for output\r\n        roiManager(\"show all with labels\");\r\n\r\n        // save results\r\n        saveAs(\"Results\", output + \"/\" + fname + \"_Measurements.csv\");\r\n\r\n        // save ROIs to ZIP file\r\n        roiManager(\"Save\", output + \"/\" + fname + \"_ROIs.zip\");\r\n        \r\n        // save original image\r\n        saveAs(\"Tiff\", output + \"/\" + fname + \"_Crop.tif\");\r\n\r\n        // clear all results\r\n        Table.reset(\"Results\");\r\n        roiManager(\"reset\");\r\n        \r\n        // close VIA annotations\r\n        selectWindow(cname);\r\n        run(\"Close\");\r\n\r\n        // close crop\r\n        selectWindow(fname + \"_Crop.tif\");\r\n        close();\r\n\r\n        \r\n    }\r\n\r\n    selectWindow(\"Results\");\r\n    run(\"Close\")\r\n\r\n    print(\"\"); // add new line\r\n    getDateAndTime(year, month, dayOfWeek, dayOfMonth, hour, minute, second, msec);\r\n    print(\"END TIME: \" + hour + \":\" + minute + \":\" + second);\r\n\r\n    selectWindow(\"Log\");\r\n    saveAs(\"text\", outdir + \"Log.txt\"); // save in crop specific folder\r\n\r\n}\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:22:14-07:00"
    },
    {
      "path": "spectral-clustering.html",
      "title": "Spectral Clustering",
      "description": "This R script performs unsupervised spectral clustering to investigate the existence of diverse phenotypes of astrocytes and microglia in control and AD brains.\n",
      "author": [
        {
          "name": {},
          "url": "https://www.github.com/ayushnoori"
        }
      ],
      "contents": "\r\n\r\nContents\r\nDependencies\r\nLoad Data\r\nDefine Clustering Functions\r\nPerform Spectral Clustering\r\nPlot Heatmap\r\n\r\nDependencies\r\nLoad requisite packages and define directories. Note that this script uses my personal utilities package brainstorm, which can be downloaded via devtools::install_github(\"ayushnoori/brainstorm\").\r\n\r\n\r\n# data manipulation\r\nlibrary(data.table)\r\nlibrary(purrr)\r\nlibrary(magrittr)\r\n\r\n# spectral clustering\r\nlibrary(stringr)\r\nlibrary(SNFtool)\r\n\r\n# heatmap\r\nlibrary(pheatmap)\r\nlibrary(ggplot2)\r\nlibrary(RColorBrewer)\r\n\r\n# utility functions\r\nlibrary(brainstorm)\r\n\r\n\r\n\r\nNote that directories are relative to the R project path.\r\n\r\n\r\n# set directories\r\ndir3 = file.path(\"Results\", \"3 - ROI Measurements\")\r\ndir4 = file.path(\"Results\", \"4 - Spectral Clustering\")\r\n\r\n\r\n\r\nLoad Data\r\nLoad ROI measurement data from the 3 - ROI Measurements directory and split by Group.\r\n\r\n\r\nall = fread(file.path(dir3, \"ROI Measurements.csv\")) %>% split(.$Group)\r\n\r\n\r\n\r\nDefine Clustering Functions\r\nDefine functions to compute spectral clustering using the SNFtool package. Here, affinityCustom is a modified version of affinityMatrix from SNFtool without sparsifying the affinity matrix by a K-nearest neighbors approach (i.e., removing the assumption that local pairwise similarities with high values are more reliable than remote ones).\r\nDefine spectral clustering function.\r\n\r\n\r\nspectral_clustering = function(dat, lab, mx, k = 3) {\r\n  \r\n  # print log\r\n  cat(paste(\"\\n\", toupper(lab), \"ANALYSIS\\n\"))\r\n  \r\n  # calculate distance matrix\r\n  distM = as.matrix(dat[, ..mx]) %>% dist2(., .) %>% .^(1/2)\r\n  \r\n  # calculate similarity matrix\r\n  simM = affinityCustom(distM)\r\n  \r\n  # perform spectral clustering\r\n  cat(paste0(\"- Performing Spectral Clustering, \", word(Sys.time(), 2), \"\\n\"))\r\n  clust = spectralClustering(simM, K = k)\r\n  \r\n  # add spectral clustering labels to data\r\n  dat[, State := clust]\r\n  \r\n  return(dat)\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to bin distance, where distlab is a character vector specifying the name of the distance column of interest.\r\n\r\n\r\nbin_distance = function(dat, distlab,\r\n                        distbins = c(0, 25, 50),\r\n                        distlevels = c(\"< 25 um\", \"25-50 um\", \"> 50 um\"),\r\n                        distna = \"None\") {\r\n  \r\n  # bin distance labels\r\n  dat %>% \r\n    .[, TemporaryBin := .SD, .SDcols = distlab] %>%\r\n    .[, TemporaryBin := cut(TemporaryBin,\r\n                        breaks = c(distbins, max(TemporaryBin, na.rm = T)),\r\n                        include.lowest = T)] %>%\r\n    .[, TemporaryBin := addNA(TemporaryBin)] %>%\r\n    .[, TemporaryBin := plyr::mapvalues(TemporaryBin, levels(TemporaryBin),\r\n                                    c(distlevels, \"None\"))]\r\n  \r\n  # group None with > 50 um\r\n  dat[TemporaryBin == \"None\", TemporaryBin := distna]\r\n  \r\n  # rename column\r\n  setnames(dat, \"TemporaryBin\", paste0(distlab, \"Bin\"))\r\n  \r\n  return(invisible(dat))\r\n  \r\n}\r\n\r\n\r\n\r\nDefine function to (a) prepare data for heatmap by refactoring label, reordering, and binning distance, then (b) plot the heatmap using the pheatmap package.\r\n\r\n\r\nscale_data = function(b) { return(100*(b - min(b))/(max(b) - min(b))) }\r\n\r\nplot_heatmap = function(dat, lab, mx, hmcols, hmsel) {\r\n\r\n  # subset marker/metadata columns\r\n  dat = dat[, .SD, .SDcols = c(mx, hmsel)]\r\n  \r\n  # calculate proportion of control ROIs by state\r\n  prop = dat[, sum(Condition == \"Control\")/.N, by = .(State)] %>%\r\n    .[order(-V1), State]\r\n  \r\n  # convert to factor then reorder ROIs\r\n  dat = dat %>%\r\n    .[, State := factor(State, levels = prop, labels = c(\"Homeostatic\", \"Intermediate\", \"Reactive\"))] %>%\r\n    # .[, State := factor(State)] %>%\r\n    .[, Sample := factor(Sample)] %>%\r\n    .[, Condition := factor(Condition, levels = c(\"Control\", \"Alzheimer\"))] %>%\r\n    .[order(State, Condition, Layer, runif(nrow(.))), ]\r\n  \r\n  # calculate distances\r\n  dat = dat %>% bin_distance(\"Distance\")\r\n  \r\n  # write file\r\n  setcolorder(dat, c(\"ID\", \"State\"))\r\n  fwrite(dat, file.path(dir4, paste(lab, \"Spectral Clustering.csv\")))\r\n  \r\n  # calculate column gaps\r\n  gaps = cumsum(summary(dat[, State]))\r\n  \r\n  # prepare for heatmap\r\n  hmdat = dat[, ..mx] %>% map_dfc(~scale_data(.x)) %>% t()\r\n  \r\n  # select row names and column names\r\n  hmannos = dat[, .SD, .SDcols = c(\"Layer\", \"Condition\", \"State\")]\r\n  \r\n  # group None with > 50\r\n  group_none = function(x) hmannos[get(x) == \"None\", c(x) := \"> 50 um\"]\r\n  walk(hmdists, group_none)\r\n  \r\n  # remove \"Bin\" label\r\n  colnames(hmannos) = gsub(\"Bin\", \"\", colnames(hmannos), fixed = T)\r\n  \r\n  # set rownames and colnames\r\n  colnames(hmdat) = dat$ID; rownames(hmannos) = dat$ID\r\n                    \r\n  # plot heatmap\r\n  hm = pheatmap(hmdat,\r\n                cluster_cols = FALSE, cluster_rows = FALSE,\r\n                annotation_colors = hmcols, annotation_col = hmannos,\r\n                border_color = NA, # main = paste(lab, \"Heatmap\"),\r\n                show_colnames = FALSE, gaps_col = gaps, silent = TRUE)\r\n  \r\n  ggsave(file.path(dir4, paste(lab, \"Heatmap.pdf\")), hm, width = 8, height = 6)\r\n  ggsave(file.path(dir4, paste(lab, \"Heatmap.png\")), hm, width = 8, height = 6, dpi = 1200)\r\n  \r\n  return(dat)\r\n\r\n}\r\n\r\n\r\n\r\nPerform Spectral Clustering\r\nApply spectral_clustering function over ROI measurement data by Type.\r\n\r\n\r\n# define markers of interest\r\nmarkers = list(Astrocyte = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\",\r\n                             \"EAAT1\", \"EAAT2\", \"GS\"),\r\n               Microglia = c(\"MHC2\", \"CD68\", \"TMEM119\", \"TSPO\", \"FTL\"),\r\n               Vessel = c(\"GFAP\", \"YKL40\", \"VIM\", \"TSPO\", \"EAAT1\", \"EAAT2\", \"GS\"))\r\n\r\n# comment out the below lines if you do NOT want to re-run spectral clustering\r\n\r\n# perform spectral clustering with k = 3 clusters\r\nall = imap(all, ~spectral_clustering(.x, .y, markers[[.y]], 4))\r\n\r\n# save spectral clustering result\r\nsaveRDS(all, file.path(dir4, \"Spectral Clustering.rds\"))\r\n\r\n# read spectral clustering result\r\n# all = readRDS(file.path(dir4, \"Spectral Clustering.rds\"))\r\n\r\n\r\n\r\nPlot Heatmap\r\nPlot data as heatmaps.\r\n\r\n\r\n# define metadata of interest for output .csv file\r\nsel = colnames(all$Astrocyte) %>% .[!(. %in% c(unlist(markers), c(\"ALDH1L1\", \"Abeta\", \"DAPI\", \"HuC.D\", \"IBA1\", \"PHF1.tau\")))]\r\n\r\n# define distance colors\r\ndistcols = c('< 25 um' = \"#FFAF85\", '25-50 um' = \"#FFED85\", '> 50 um' = \"#96BDD9\")\r\n\r\n# define heatmap color palette\r\ncols = list(\r\n  Distance = distcols, \r\n  Layer = c(II = \"#DDF2B2\", III = \"#8DD2B9\", IV = \"#39AEC3\", V = \"#2072B1\", VI = \"#0C2C84\"),\r\n  Condition = c(Control = \"#377EB8\", Alzheimer = \"#CE6D8B\"),\r\n  State = c('Homeostatic' = \"#39B200\", 'Intermediate' = \"#F0C808\", 'Reactive' = \"#960200\"))\r\n\r\n# plot heatmap data\r\nhm = imap(all, ~plot_heatmap(.x, .y, markers[[.y]], cols, sel))\r\n\r\n# save processed data\r\nsaveRDS(hm, file.path(dir4, \"Z-Score Data.rds\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-07-10T23:22:27-07:00"
    }
  ],
  "collections": []
}
