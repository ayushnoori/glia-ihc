
@article{schindelin_fiji_2012,
	title = {Fiji: {An} {Open}-{Source} {Platform} for {Biological}-{Image} {Analysis}},
	volume = {9},
	issn = {1548-7105},
	shorttitle = {Fiji},
	doi = {10.1038/nmeth.2019},
	abstract = {Fiji is a distribution of the popular open-source software ImageJ focused on biological-image analysis. Fiji uses modern software engineering practices to combine powerful software libraries with a broad range of scripting languages to enable rapid prototyping of image-processing algorithms. Fiji facilitates the transformation of new algorithms into ImageJ plugins that can be shared with end users through an integrated update system. We propose Fiji as a platform for productive collaboration between computer science and biology research communities.},
	language = {eng},
	number = {7},
	journal = {Nature Methods},
	author = {Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
	month = jun,
	year = {2012},
	pmid = {22743772},
	pmcid = {PMC3855844},
	keywords = {Algorithms, Animals, Brain, Computational Biology, Drosophila melanogaster, Image Enhancement, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Information Dissemination, Software, Software Design},
	pages = {676--682},
}

@article{rueden_imagej2_2017,
	title = {{ImageJ2}: {ImageJ} for the next generation of scientific image data},
	volume = {18},
	issn = {1471-2105},
	shorttitle = {{ImageJ2}},
	url = {https://doi.org/10.1186/s12859-017-1934-z},
	doi = {10.1186/s12859-017-1934-z},
	abstract = {ImageJ is an image analysis program extensively used in the biological sciences and beyond. Due to its ease of use, recordable macro language, and extensible plug-in architecture, ImageJ enjoys contributions from non-programmers, amateur programmers, and professional developers alike. Enabling such a diversity of contributors has resulted in a large community that spans the biological and physical sciences. However, a rapidly growing user base, diverging plugin suites, and technical limitations have revealed a clear need for a concerted software engineering effort to support emerging imaging paradigms, to ensure the software’s ability to handle the requirements of modern science.},
	number = {1},
	urldate = {2021-02-28},
	journal = {BMC Bioinformatics},
	author = {Rueden, Curtis T. and Schindelin, Johannes and Hiner, Mark C. and DeZonia, Barry E. and Walter, Alison E. and Arena, Ellen T. and Eliceiri, Kevin W.},
	month = nov,
	year = {2017},
	keywords = {Extensibility, Image processing, ImageJ, ImageJ2, Interoperability, N-dimensional, Open development, Open source, Reproducibility},
	pages = {529},
}

@incollection{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	pages = {8024--8035},
}

@misc{kokhlikyan_pytorch_2019,
	title = {{PyTorch} {Captum}},
	url = {https://github.com/pytorch/captum},
	publisher = {GitHub},
	author = {Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Reynolds, Jonathan and Melnikov, Alexander and Lunova, Natalia and Reblitz-Richardson, Orion},
	year = {2019},
	note = {Publication Title: GitHub repository},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2021-03-03},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv Fulltext PDF:C\:\\Users\\ayush\\Zotero\\storage\\3FCH7WZ8\\Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ayush\\Zotero\\storage\\VUXJNZLI\\1412.html:text/html},
}
